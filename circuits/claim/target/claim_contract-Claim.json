{
  "transpiled": true,
  "noir_version": "1.0.0-beta.5+0000000000000000000000000000000000000000",
  "name": "Claim",
  "functions": [
    {
      "name": "sync_private_state",
      "is_unconstrained": true,
      "custom_attributes": ["utility"],
      "abi": {
        "parameters": [],
        "return_type": null,
        "error_types": {
          "576755928210959028": {
            "error_kind": "string",
            "string": "0 has a square root; you cannot claim it is not square"
          },
          "2709101749560550278": {
            "error_kind": "string",
            "string": "Cannot serialize point at infinity as bytes."
          },
          "2896122431943215824": {
            "error_kind": "fmtstring",
            "length": 144,
            "item_types": [{ "kind": "integer", "sign": "unsigned", "width": 32 }]
          },
          "2920182694213909827": {
            "error_kind": "string",
            "string": "attempt to subtract with overflow"
          },
          "3305101268118424981": {
            "error_kind": "string",
            "string": "Attempted to delete past the length of a CapsuleArray"
          },
          "3367683922240523006": {
            "error_kind": "fmtstring",
            "length": 58,
            "item_types": [{ "kind": "field" }]
          },
          "5019202896831570965": {
            "error_kind": "string",
            "string": "attempt to add with overflow"
          },
          "5727012404371710682": { "error_kind": "string", "string": "push out of bounds" },
          "5870202753060865374": {
            "error_kind": "fmtstring",
            "length": 61,
            "item_types": [{ "kind": "field" }, { "kind": "field" }]
          },
          "6336853191198150230": {
            "error_kind": "fmtstring",
            "length": 77,
            "item_types": [{ "kind": "integer", "sign": "unsigned", "width": 32 }]
          },
          "6485997221020871071": {
            "error_kind": "string",
            "string": "call to assert_max_bit_size"
          },
          "6753155520859132764": { "error_kind": "string", "string": "Failed to deliver note" },
          "7233212735005103307": {
            "error_kind": "string",
            "string": "attempt to multiply with overflow"
          },
          "8270195893599566439": {
            "error_kind": "string",
            "string": "Invalid public keys hint for address"
          },
          "8830323656616886390": {
            "error_kind": "string",
            "string": "Got a public log emitted by a different contract"
          },
          "12822839658937144934": { "error_kind": "fmtstring", "length": 75, "item_types": [] },
          "13649294680379557736": {
            "error_kind": "string",
            "string": "extend_from_bounded_vec out of bounds"
          },
          "14225679739041873922": { "error_kind": "string", "string": "Index out of bounds" },
          "14514982005979867414": {
            "error_kind": "string",
            "string": "attempt to bit-shift with overflow"
          },
          "14657895983200220173": {
            "error_kind": "string",
            "string": "Attempted to read past the length of a CapsuleArray"
          },
          "15366650908120444287": {
            "error_kind": "fmtstring",
            "length": 48,
            "item_types": [{ "kind": "field" }, { "kind": "field" }]
          },
          "16218014537381711836": {
            "error_kind": "string",
            "string": "Value does not fit in field"
          },
          "16446004518090376065": {
            "error_kind": "string",
            "string": "Input length must be a multiple of 32"
          },
          "16954218183513903507": {
            "error_kind": "string",
            "string": "Attempted to read past end of BoundedVec"
          },
          "17843811134343075018": { "error_kind": "string", "string": "Stack too deep" },
          "17879506016437779469": {
            "error_kind": "fmtstring",
            "length": 128,
            "item_types": [{ "kind": "integer", "sign": "unsigned", "width": 32 }]
          },
          "18194595712952743247": {
            "error_kind": "fmtstring",
            "length": 98,
            "item_types": [
              { "kind": "integer", "sign": "unsigned", "width": 32 },
              { "kind": "integer", "sign": "unsigned", "width": 32 },
              { "kind": "field" }
            ]
          }
        }
      },
      "bytecode": "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",
      "debug_symbols": "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",
      "brillig_names": ["sync_private_state"]
    },
    {
      "name": "public_dispatch",
      "is_unconstrained": true,
      "custom_attributes": ["public"],
      "abi": {
        "parameters": [
          { "name": "selector", "type": { "kind": "field" }, "visibility": "private" }
        ],
        "return_type": null,
        "error_types": {
          "1752556835457866331": { "error_kind": "string", "string": "No public functions" }
        }
      },
      "bytecode": "JwAABAEqAAABBRhSVSgKJhpbPAAAAQ==",
      "debug_symbols": "XY1bCoAgEEX3Mt+toK1EiI9RBkRl0iDEvWeRIH3ee+6jgkFVnKBg4wHrVkExeU9O+Khlphi6W9sCQ4rMiN2CiW97D0hN/C+dkkkqj5+0JeiJ5isNMk4TR42mMD5LL2t7uwE=",
      "brillig_names": ["public_dispatch"]
    }
  ],
  "outputs": {
    "globals": {
      "notes": [
        {
          "fields": [
            {
              "kind": "integer",
              "sign": false,
              "value": "0000000000000000000000000000000000000000000000000000000000000000"
            },
            { "kind": "string", "value": "UintNote" },
            {
              "fields": [
                {
                  "name": "owner",
                  "value": {
                    "fields": [
                      {
                        "name": "index",
                        "value": {
                          "kind": "integer",
                          "sign": false,
                          "value": "0000000000000000000000000000000000000000000000000000000000000000"
                        }
                      },
                      { "name": "nullable", "value": { "kind": "boolean", "value": false } }
                    ],
                    "kind": "struct"
                  }
                },
                {
                  "name": "randomness",
                  "value": {
                    "fields": [
                      {
                        "name": "index",
                        "value": {
                          "kind": "integer",
                          "sign": false,
                          "value": "0000000000000000000000000000000000000000000000000000000000000001"
                        }
                      },
                      { "name": "nullable", "value": { "kind": "boolean", "value": false } }
                    ],
                    "kind": "struct"
                  }
                },
                {
                  "name": "value",
                  "value": {
                    "fields": [
                      {
                        "name": "index",
                        "value": {
                          "kind": "integer",
                          "sign": false,
                          "value": "0000000000000000000000000000000000000000000000000000000000000002"
                        }
                      },
                      { "name": "nullable", "value": { "kind": "boolean", "value": false } }
                    ],
                    "kind": "struct"
                  }
                }
              ],
              "kind": "struct"
            }
          ],
          "kind": "tuple"
        },
        {
          "fields": [
            {
              "kind": "integer",
              "sign": false,
              "value": "0000000000000000000000000000000000000000000000000000000000000000"
            },
            { "kind": "string", "value": "UintNote" },
            {
              "fields": [
                {
                  "name": "owner",
                  "value": {
                    "fields": [
                      {
                        "name": "index",
                        "value": {
                          "kind": "integer",
                          "sign": false,
                          "value": "0000000000000000000000000000000000000000000000000000000000000000"
                        }
                      },
                      { "name": "nullable", "value": { "kind": "boolean", "value": false } }
                    ],
                    "kind": "struct"
                  }
                },
                {
                  "name": "randomness",
                  "value": {
                    "fields": [
                      {
                        "name": "index",
                        "value": {
                          "kind": "integer",
                          "sign": false,
                          "value": "0000000000000000000000000000000000000000000000000000000000000001"
                        }
                      },
                      { "name": "nullable", "value": { "kind": "boolean", "value": false } }
                    ],
                    "kind": "struct"
                  }
                },
                {
                  "name": "value",
                  "value": {
                    "fields": [
                      {
                        "name": "index",
                        "value": {
                          "kind": "integer",
                          "sign": false,
                          "value": "0000000000000000000000000000000000000000000000000000000000000002"
                        }
                      },
                      { "name": "nullable", "value": { "kind": "boolean", "value": false } }
                    ],
                    "kind": "struct"
                  }
                }
              ],
              "kind": "struct"
            }
          ],
          "kind": "tuple"
        },
        {
          "fields": [
            {
              "kind": "integer",
              "sign": false,
              "value": "0000000000000000000000000000000000000000000000000000000000000000"
            },
            { "kind": "string", "value": "UintNote" },
            {
              "fields": [
                {
                  "name": "owner",
                  "value": {
                    "fields": [
                      {
                        "name": "index",
                        "value": {
                          "kind": "integer",
                          "sign": false,
                          "value": "0000000000000000000000000000000000000000000000000000000000000000"
                        }
                      },
                      { "name": "nullable", "value": { "kind": "boolean", "value": false } }
                    ],
                    "kind": "struct"
                  }
                },
                {
                  "name": "randomness",
                  "value": {
                    "fields": [
                      {
                        "name": "index",
                        "value": {
                          "kind": "integer",
                          "sign": false,
                          "value": "0000000000000000000000000000000000000000000000000000000000000001"
                        }
                      },
                      { "name": "nullable", "value": { "kind": "boolean", "value": false } }
                    ],
                    "kind": "struct"
                  }
                },
                {
                  "name": "value",
                  "value": {
                    "fields": [
                      {
                        "name": "index",
                        "value": {
                          "kind": "integer",
                          "sign": false,
                          "value": "0000000000000000000000000000000000000000000000000000000000000002"
                        }
                      },
                      { "name": "nullable", "value": { "kind": "boolean", "value": false } }
                    ],
                    "kind": "struct"
                  }
                }
              ],
              "kind": "struct"
            }
          ],
          "kind": "tuple"
        }
      ],
      "storage": [
        {
          "fields": [
            { "name": "contract_name", "value": { "kind": "string", "value": "Token" } },
            {
              "name": "fields",
              "value": {
                "fields": [
                  {
                    "name": "admin",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000001"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  },
                  {
                    "name": "minters",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000002"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  },
                  {
                    "name": "balances",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000003"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  },
                  {
                    "name": "total_supply",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000004"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  },
                  {
                    "name": "public_balances",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000005"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  },
                  {
                    "name": "symbol",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000006"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  },
                  {
                    "name": "name",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000008"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  },
                  {
                    "name": "decimals",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "000000000000000000000000000000000000000000000000000000000000000a"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  }
                ],
                "kind": "struct"
              }
            }
          ],
          "kind": "struct"
        },
        {
          "fields": [
            { "name": "contract_name", "value": { "kind": "string", "value": "Crowdfunding" } },
            {
              "name": "fields",
              "value": {
                "fields": [
                  {
                    "name": "config",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000001"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  },
                  {
                    "name": "donation_receipts",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000005"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  }
                ],
                "kind": "struct"
              }
            }
          ],
          "kind": "struct"
        },
        {
          "fields": [
            { "name": "contract_name", "value": { "kind": "string", "value": "Claim" } },
            {
              "name": "fields",
              "value": {
                "fields": [
                  {
                    "name": "target_contract",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000001"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  },
                  {
                    "name": "reward_token",
                    "value": {
                      "fields": [
                        {
                          "name": "slot",
                          "value": {
                            "kind": "integer",
                            "sign": false,
                            "value": "0000000000000000000000000000000000000000000000000000000000000003"
                          }
                        }
                      ],
                      "kind": "struct"
                    }
                  }
                ],
                "kind": "struct"
              }
            }
          ],
          "kind": "struct"
        }
      ]
    },
    "structs": {
      "functions": [
        {
          "fields": [
            {
              "name": "parameters",
              "type": {
                "fields": [],
                "kind": "struct",
                "path": "Claim::sync_private_state_parameters"
              }
            }
          ],
          "kind": "struct",
          "path": "Claim::sync_private_state_abi"
        }
      ]
    }
  },
  "file_map": {
    "100": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/messages/discovery/mod.nr",
      "source": "use protocol_types::{address::AztecAddress, debug_log::debug_log};\n\npub mod nonce_discovery;\npub mod partial_notes;\npub mod pending_tagged_log;\npub mod private_logs;\npub mod private_notes;\n\nuse private_notes::MAX_NOTE_PACKED_LEN;\n\npub struct NoteHashAndNullifier {\n    /// The result of NoteHash::compute_note_hash\n    pub note_hash: Field,\n    /// The result of NoteHash::compute_nullifier_unconstrained (since all of message discovery is unconstrained)\n    pub inner_nullifier: Field,\n}\n\n/// A function which takes a note's packed content, address of the emitting contract, nonce, storage slot and note type\n/// ID and attempts to compute its note hash (not siloed by nonce nor address) and inner nullifier (not siloed by\n/// address).\n///\n/// This function must be user-provided as its implementation requires knowledge of how note type IDs are allocated in a\n/// contract. The `#[aztec]` macro automatically creates such a contract library method called\n/// `_compute_note_hash_and_nullifier`, which looks something like this:\n///\n/// ```\n/// |packed_note, contract_address, nonce, storage_slot, note_type_id| {\n///     if note_type_id == MyNoteType::get_id() {\n///         assert(packed_note.len() == MY_NOTE_TYPE_SERIALIZATION_LENGTH);\n///\n///         let note = MyNoteType::unpack(aztec::utils::array::subarray(packed_note.storage(), 0));\n///\n///         let note_hash = note.compute_note_hash(storage_slot);\n///         let note_hash_for_nullify = aztec::note::utils::compute_note_hash_for_nullify(\n///             RetrievedNote{ note, contract_address, metadata: SettledNoteMetadata::new(nonce).into() },\n///             storage_slot\n///         );\n///\n///         let inner_nullifier = note.compute_nullifier_unconstrained(note_hash_for_nullify);\n///\n///         Option::some(\n///             aztec::messages::discovery::NoteHashAndNullifier {\n///                 note_hash, inner_nullifier\n///             }\n///         )\n///     } else if note_type_id == MyOtherNoteType::get_id() {\n///           ... // Similar to above but calling MyOtherNoteType::unpack_content\n///     } else {\n///         Option::none() // Unknown note type ID\n///     };\n/// }\n/// ```\ntype ComputeNoteHashAndNullifier<Env> = unconstrained fn[Env](/* packed_note */BoundedVec<Field, MAX_NOTE_PACKED_LEN>, /* storage_slot */ Field, /* note_type_id */ Field, /* contract_address */ AztecAddress, /* nonce */ Field) -> Option<NoteHashAndNullifier>;\n\n/// Performs the message discovery process, in which private are downloaded and inspected to find new private notes,\n/// partial notes and events, etc., and pending partial notes are processed to search for their completion logs.\n/// This is the mechanism via which a contract updates its knowledge of its private state.\n///\n/// Receives the address of the contract on which discovery is performed along with its\n/// `compute_note_hash_and_nullifier` function.\npub unconstrained fn discover_new_messages<Env>(\n    contract_address: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n) {\n    debug_log(\"Performing message discovery\");\n\n    private_logs::fetch_and_process_private_tagged_logs(\n        contract_address,\n        compute_note_hash_and_nullifier,\n    );\n\n    partial_notes::fetch_and_process_public_partial_note_completion_logs(\n        contract_address,\n        compute_note_hash_and_nullifier,\n    );\n}\n"
    },
    "101": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/messages/discovery/nonce_discovery.nr",
      "source": "use crate::messages::discovery::{ComputeNoteHashAndNullifier, private_notes::MAX_NOTE_PACKED_LEN};\n\nuse dep::protocol_types::{\n    address::AztecAddress,\n    constants::MAX_NOTE_HASHES_PER_TX,\n    debug_log::debug_log_format,\n    hash::{compute_note_hash_nonce, compute_siloed_note_hash, compute_unique_note_hash},\n    traits::ToField,\n};\n\n/// A struct with the discovered information of a complete note, required for delivery to PXE. Note that this is *not*\n/// the complete note information, since it does not include content, storage slot, etc.\npub struct DiscoveredNoteInfo {\n    pub nonce: Field,\n    pub note_hash: Field,\n    pub inner_nullifier: Field,\n}\n\n/// Searches for note nonces that will result in a note that was emitted in a transaction. While rare, it is possible\n/// for multiple notes to have the exact same packed content and storage slot but different nonces, resulting in\n/// different unique note hashes. Because of this this function returns a *vector* of discovered notes, though in most\n/// cases it will contain a single element.\n///\n/// Due to how nonces are computed, this function requires knowledge of the transaction in which the note was created,\n/// more specifically the list of all unique note hashes in it plus the value of its first nullifier.\npub unconstrained fn attempt_note_nonce_discovery<Env>(\n    unique_note_hashes_in_tx: BoundedVec<Field, MAX_NOTE_HASHES_PER_TX>,\n    first_nullifier_in_tx: Field,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n    contract_address: AztecAddress,\n    storage_slot: Field,\n    note_type_id: Field,\n    packed_note: BoundedVec<Field, MAX_NOTE_PACKED_LEN>,\n) -> BoundedVec<DiscoveredNoteInfo, MAX_NOTE_HASHES_PER_TX> {\n    let discovered_notes = &mut BoundedVec::new();\n\n    debug_log_format(\n        \"Attempting nonce discovery on {0} potential notes on contract {1} for storage slot {2}\",\n        [unique_note_hashes_in_tx.len() as Field, contract_address.to_field(), storage_slot],\n    );\n\n    // We need to find nonces (typically just one) that result in a note hash that, once siloed into a unique note hash,\n    // is one of the note hashes created by the transaction.\n    unique_note_hashes_in_tx.for_eachi(|i, expected_unique_note_hash| {\n        // Nonces are computed by hashing the first nullifier in the transaction with the index of the note in the\n        // new note hashes array. We therefore know for each note in every transaction what its nonce is.\n        let candidate_nonce = compute_note_hash_nonce(first_nullifier_in_tx, i);\n\n        // Given nonce, note content and metadata, we can compute the note hash and silo it to check if it matches\n        // the note hash at the array index we're currently processing.\n        // TODO(#11157): handle failed note_hash_and_nullifier computation\n        let hashes = compute_note_hash_and_nullifier(\n            packed_note,\n            storage_slot,\n            note_type_id,\n            contract_address,\n            candidate_nonce,\n        )\n            .expect(f\"Failed to compute a note hash for note type {note_type_id}\");\n\n        let siloed_note_hash = compute_siloed_note_hash(contract_address, hashes.note_hash);\n        let unique_note_hash = compute_unique_note_hash(candidate_nonce, siloed_note_hash);\n\n        if unique_note_hash == expected_unique_note_hash {\n            // Note that while we did check that the note hash is the preimage of the expected unique note hash, we\n            // perform no validations on the nullifier - we fundamentally cannot, since only the application knows\n            // how to compute nullifiers. We simply trust it to have provided the correct one: if it hasn't, then\n            // PXE may fail to realize that a given note has been nullified already, and calls to the application\n            // could result in invalid transactions (with duplicate nullifiers). This is not a concern because an\n            // application already has more direct means of making a call to it fail the transaction.\n            discovered_notes.push(\n                DiscoveredNoteInfo {\n                    nonce: candidate_nonce,\n                    note_hash: hashes.note_hash,\n                    inner_nullifier: hashes.inner_nullifier,\n                },\n            );\n\n            // We don't exit the loop - it is possible (though rare) for the exact same note content to be present\n            // multiple times in the same transaction with different nonces. This typically doesn't happen due to\n            // notes containing random values in order to hide their contents.\n        }\n    });\n\n    debug_log_format(\n        \"Discovered a total of {0} notes\",\n        [discovered_notes.len() as Field],\n    );\n\n    *discovered_notes\n}\n\nmod test {\n    use crate::{\n        messages::discovery::{NoteHashAndNullifier, private_notes::MAX_NOTE_PACKED_LEN},\n        note::{\n            note_interface::{NoteHash, NoteType},\n            note_metadata::SettledNoteMetadata,\n            retrieved_note::RetrievedNote,\n            utils::compute_note_hash_for_nullify,\n        },\n        oracle::random::random,\n        test::mocks::mock_note::MockNote,\n        utils::array,\n    };\n\n    use dep::protocol_types::{\n        address::AztecAddress,\n        hash::{compute_note_hash_nonce, compute_siloed_note_hash, compute_unique_note_hash},\n        traits::{FromField, Packable},\n    };\n\n    use super::attempt_note_nonce_discovery;\n\n    // This implementation could be simpler, but this serves as a nice example of the expected flow in a real\n    // implementation, and as a sanity check that the interface is sufficient.\n    unconstrained fn compute_note_hash_and_nullifier(\n        packed_note: BoundedVec<Field, MAX_NOTE_PACKED_LEN>,\n        storage_slot: Field,\n        note_type_id: Field,\n        contract_address: AztecAddress,\n        nonce: Field,\n    ) -> Option<NoteHashAndNullifier> {\n        if note_type_id == MockNote::get_id() {\n            let note = MockNote::unpack(array::subarray(packed_note.storage(), 0));\n            let note_hash = note.compute_note_hash(storage_slot);\n\n            let note_hash_for_nullify = compute_note_hash_for_nullify(\n                RetrievedNote {\n                    note,\n                    contract_address,\n                    metadata: SettledNoteMetadata::new(nonce).into(),\n                },\n                storage_slot,\n            );\n\n            let inner_nullifier = note.compute_nullifier_unconstrained(note_hash_for_nullify);\n\n            Option::some(NoteHashAndNullifier { note_hash, inner_nullifier })\n        } else {\n            Option::none()\n        }\n    }\n\n    global VALUE: Field = 7;\n    global FIRST_NULLIFIER_IN_TX: Field = 47;\n    global CONTRACT_ADDRESS: AztecAddress = AztecAddress::from_field(13);\n    global STORAGE_SLOT: Field = 99;\n\n    #[test]\n    unconstrained fn no_note_hashes() {\n        let unique_note_hashes_in_tx = BoundedVec::new();\n        let packed_note = BoundedVec::new();\n\n        let discovered_notes = attempt_note_nonce_discovery(\n            unique_note_hashes_in_tx,\n            FIRST_NULLIFIER_IN_TX,\n            compute_note_hash_and_nullifier,\n            CONTRACT_ADDRESS,\n            STORAGE_SLOT,\n            MockNote::get_id(),\n            packed_note,\n        );\n\n        assert_eq(discovered_notes.len(), 0);\n    }\n\n    #[test(should_fail_with = \"Failed to compute a note hash\")]\n    unconstrained fn failed_hash_computation() {\n        let unique_note_hashes_in_tx = BoundedVec::from_array([random()]);\n        let packed_note = BoundedVec::new();\n        let note_type_id = 0; // This note type id is unknown to compute_note_hash_and_nullifier\n\n        let discovered_notes = attempt_note_nonce_discovery(\n            unique_note_hashes_in_tx,\n            FIRST_NULLIFIER_IN_TX,\n            compute_note_hash_and_nullifier,\n            CONTRACT_ADDRESS,\n            STORAGE_SLOT,\n            note_type_id,\n            packed_note,\n        );\n\n        assert_eq(discovered_notes.len(), 0);\n    }\n\n    struct NoteAndData {\n        note: MockNote,\n        nonce: Field,\n        note_hash: Field,\n        unique_note_hash: Field,\n        inner_nullifier: Field,\n    }\n\n    unconstrained fn construct_note(value: Field, note_index_in_tx: u32) -> NoteAndData {\n        let nonce = compute_note_hash_nonce(FIRST_NULLIFIER_IN_TX, note_index_in_tx);\n\n        let retrieved_note = MockNote::new(value)\n            .contract_address(CONTRACT_ADDRESS)\n            .note_metadata(SettledNoteMetadata::new(nonce).into())\n            .build_retrieved_note();\n        let note = retrieved_note.note;\n\n        let note_hash = note.compute_note_hash(STORAGE_SLOT);\n        let unique_note_hash =\n            compute_unique_note_hash(nonce, compute_siloed_note_hash(CONTRACT_ADDRESS, note_hash));\n        let inner_nullifier = note.compute_nullifier_unconstrained(compute_note_hash_for_nullify(\n            retrieved_note,\n            STORAGE_SLOT,\n        ));\n\n        NoteAndData { note, nonce, note_hash, unique_note_hash, inner_nullifier }\n    }\n\n    #[test]\n    unconstrained fn single_note() {\n        let note_index_in_tx = 2;\n        let note_and_data = construct_note(VALUE, note_index_in_tx);\n\n        let mut unique_note_hashes_in_tx = BoundedVec::from_array([\n            random(), random(), random(), random(), random(), random(), random(),\n        ]);\n        unique_note_hashes_in_tx.set(note_index_in_tx, note_and_data.unique_note_hash);\n\n        let discovered_notes = attempt_note_nonce_discovery(\n            unique_note_hashes_in_tx,\n            FIRST_NULLIFIER_IN_TX,\n            compute_note_hash_and_nullifier,\n            CONTRACT_ADDRESS,\n            STORAGE_SLOT,\n            MockNote::get_id(),\n            BoundedVec::from_array(note_and_data.note.pack()),\n        );\n\n        assert_eq(discovered_notes.len(), 1);\n        let discovered_note = discovered_notes.get(0);\n\n        assert_eq(discovered_note.nonce, note_and_data.nonce);\n        assert_eq(discovered_note.note_hash, note_and_data.note_hash);\n        assert_eq(discovered_note.inner_nullifier, note_and_data.inner_nullifier);\n    }\n\n    #[test]\n    unconstrained fn multiple_notes_same_preimage() {\n        let first_note_index_in_tx = 3;\n        let first_note_and_data = construct_note(VALUE, first_note_index_in_tx);\n\n        let second_note_index_in_tx = 5;\n        let second_note_and_data = construct_note(VALUE, second_note_index_in_tx);\n\n        // Both notes have the same preimage (and therefore packed representation), so both should be found in the same\n        // call.\n        assert_eq(first_note_and_data.note, second_note_and_data.note);\n        let packed_note = first_note_and_data.note.pack();\n\n        let mut unique_note_hashes_in_tx = BoundedVec::from_array([\n            random(), random(), random(), random(), random(), random(), random(),\n        ]);\n        unique_note_hashes_in_tx.set(first_note_index_in_tx, first_note_and_data.unique_note_hash);\n        unique_note_hashes_in_tx.set(second_note_index_in_tx, second_note_and_data.unique_note_hash);\n\n        let discovered_notes = attempt_note_nonce_discovery(\n            unique_note_hashes_in_tx,\n            FIRST_NULLIFIER_IN_TX,\n            compute_note_hash_and_nullifier,\n            CONTRACT_ADDRESS,\n            STORAGE_SLOT,\n            MockNote::get_id(),\n            BoundedVec::from_array(packed_note),\n        );\n\n        assert_eq(discovered_notes.len(), 2);\n\n        assert(discovered_notes.any(|discovered_note| {\n            (discovered_note.nonce == first_note_and_data.nonce)\n                & (discovered_note.note_hash == first_note_and_data.note_hash)\n                & (discovered_note.inner_nullifier == first_note_and_data.inner_nullifier)\n        }));\n\n        assert(discovered_notes.any(|discovered_note| {\n            (discovered_note.nonce == second_note_and_data.nonce)\n                & (discovered_note.note_hash == second_note_and_data.note_hash)\n                & (discovered_note.inner_nullifier == second_note_and_data.inner_nullifier)\n        }));\n    }\n}\n"
    },
    "102": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/messages/discovery/partial_notes.nr",
      "source": "use crate::{\n    capsules::CapsuleArray,\n    messages::{\n        discovery::{ComputeNoteHashAndNullifier, nonce_discovery::attempt_note_nonce_discovery},\n        encoding::MAX_MESSAGE_CONTENT_LEN,\n    },\n    oracle::message_discovery::{deliver_note, get_log_by_tag},\n    utils::array,\n};\n\nuse dep::protocol_types::{\n    address::AztecAddress,\n    constants::PUBLIC_LOG_SIZE_IN_FIELDS,\n    debug_log::debug_log_format,\n    hash::sha256_to_field,\n    traits::{Deserialize, Serialize, ToField},\n};\n\nglobal PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN: u32 = 2;\n\n/// Partial notes have a maximum packed length of their private fields bound by extra content in their private message\n/// (e.g. the storage slot, note completion log tag, etc.).\npub global MAX_PARTIAL_NOTE_PRIVATE_PACKED_LEN: u32 =\n    MAX_MESSAGE_CONTENT_LEN - PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN;\n\n/// The slot in the PXE capsules where we store a `CapsuleArray` of `DeliveredPendingPartialNote`.\npub global DELIVERED_PENDING_PARTIAL_NOTE_ARRAY_LENGTH_CAPSULES_SLOT: Field = sha256_to_field(\n    \"AZTEC_NR::DELIVERED_PENDING_PARTIAL_NOTE_ARRAY_LENGTH_CAPSULES_SLOT\".as_bytes(),\n);\n\n/// Public logs contain an extra field at the beginning with the address of the contract that emitted them, and partial\n/// notes emit their completion tag in the log, resulting in the first two fields in the public log not being part of\n/// the packed public content.\n// TODO(#10273): improve how contract log siloing is handled\npub global NON_PACKED_CONTENT_FIELDS_IN_PUBLIC_LOG: u32 = 2;\n\n/// The maximum length of the packed representation of public fields in a partial note. This is limited by public log\n/// size and extra fields in the log (e.g. the tag).\npub global MAX_PUBLIC_PARTIAL_NOTE_PACKED_CONTENT_LENGTH: u32 =\n    PUBLIC_LOG_SIZE_IN_FIELDS - NON_PACKED_CONTENT_FIELDS_IN_PUBLIC_LOG;\n\n/// A partial note that was delivered but is still pending completion. Contains the information necessary to find the\n/// log that will complete it and lead to a note being discovered and delivered.\n#[derive(Serialize, Deserialize)]\npub(crate) struct DeliveredPendingPartialNote {\n    pub(crate) note_completion_log_tag: Field,\n    pub(crate) storage_slot: Field,\n    pub(crate) note_type_id: Field,\n    pub(crate) packed_private_note_content: BoundedVec<Field, MAX_PARTIAL_NOTE_PRIVATE_PACKED_LEN>,\n    pub(crate) recipient: AztecAddress,\n}\n\npub unconstrained fn process_partial_note_private_msg(\n    contract_address: AztecAddress,\n    recipient: AztecAddress,\n    msg_metadata: u64,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n) {\n    let (note_type_id, storage_slot, note_completion_log_tag, packed_private_note_content) =\n        decode_partial_note_private_msg(msg_metadata, msg_content);\n\n    // We store the information of the partial note we found in a persistent capsule in PXE, so that we can later search\n    // for the public log that will complete it.\n    let pending = DeliveredPendingPartialNote {\n        note_completion_log_tag,\n        storage_slot,\n        note_type_id,\n        packed_private_note_content,\n        recipient,\n    };\n\n    CapsuleArray::at(\n        contract_address,\n        DELIVERED_PENDING_PARTIAL_NOTE_ARRAY_LENGTH_CAPSULES_SLOT,\n    )\n        .push(pending);\n}\n\n/// Searches for public logs that would result in the completion of pending partial notes, ultimately resulting in the\n/// notes being delivered to PXE if completed.\npub unconstrained fn fetch_and_process_public_partial_note_completion_logs<Env>(\n    contract_address: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n) {\n    let pending_partial_notes = CapsuleArray::at(\n        contract_address,\n        DELIVERED_PENDING_PARTIAL_NOTE_ARRAY_LENGTH_CAPSULES_SLOT,\n    );\n\n    debug_log_format(\n        \"{} pending partial notes\",\n        [pending_partial_notes.len() as Field],\n    );\n\n    pending_partial_notes.for_each(|i, pending_partial_note: DeliveredPendingPartialNote| {\n        let maybe_log = get_log_by_tag(pending_partial_note.note_completion_log_tag);\n        if maybe_log.is_none() {\n            debug_log_format(\n                \"Found no completion logs for partial note with tag {}\",\n                [pending_partial_note.note_completion_log_tag],\n            );\n\n            // Note that we're not removing the pending partial note from the capsule array, so we will continue\n            // searching for this tagged log when performing message discovery in the future until we either find it or\n            // the entry is somehow removed from the array.\n        } else {\n            debug_log_format(\n                \"Completion log found for partial note with tag {}\",\n                [pending_partial_note.note_completion_log_tag],\n            );\n            let log = maybe_log.unwrap();\n\n            // Public logs have an extra field at the beginning with the contract address, which we use to verify\n            // that we're getting the logs from the expected contract.\n            // TODO(#10273): improve how contract log siloing is handled\n            assert_eq(\n                log.log_content.get(0),\n                contract_address.to_field(),\n                \"Got a public log emitted by a different contract\",\n            );\n\n            // Public fields are assumed to all be placed at the end of the packed representation, so we combine the\n            // private and public packed fields (i.e. the contents of the private message and public log sans the extra\n            // fields) to get the complete packed content.\n            let packed_public_note_content: BoundedVec<_, MAX_PUBLIC_PARTIAL_NOTE_PACKED_CONTENT_LENGTH> =\n                array::subbvec(log.log_content, NON_PACKED_CONTENT_FIELDS_IN_PUBLIC_LOG);\n            let complete_packed_note = array::append(\n                pending_partial_note.packed_private_note_content,\n                packed_public_note_content,\n            );\n\n            let discovered_notes = attempt_note_nonce_discovery(\n                log.unique_note_hashes_in_tx,\n                log.first_nullifier_in_tx,\n                compute_note_hash_and_nullifier,\n                contract_address,\n                pending_partial_note.storage_slot,\n                pending_partial_note.note_type_id,\n                complete_packed_note,\n            );\n\n            debug_log_format(\n                \"Discovered {0} notes for partial note with tag {1}\",\n                [discovered_notes.len() as Field, pending_partial_note.note_completion_log_tag],\n            );\n\n            discovered_notes.for_each(|discovered_note| {\n                // TODO:(#10728): decide how to handle notes that fail delivery. This could be due to e.g. a\n                // temporary node connectivity issue - is simply throwing good enough here?\n                assert(\n                    deliver_note(\n                        contract_address,\n                        pending_partial_note.storage_slot,\n                        discovered_note.nonce,\n                        complete_packed_note,\n                        discovered_note.note_hash,\n                        discovered_note.inner_nullifier,\n                        log.tx_hash,\n                        pending_partial_note.recipient,\n                    ),\n                    \"Failed to deliver note\",\n                );\n            });\n\n            // Because there is only a single log for a given tag, once we've processed the tagged log then we\n            // simply delete the pending work entry, regardless of whether it was actually completed or not.\n            // TODO(#11627): only remove the pending entry if we actually process a log that results in the note\n            // being completed.\n            pending_partial_notes.remove(i);\n        }\n    });\n}\n\nfn decode_partial_note_private_msg(\n    msg_metadata: u64,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n) -> (Field, Field, Field, BoundedVec<Field, MAX_PARTIAL_NOTE_PRIVATE_PACKED_LEN>) {\n    let note_type_id = msg_metadata as Field; // TODO: make note type id not be a full field\n\n    assert(\n        msg_content.len() > PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN,\n        f\"Invalid private note message: all partial note private messages must have at least {PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN} fields\",\n    );\n\n    // If PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN is changed, causing the assertion below to fail, then the\n    // destructuring of the partial note private message encoding below must be updated as well.\n    std::static_assert(\n        PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN == 2,\n        \"unexpected value for PARTIAL_NOTE_PRIVATE_MSG_CONTENT_NON_NOTE_FIELDS_LEN\",\n    );\n\n    // We currently have two fields that are not the partial note's packed representation, which are the storage slot\n    // and the note completion log tag.\n    let storage_slot = msg_content.get(0);\n    let note_completion_log_tag = msg_content.get(1);\n\n    let packed_private_note_content = array::subbvec(msg_content, 2);\n\n    (note_type_id, storage_slot, note_completion_log_tag, packed_private_note_content)\n}\n"
    },
    "104": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/messages/discovery/private_logs.nr",
      "source": "use crate::{\n    capsules::CapsuleArray,\n    messages::{\n        discovery::{\n            ComputeNoteHashAndNullifier,\n            partial_notes::process_partial_note_private_msg,\n            pending_tagged_log::{PENDING_TAGGED_LOG_ARRAY_BASE_SLOT, PendingTaggedLog},\n            private_notes::process_private_note_msg,\n        },\n        encoding::decode_message,\n        encryption::{aes128::AES128, log_encryption::LogEncryption},\n        msg_type::{\n            PARTIAL_NOTE_PRIVATE_MSG_TYPE_ID, PRIVATE_EVENT_MSG_TYPE_ID, PRIVATE_NOTE_MSG_TYPE_ID,\n        },\n    },\n    oracle::{logs::store_private_event_log, message_discovery::sync_private_state},\n    utils::array,\n};\n\nuse protocol_types::{\n    abis::event_selector::EventSelector,\n    address::AztecAddress,\n    debug_log::{debug_log, debug_log_format},\n    traits::FromField,\n};\n\n/// Searches for private logs that signal new private notes that are then delivered to PXE, or new partial notes that\n/// are stored in the PXE capsules so that `fetch_and_process_public_partial_note_completion_logs` can later search for\n/// public logs that will complete them.\npub unconstrained fn fetch_and_process_private_tagged_logs<Env>(\n    contract_address: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n) {\n    // We will eventually perform log discovery via tagging here, but for now we simply call the `syncPrivateState` oracle.\n    // This makes PXE synchronize tags, download logs and store the pending tagged logs in capsule array which are then\n    // retrieved and processed here.\n    sync_private_state(PENDING_TAGGED_LOG_ARRAY_BASE_SLOT);\n\n    // Get the logs from the capsule array and process them one by one\n    let logs =\n        CapsuleArray::<PendingTaggedLog>::at(contract_address, PENDING_TAGGED_LOG_ARRAY_BASE_SLOT);\n    logs.for_each(|i, log: PendingTaggedLog| {\n        process_log(contract_address, compute_note_hash_and_nullifier, log);\n        logs.remove(i);\n    });\n}\n\n/// Processes a log's ciphertext by decrypting it and then searching the plaintext for private notes or partial notes.\n///\n/// Private notes result in nonce discovery being performed prior to delivery, which requires knowledge of the\n/// transaction hash in which the notes would've been created (typically the same transaction in which the log was\n/// emitted), along with the list of unique note hashes in said transaction and the `compute_note_hash_and_nullifier`\n/// function.\n///\n/// Partial notes result in a pending partial note entry being stored in a PXE capsule, which will later be retrieved to\n/// search for the note's completion public log.\nunconstrained fn process_log<Env>(\n    contract_address: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n    pending_tagged_log: PendingTaggedLog,\n) {\n    debug_log_format(\n        \"Processing log with tag {0}\",\n        [pending_tagged_log.log.get(0)],\n    );\n\n    // The tag is ignored for now.\n    let ciphertext = array::subbvec(pending_tagged_log.log, 1);\n\n    let log_plaintext = AES128::decrypt_log(ciphertext, pending_tagged_log.recipient);\n\n    // The first thing to do after decrypting the log is to determine what type of private log we're processing. We\n    // have 3 log types: private note logs, partial note logs and event logs.\n\n    let (msg_type_id, msg_metadata, msg_content) = decode_message(log_plaintext);\n\n    if msg_type_id == PRIVATE_NOTE_MSG_TYPE_ID {\n        debug_log(\"Processing private note msg\");\n\n        process_private_note_msg(\n            contract_address,\n            pending_tagged_log.tx_hash,\n            pending_tagged_log.unique_note_hashes_in_tx,\n            pending_tagged_log.first_nullifier_in_tx,\n            pending_tagged_log.recipient,\n            compute_note_hash_and_nullifier,\n            msg_metadata,\n            msg_content,\n        );\n    } else if msg_type_id == PARTIAL_NOTE_PRIVATE_MSG_TYPE_ID {\n        debug_log(\"Processing partial note private msg\");\n\n        process_partial_note_private_msg(\n            contract_address,\n            pending_tagged_log.recipient,\n            msg_metadata,\n            msg_content,\n        );\n    } else if msg_type_id == PRIVATE_EVENT_MSG_TYPE_ID {\n        debug_log(\"Processing private event msg\");\n\n        // In the case of events, the msg metadata is the event selector.\n        let event_selector = EventSelector::from_field(msg_metadata as Field);\n\n        store_private_event_log(\n            contract_address,\n            pending_tagged_log.recipient,\n            event_selector,\n            msg_content,\n            pending_tagged_log.tx_hash,\n            pending_tagged_log.log_index_in_tx,\n            pending_tagged_log.tx_index_in_block,\n        );\n    } else {\n        debug_log_format(\"Unknown msg type id {0}\", [msg_type_id as Field]);\n    }\n}\n"
    },
    "105": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/messages/discovery/private_notes.nr",
      "source": "use crate::{\n    messages::{\n        discovery::{ComputeNoteHashAndNullifier, nonce_discovery::attempt_note_nonce_discovery},\n        encoding::MAX_MESSAGE_CONTENT_LEN,\n    },\n    oracle,\n    utils::array,\n};\nuse protocol_types::{\n    address::AztecAddress, constants::MAX_NOTE_HASHES_PER_TX, debug_log::debug_log_format,\n};\n\n/// The number of fields in a private note message content that are not the note's packed representation.\nglobal PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN: u32 = 1;\n\n/// The maximum length of the packed representation of a note's contents. This is limited by private log size,\n/// encryption overhead and extra fields in the message (e.g. message type id, storage slot, etc.).\npub global MAX_NOTE_PACKED_LEN: u32 =\n    MAX_MESSAGE_CONTENT_LEN - PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN;\n\npub unconstrained fn process_private_note_msg<Env>(\n    contract_address: AztecAddress,\n    tx_hash: Field,\n    unique_note_hashes_in_tx: BoundedVec<Field, MAX_NOTE_HASHES_PER_TX>,\n    first_nullifier_in_tx: Field,\n    recipient: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n    msg_metadata: u64,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n) {\n    let (note_type_id, storage_slot, packed_note) =\n        decode_private_note_msg(msg_metadata, msg_content);\n\n    attempt_note_discovery(\n        contract_address,\n        tx_hash,\n        unique_note_hashes_in_tx,\n        first_nullifier_in_tx,\n        recipient,\n        compute_note_hash_and_nullifier,\n        storage_slot,\n        note_type_id,\n        packed_note,\n    );\n}\n\n/// Attempts discovery of a note given information about its contents and the transaction in which it is\n/// suspected the note was created.\npub unconstrained fn attempt_note_discovery<Env>(\n    contract_address: AztecAddress,\n    tx_hash: Field,\n    unique_note_hashes_in_tx: BoundedVec<Field, MAX_NOTE_HASHES_PER_TX>,\n    first_nullifier_in_tx: Field,\n    recipient: AztecAddress,\n    compute_note_hash_and_nullifier: ComputeNoteHashAndNullifier<Env>,\n    storage_slot: Field,\n    note_type_id: Field,\n    packed_note: BoundedVec<Field, MAX_NOTE_PACKED_LEN>,\n) {\n    let discovered_notes = attempt_note_nonce_discovery(\n        unique_note_hashes_in_tx,\n        first_nullifier_in_tx,\n        compute_note_hash_and_nullifier,\n        contract_address,\n        storage_slot,\n        note_type_id,\n        packed_note,\n    );\n\n    debug_log_format(\n        \"Discovered {0} notes from a private message\",\n        [discovered_notes.len() as Field],\n    );\n\n    discovered_notes.for_each(|discovered_note| {\n        // TODO:(#10728): handle notes that fail delivery. This could be due to e.g. a temporary node connectivity\n        // issue, and we should perhaps not have marked the tag index as taken.\n        assert(\n            oracle::message_discovery::deliver_note(\n                contract_address,\n                storage_slot,\n                discovered_note.nonce,\n                packed_note,\n                discovered_note.note_hash,\n                discovered_note.inner_nullifier,\n                tx_hash,\n                recipient,\n            ),\n            \"Failed to deliver note\",\n        );\n    });\n}\n\nfn decode_private_note_msg(\n    msg_metadata: u64,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n) -> (Field, Field, BoundedVec<Field, MAX_NOTE_PACKED_LEN>) {\n    let note_type_id = msg_metadata as Field; // TODO: make note type id not be a full field\n\n    assert(\n        msg_content.len() > PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN,\n        f\"Invalid private note message: all private note messages must have at least {PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN} fields\",\n    );\n\n    // If PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN is changed, causing the assertion below to fail, then the\n    // destructuring of the private note message encoding below must be updated as well.\n    std::static_assert(\n        PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN == 1,\n        \"unexpected value for PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN\",\n    );\n\n    // We currently have a single field that is not the note's packed representation, which is the storage slot.\n    let storage_slot = msg_content.get(0);\n    let packed_note = array::subbvec(msg_content, PRIVATE_NOTE_MSG_CONTENT_NON_NOTE_FIELDS_LEN);\n\n    (note_type_id, storage_slot, packed_note)\n}\n"
    },
    "106": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/messages/encoding.nr",
      "source": "// TODO(#12750): don't make these values assume we're using AES.\nuse crate::{\n    messages::encryption::log_encryption::PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS, utils::array,\n};\n\nglobal MAX_MESSAGE_LEN: u32 = PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS;\n\nglobal MESSAGE_EXPANDED_METADATA_LEN: u32 = 1;\n\n// The standard message layout is composed of:\n//  - an initial field called the 'expanded metadata'\n//  - an arbitrary number of fields following that called the 'message content'\n//\n// ```\n// message: [ msg_expanded_metadata, ...msg_content ]\n// ```\n//\n// The expanded metadata itself is interpreted as a u128, of which:\n//  - the upper 64 bits are the message type id\n//  - the lower 64 bits are called the 'message metadata'\n//\n// ```\n// msg_expanded_metadata: [  msg_type_id    |  msg_metadata  ]\n//                        <---  64 bits --->|<--- 64 bits --->\n// ```\n//\n// The meaning of the message metadata and message content depend on the value of the message type id. Note that there\n// is nothing special about the message metadata, it _can_ be considered part of the content. It just has a different\n// name to make it distinct from the message content given that it is not a full field.\n\n/// The maximum length of a message's content, i.e. not including the expanded message metadata.\npub global MAX_MESSAGE_CONTENT_LEN: u32 = MAX_MESSAGE_LEN - MESSAGE_EXPANDED_METADATA_LEN;\n\n/// Encodes a message following aztec-nr's standard message encoding. This message can later be decoded with\n/// `decode_message` to retrieve the original values.\n///\n/// - The `msg_type` is an identifier that groups types of messages that are all processed the same way, e.g. private\n/// notes or events. Possible values are defined in `aztec::messages::msg_type`.\n/// - The `msg_metadata` and `msg_content` are the values stored in the message, whose meaning depends on the\n///  `msg_type`. The only special thing about `msg_metadata` that separates it from `msg_content` is that it is a u64\n/// instead of a full Field (due to details of how messages are encoded), allowing applications that can fit values into\n/// this smaller variable to achieve higher data efficiency.\npub fn encode_message<let N: u32>(\n    msg_type: u64,\n    msg_metadata: u64,\n    msg_content: [Field; N],\n) -> [Field; (N + MESSAGE_EXPANDED_METADATA_LEN)] {\n    std::static_assert(\n        msg_content.len() <= MAX_MESSAGE_CONTENT_LEN,\n        \"Invalid message content: it must have a length of at most MAX_MESSAGE_CONTENT_LEN\",\n    );\n\n    // If MESSAGE_EXPANDED_METADATA_LEN is changed, causing the assertion below to fail, then the destructuring of\n    // the message encoding below must be updated as well.\n    std::static_assert(\n        MESSAGE_EXPANDED_METADATA_LEN == 1,\n        \"unexpected value for MESSAGE_EXPANDED_METADATA_LEN\",\n    );\n    let mut message: [Field; (N + MESSAGE_EXPANDED_METADATA_LEN)] = std::mem::zeroed();\n\n    message[0] = to_expanded_metadata(msg_type, msg_metadata);\n    for i in 0..msg_content.len() {\n        message[MESSAGE_EXPANDED_METADATA_LEN + i] = msg_content[i];\n    }\n\n    message\n}\n\n/// Decodes a standard aztec-nr message, i.e. one created via `encode_message`, returning the original encoded values.\n///\n/// Note that `encode_message` returns a fixed size array while this function takes a `BoundedVec`: this is because\n/// prior to decoding the message type is unknown, and consequentially not known at compile time. If working with\n/// fixed-size messages, consider using `BoundedVec::from_array` to convert them.\npub unconstrained fn decode_message(\n    message: BoundedVec<Field, MAX_MESSAGE_LEN>,\n) -> (u64, u64, BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>) {\n    assert(\n        message.len() >= MESSAGE_EXPANDED_METADATA_LEN,\n        f\"Invalid message: it must have at least {MESSAGE_EXPANDED_METADATA_LEN} fields\",\n    );\n\n    // If MESSAGE_EXPANDED_METADATA_LEN is changed, causing the assertion below to fail, then the destructuring of\n    // the message encoding below must be updated as well.\n    std::static_assert(\n        MESSAGE_EXPANDED_METADATA_LEN == 1,\n        \"unexpected value for MESSAGE_EXPANDED_METADATA_LEN\",\n    );\n\n    let msg_expanded_metadata = message.get(0);\n    let (msg_type_id, msg_metadata) = from_expanded_metadata(msg_expanded_metadata);\n    let msg_content = array::subbvec(message, MESSAGE_EXPANDED_METADATA_LEN);\n\n    (msg_type_id, msg_metadata, msg_content)\n}\n\nglobal U64_SHIFT_MULTIPLIER: Field = 2.pow_32(64);\n\nfn to_expanded_metadata(msg_type: u64, msg_metadata: u64) -> Field {\n    // We use multiplication instead of bit shifting operations to shift the type bits as bit shift operations are\n    // expensive in circuits.\n    let type_field: Field = (msg_type as Field) * U64_SHIFT_MULTIPLIER;\n    let msg_metadata_field = msg_metadata as Field;\n\n    type_field + msg_metadata_field\n}\n\nfn from_expanded_metadata(input: Field) -> (u64, u64) {\n    input.assert_max_bit_size::<128>();\n    let msg_metadata = (input as u64);\n    let msg_type = ((input - (msg_metadata as Field)) / U64_SHIFT_MULTIPLIER) as u64;\n    // Use division instead of bit shift since bit shifts are expensive in circuits\n    (msg_type, msg_metadata)\n}\n\nmod tests {\n    use crate::utils::array::subarray::subarray;\n    use super::{\n        decode_message, encode_message, from_expanded_metadata, MAX_MESSAGE_CONTENT_LEN,\n        to_expanded_metadata,\n    };\n\n    global U64_MAX: u64 = (2.pow_32(64) - 1) as u64;\n    global U128_MAX: Field = (2.pow_32(128) - 1);\n\n    #[test]\n    unconstrained fn encode_decode_empty_message(msg_type: u64, msg_metadata: u64) {\n        let encoded = encode_message(msg_type, msg_metadata, []);\n        let (decoded_msg_type, decoded_msg_metadata, decoded_msg_content) =\n            decode_message(BoundedVec::from_array(encoded));\n\n        assert_eq(decoded_msg_type, msg_type);\n        assert_eq(decoded_msg_metadata, msg_metadata);\n        assert_eq(decoded_msg_content.len(), 0);\n    }\n\n    #[test]\n    unconstrained fn encode_decode_short_message(\n        msg_type: u64,\n        msg_metadata: u64,\n        msg_content: [Field; MAX_MESSAGE_CONTENT_LEN / 2],\n    ) {\n        let encoded = encode_message(msg_type, msg_metadata, msg_content);\n        let (decoded_msg_type, decoded_msg_metadata, decoded_msg_content) =\n            decode_message(BoundedVec::from_array(encoded));\n\n        assert_eq(decoded_msg_type, msg_type);\n        assert_eq(decoded_msg_metadata, msg_metadata);\n        assert_eq(decoded_msg_content.len(), msg_content.len());\n        assert_eq(subarray(decoded_msg_content.storage(), 0), msg_content);\n    }\n\n    #[test]\n    unconstrained fn encode_decode_full_message(\n        msg_type: u64,\n        msg_metadata: u64,\n        msg_content: [Field; MAX_MESSAGE_CONTENT_LEN],\n    ) {\n        let encoded = encode_message(msg_type, msg_metadata, msg_content);\n        let (decoded_msg_type, decoded_msg_metadata, decoded_msg_content) =\n            decode_message(BoundedVec::from_array(encoded));\n\n        assert_eq(decoded_msg_type, msg_type);\n        assert_eq(decoded_msg_metadata, msg_metadata);\n        assert_eq(decoded_msg_content.len(), msg_content.len());\n        assert_eq(subarray(decoded_msg_content.storage(), 0), msg_content);\n    }\n\n    #[test]\n    unconstrained fn to_expanded_metadata_packing() {\n        // Test case 1: All bits set\n        let packed = to_expanded_metadata(U64_MAX, U64_MAX);\n        let (msg_type, msg_metadata) = from_expanded_metadata(packed);\n        assert_eq(msg_type, U64_MAX);\n        assert_eq(msg_metadata, U64_MAX);\n\n        // Test case 2: Only log type bits set\n        let packed = to_expanded_metadata(U64_MAX, 0);\n        let (msg_type, msg_metadata) = from_expanded_metadata(packed);\n        assert_eq(msg_type, U64_MAX);\n        assert_eq(msg_metadata, 0);\n\n        // Test case 3: Only msg_metadata bits set\n        let packed = to_expanded_metadata(0, U64_MAX);\n        let (msg_type, msg_metadata) = from_expanded_metadata(packed);\n        assert_eq(msg_type, 0);\n        assert_eq(msg_metadata, U64_MAX);\n\n        // Test case 4: No bits set\n        let packed = to_expanded_metadata(0, 0);\n        let (msg_type, msg_metadata) = from_expanded_metadata(packed);\n        assert_eq(msg_type, 0);\n        assert_eq(msg_metadata, 0);\n    }\n\n    #[test]\n    unconstrained fn from_expanded_metadata_packing() {\n        // Test case 1: All bits set\n        let input = U128_MAX as Field;\n        let (msg_type, msg_metadata) = from_expanded_metadata(input);\n        assert_eq(msg_type, U64_MAX);\n        assert_eq(msg_metadata, U64_MAX);\n\n        // Test case 2: Only log type bits set\n        let input = (U128_MAX - U64_MAX as Field);\n        let (msg_type, msg_metadata) = from_expanded_metadata(input);\n        assert_eq(msg_type, U64_MAX);\n        assert_eq(msg_metadata, 0);\n\n        // Test case 3: Only msg_metadata bits set\n        let input = U64_MAX as Field;\n        let (msg_type, msg_metadata) = from_expanded_metadata(input);\n        assert_eq(msg_type, 0);\n        assert_eq(msg_metadata, U64_MAX);\n\n        // Test case 4: No bits set\n        let input = 0;\n        let (msg_type, msg_metadata) = from_expanded_metadata(input);\n        assert_eq(msg_type, 0);\n        assert_eq(msg_metadata, 0);\n    }\n\n    #[test]\n    unconstrained fn to_from_expanded_metadata(original_msg_type: u64, original_msg_metadata: u64) {\n        let packed = to_expanded_metadata(original_msg_type, original_msg_metadata);\n        let (unpacked_msg_type, unpacked_msg_metadata) = from_expanded_metadata(packed);\n\n        assert_eq(original_msg_type, unpacked_msg_type);\n        assert_eq(original_msg_metadata, unpacked_msg_metadata);\n    }\n}\n"
    },
    "107": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/messages/encryption/aes128.nr",
      "source": "use dep::protocol_types::{\n    constants::{GENERATOR_INDEX__SYMMETRIC_KEY, GENERATOR_INDEX__SYMMETRIC_KEY_2},\n    hash::poseidon2_hash_with_separator,\n    point::Point,\n};\n\nuse crate::{\n    keys::{\n        ecdh_shared_secret::derive_ecdh_shared_secret_using_aztec_address,\n        ephemeral::generate_ephemeral_key_pair,\n    },\n    messages::{\n        encryption::log_encryption::{\n            EPH_PK_SIGN_BYTE_SIZE_IN_BYTES, EPH_PK_X_SIZE_IN_FIELDS,\n            HEADER_CIPHERTEXT_SIZE_IN_BYTES, LogEncryption, PRIVATE_LOG_CIPHERTEXT_LEN,\n            PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS,\n        },\n        logs::arithmetic_generics_utils::{\n            get_arr_of_size__log_bytes__from_PT, get_arr_of_size__log_bytes_padding__from_PT,\n        },\n    },\n    oracle::{aes128_decrypt::aes128_decrypt_oracle, shared_secret::get_shared_secret},\n    prelude::AztecAddress,\n    utils::{\n        array,\n        conversion::{\n            bytes_to_fields::{bytes_from_fields, bytes_to_fields},\n            fields_to_bytes::{fields_from_bytes, fields_to_bytes},\n        },\n        point::{get_sign_of_point, point_from_x_coord_and_sign, point_to_bytes},\n        random::get_random_bytes,\n    },\n};\n\nuse std::aes128::aes128_encrypt;\n\nfn extract_close_to_uniformly_random_256_bits_from_ecdh_shared_secret_using_poseidon2(\n    shared_secret: Point,\n) -> [u8; 32] {\n    let rand1: Field = poseidon2_hash_with_separator(\n        [shared_secret.x, shared_secret.y],\n        GENERATOR_INDEX__SYMMETRIC_KEY,\n    );\n    let rand2: Field = poseidon2_hash_with_separator(\n        [shared_secret.x, shared_secret.y],\n        GENERATOR_INDEX__SYMMETRIC_KEY_2,\n    );\n    let rand1_bytes: [u8; 16] = rand1.to_le_bytes();\n    let rand2_bytes: [u8; 16] = rand2.to_le_bytes();\n    let mut bytes: [u8; 32] = [0; 32];\n    for i in 0..16 {\n        bytes[i] = rand1_bytes[i];\n        bytes[i + 1] = rand2_bytes[i];\n    }\n    bytes\n}\n\n// TODO(#10537): Consider nuking this function.\nfn extract_close_to_uniformly_random_256_bits_from_ecdh_shared_secret_using_sha256(\n    shared_secret: Point,\n) -> [u8; 32] {\n    let shared_secret_bytes: [u8; 32] = point_to_bytes(shared_secret);\n\n    let mut shared_secret_bytes_with_separator: [u8; 33] = std::mem::zeroed();\n    for i in 0..shared_secret_bytes.len() {\n        shared_secret_bytes_with_separator[i] = shared_secret_bytes[i];\n    }\n    shared_secret_bytes_with_separator[32] = GENERATOR_INDEX__SYMMETRIC_KEY;\n\n    sha256::digest(shared_secret_bytes_with_separator)\n}\n\nfn derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret(\n    shared_secret: Point,\n    randomness_extraction_fn: fn(Point) -> [u8; 32],\n) -> ([u8; 16], [u8; 16]) {\n    let random_256_bits = randomness_extraction_fn(shared_secret);\n    let mut sym_key = [0; 16];\n    let mut iv = [0; 16];\n    for i in 0..16 {\n        sym_key[i] = random_256_bits[i];\n        iv[i] = random_256_bits[i + 16];\n    }\n    (sym_key, iv)\n}\n\n// TODO(#10537): Consider nuking this function.\npub fn derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret_using_sha256(\n    shared_secret: Point,\n) -> ([u8; 16], [u8; 16]) {\n    derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret(\n        shared_secret,\n        extract_close_to_uniformly_random_256_bits_from_ecdh_shared_secret_using_sha256,\n    )\n}\n\n// TODO(#10537): This function is currently unused. Consider using it instead of the sha256 one.\npub fn derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret_using_poseidon2(\n    shared_secret: Point,\n) -> ([u8; 16], [u8; 16]) {\n    derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret(\n        shared_secret,\n        extract_close_to_uniformly_random_256_bits_from_ecdh_shared_secret_using_poseidon2,\n    )\n}\n\npub struct AES128 {}\n\nimpl LogEncryption for AES128 {\n    fn encrypt_log<let PLAINTEXT_LEN: u32>(\n        plaintext: [Field; PLAINTEXT_LEN],\n        recipient: AztecAddress,\n    ) -> [Field; PRIVATE_LOG_CIPHERTEXT_LEN] {\n        // AES 128 operates on bytes, not fields, so we need to convert the fields to bytes.\n        // (This process is then reversed when processing the log in `do_process_log`)\n        let plaintext_bytes = fields_to_bytes(plaintext);\n\n        // *****************************************************************************\n        // Compute the shared secret\n        // *****************************************************************************\n\n        let (eph_sk, eph_pk) = generate_ephemeral_key_pair();\n\n        let eph_pk_sign_byte: u8 = get_sign_of_point(eph_pk) as u8;\n\n        // (not to be confused with the tagging shared secret)\n        let ciphertext_shared_secret =\n            derive_ecdh_shared_secret_using_aztec_address(eph_sk, recipient);\n\n        // TODO: also use this shared secret for deriving note randomness.\n\n        // *****************************************************************************\n        // Convert the plaintext into whatever format the encryption function expects\n        // *****************************************************************************\n\n        // Already done for this strategy: AES expects bytes.\n\n        // *****************************************************************************\n        // Encrypt the plaintext\n        // *****************************************************************************\n\n        let (sym_key, iv) = derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret_using_sha256(\n            ciphertext_shared_secret,\n        );\n\n        let ciphertext_bytes = aes128_encrypt(plaintext_bytes, iv, sym_key);\n\n        // |full_pt| = |pt_length| + |pt|\n        // |pt_aes_padding| = 16 - (|full_pt| % 16)\n        // or... since a % b is the same as a - b * (a // b) (integer division), so:\n        // |pt_aes_padding| = 16 - (|full_pt| - 16 * (|full_pt| // 16))\n        // |ct| = |full_pt| + |pt_aes_padding|\n        //      = |full_pt| + 16 - (|full_pt| - 16 * (|full_pt| // 16))\n        //      = 16 + 16 * (|full_pt| // 16)\n        //      = 16 * (1 + |full_pt| // 16)\n        assert(ciphertext_bytes.len() == 16 * (1 + (PLAINTEXT_LEN * 32) / 16));\n\n        // *****************************************************************************\n        // Compute the header ciphertext\n        // *****************************************************************************\n\n        // Header contains only the length of the ciphertext stored in 2 bytes.\n        // TODO: consider nuking the header altogether and just have a fixed-size ciphertext by padding the plaintext.\n        // This would be more costly constraint-wise but cheaper DA-wise.\n        let mut header_plaintext: [u8; 2] = [0 as u8; 2];\n        let ciphertext_bytes_length = ciphertext_bytes.len();\n        header_plaintext[0] = (ciphertext_bytes_length >> 8) as u8;\n        header_plaintext[1] = ciphertext_bytes_length as u8;\n\n        // TODO: this is insecure and wasteful:\n        // \"Insecure\", because the esk shouldn't be used twice (once for the header,\n        // and again for the proper ciphertext) (at least, I never got the\n        // \"go ahead\" that this would be safe, unfortunately).\n        // \"Wasteful\", because the exact same computation is happening further down.\n        // I'm leaving that 2nd computation where it is, because this 1st computation\n        // will be imminently deleted, when the header logic is deleted.\n        let (sym_key, iv) = derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret_using_sha256(\n            ciphertext_shared_secret,\n        );\n\n        // Note: the aes128_encrypt builtin fn automatically appends bytes to the\n        // input, according to pkcs#7; hence why the output `header_ciphertext_bytes` is 16\n        // bytes larger than the input in this case.\n        let header_ciphertext_bytes = aes128_encrypt(header_plaintext, iv, sym_key);\n        // I recall that converting a slice to an array incurs constraints, so I'll check the length this way instead:\n        assert(header_ciphertext_bytes.len() == HEADER_CIPHERTEXT_SIZE_IN_BYTES);\n\n        // *****************************************************************************\n        // Prepend / append more bytes of data to the ciphertext, before converting back\n        // to fields.\n        // *****************************************************************************\n\n        let mut log_bytes_padding_to_mult_31 =\n            get_arr_of_size__log_bytes_padding__from_PT::<PLAINTEXT_LEN * 32>();\n        // Safety: this randomness won't be constrained to be random. It's in the\n        // interest of the executor of this fn to encrypt with random bytes.\n        log_bytes_padding_to_mult_31 = unsafe { get_random_bytes() };\n\n        let mut log_bytes = get_arr_of_size__log_bytes__from_PT::<PLAINTEXT_LEN * 32>();\n\n        assert(\n            log_bytes.len() % 31 == 0,\n            \"Unexpected error: log_bytes.len() should be divisible by 31, by construction.\",\n        );\n\n        log_bytes[0] = eph_pk_sign_byte;\n        let mut offset = 1;\n        for i in 0..header_ciphertext_bytes.len() {\n            log_bytes[offset + i] = header_ciphertext_bytes[i];\n        }\n        offset += header_ciphertext_bytes.len();\n\n        for i in 0..ciphertext_bytes.len() {\n            log_bytes[offset + i] = ciphertext_bytes[i];\n        }\n        offset += ciphertext_bytes.len();\n\n        for i in 0..log_bytes_padding_to_mult_31.len() {\n            log_bytes[offset + i] = log_bytes_padding_to_mult_31[i];\n        }\n\n        assert(\n            offset + log_bytes_padding_to_mult_31.len() == log_bytes.len(),\n            \"Something has gone wrong\",\n        );\n\n        // *****************************************************************************\n        // Convert bytes back to fields\n        // *****************************************************************************\n\n        // TODO(#12749): As Mike pointed out, we need to make logs produced by different encryption schemes\n        // indistinguishable from each other and for this reason the output here and in the last for-loop of this function\n        // should cover a full field.\n        let log_bytes_as_fields = bytes_to_fields(log_bytes);\n\n        // *****************************************************************************\n        // Prepend / append fields, to create the final log\n        // *****************************************************************************\n\n        let mut ciphertext: [Field; PRIVATE_LOG_CIPHERTEXT_LEN] = [0; PRIVATE_LOG_CIPHERTEXT_LEN];\n\n        ciphertext[0] = eph_pk.x;\n\n        let mut offset = 1;\n        for i in 0..log_bytes_as_fields.len() {\n            ciphertext[offset + i] = log_bytes_as_fields[i];\n        }\n        offset += log_bytes_as_fields.len();\n\n        for i in offset..PRIVATE_LOG_CIPHERTEXT_LEN {\n            // We need to get a random value that fits in 31 bytes to not leak information about the size of the log\n            // (all the \"real\" log fields contain at most 31 bytes because of the way we convert the bytes to fields).\n            // TODO(#12749): Long term, this is not a good solution.\n\n            // Safety: we assume that the sender wants for the log to be private - a malicious one could simply reveal its\n            // contents publicly. It is therefore fine to trust the sender to provide random padding.\n            let field_bytes = unsafe { get_random_bytes::<31>() };\n            ciphertext[i] = Field::from_be_bytes::<31>(field_bytes);\n        }\n\n        ciphertext\n    }\n\n    unconstrained fn decrypt_log(\n        ciphertext: BoundedVec<Field, PRIVATE_LOG_CIPHERTEXT_LEN>,\n        recipient: AztecAddress,\n    ) -> BoundedVec<Field, PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS> {\n        let eph_pk_x = ciphertext.get(0);\n\n        let ciphertext_without_eph_pk_x_fields = array::subbvec::<Field, PRIVATE_LOG_CIPHERTEXT_LEN, PRIVATE_LOG_CIPHERTEXT_LEN - EPH_PK_X_SIZE_IN_FIELDS>(\n            ciphertext,\n            EPH_PK_X_SIZE_IN_FIELDS,\n        );\n\n        // Convert the ciphertext represented as fields to a byte representation (its original format)\n        let ciphertext_without_eph_pk_x = bytes_from_fields(ciphertext_without_eph_pk_x_fields);\n\n        // First byte of the ciphertext represents the ephemeral public key sign\n        let eph_pk_sign_bool = ciphertext_without_eph_pk_x.get(0) as bool;\n        // With the sign and the x-coordinate of the ephemeral public key, we can reconstruct the point\n        let eph_pk = point_from_x_coord_and_sign(eph_pk_x, eph_pk_sign_bool);\n\n        // Derive shared secret and symmetric key\n        let ciphertext_shared_secret = get_shared_secret(recipient, eph_pk);\n        let (sym_key, iv) = derive_aes_symmetric_key_and_iv_from_ecdh_shared_secret_using_sha256(\n            ciphertext_shared_secret,\n        );\n\n        // Extract the header ciphertext\n        let header_start = EPH_PK_SIGN_BYTE_SIZE_IN_BYTES; // Skip eph_pk_sign byte\n        let header_ciphertext: [u8; HEADER_CIPHERTEXT_SIZE_IN_BYTES] =\n            array::subarray(ciphertext_without_eph_pk_x.storage(), header_start);\n        // We need to convert the array to a BoundedVec because the oracle expects a BoundedVec as it's designed to work\n        // with logs with unknown length at compile time. This would not be necessary here as the header ciphertext length\n        // is fixed. But we do it anyway to not have to have duplicate oracles.\n        let header_ciphertext_bvec =\n            BoundedVec::<u8, HEADER_CIPHERTEXT_SIZE_IN_BYTES>::from_array(header_ciphertext);\n\n        // Decrypt header\n        let header_plaintext = aes128_decrypt_oracle(header_ciphertext_bvec, iv, sym_key);\n\n        // Extract ciphertext length from header (2 bytes, big-endian)\n        let ciphertext_length =\n            ((header_plaintext.get(0) as u32) << 8) | (header_plaintext.get(1) as u32);\n\n        // Extract and decrypt main ciphertext\n        let ciphertext_start = header_start + HEADER_CIPHERTEXT_SIZE_IN_BYTES;\n        let ciphertext_with_padding: [u8; (PRIVATE_LOG_CIPHERTEXT_LEN - EPH_PK_X_SIZE_IN_FIELDS) * 31 - HEADER_CIPHERTEXT_SIZE_IN_BYTES - EPH_PK_SIGN_BYTE_SIZE_IN_BYTES] =\n            array::subarray(ciphertext_without_eph_pk_x.storage(), ciphertext_start);\n        let ciphertext: BoundedVec<u8, (PRIVATE_LOG_CIPHERTEXT_LEN - EPH_PK_X_SIZE_IN_FIELDS) * 31 - HEADER_CIPHERTEXT_SIZE_IN_BYTES - EPH_PK_SIGN_BYTE_SIZE_IN_BYTES> =\n            BoundedVec::from_parts(ciphertext_with_padding, ciphertext_length);\n\n        // Decrypt main ciphertext and return it\n        let plaintext_bytes = aes128_decrypt_oracle(ciphertext, iv, sym_key);\n\n        // Each field of the original note log was serialized to 32 bytes so we convert the bytes back to fields.\n        fields_from_bytes(plaintext_bytes)\n    }\n}\n\nmod test {\n    use crate::{\n        keys::ecdh_shared_secret::derive_ecdh_shared_secret_using_aztec_address,\n        messages::encryption::log_encryption::{LogEncryption, PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS},\n        test::helpers::test_environment::TestEnvironment,\n    };\n    use super::AES128;\n    use protocol_types::{\n        address::AztecAddress,\n        indexed_tagging_secret::IndexedTaggingSecret,\n        traits::{Deserialize, FromField},\n    };\n    use std::{embedded_curve_ops::EmbeddedCurveScalar, test::OracleMock};\n\n    #[test]\n    unconstrained fn encrypt_decrypt_log() {\n        let mut env = TestEnvironment::new();\n        // Advance 1 block so we can read historic state from private\n        env.advance_block_by(1);\n\n        let plaintext = [1, 2, 3];\n\n        let recipient = AztecAddress::from_field(\n            0x25afb798ea6d0b8c1618e50fdeafa463059415013d3b7c75d46abf5e242be70c,\n        );\n\n        // Mock random values for deterministic test\n        let eph_sk = 0x1358d15019d4639393d62b97e1588c095957ce74a1c32d6ec7d62fe6705d9538;\n        let _ = OracleMock::mock(\"getRandomField\").returns(eph_sk).times(1);\n\n        let randomness = 0x0101010101010101010101010101010101010101010101010101010101010101;\n        let _ = OracleMock::mock(\"getRandomField\").returns(randomness).times(1000000);\n\n        let _ = OracleMock::mock(\"getIndexedTaggingSecretAsSender\").returns(\n            IndexedTaggingSecret::deserialize([69420, 1337]),\n        );\n        let _ = OracleMock::mock(\"incrementAppTaggingSecretIndexAsSender\").returns(());\n\n        // Encrypt the log\n        let encrypted_log = BoundedVec::from_array(AES128::encrypt_log(plaintext, recipient));\n\n        // Mock shared secret for deterministic test\n        let shared_secret = derive_ecdh_shared_secret_using_aztec_address(\n            EmbeddedCurveScalar::from_field(eph_sk),\n            recipient,\n        );\n        let _ = OracleMock::mock(\"getSharedSecret\").returns(shared_secret);\n\n        // Decrypt the log\n        let decrypted = AES128::decrypt_log(encrypted_log, recipient);\n\n        // The decryption function spits out a BoundedVec because it's designed to work with logs with unknown length\n        // at compile time. For this reason we need to convert the original input to a BoundedVec.\n        let plaintext_bvec =\n            BoundedVec::<Field, PRIVATE_LOG_PLAINTEXT_SIZE_IN_FIELDS>::from_array(plaintext);\n\n        // Verify decryption matches original plaintext\n        assert_eq(decrypted, plaintext_bvec, \"Decrypted bytes should match original plaintext\");\n\n        // The following is a workaround of \"struct is never constructed\" Noir compilation error (we only ever use\n        // static methods of the struct).\n        let _ = AES128 {};\n    }\n}\n"
    },
    "12": {
      "path": "std/convert.nr",
      "source": "// docs:start:from-trait\npub trait From<T> {\n    fn from(input: T) -> Self;\n}\n// docs:end:from-trait\n\nimpl<T> From<T> for T {\n    fn from(input: T) -> T {\n        input\n    }\n}\n\n// docs:start:into-trait\npub trait Into<T> {\n    fn into(self) -> T;\n}\n\nimpl<T, U> Into<T> for U\nwhere\n    T: From<U>,\n{\n    fn into(self) -> T {\n        T::from(self)\n    }\n}\n// docs:end:into-trait\n\n// docs:start:from-impls\n// Unsigned integers\n\nimpl From<u8> for u32 {\n    fn from(value: u8) -> u32 {\n        value as u32\n    }\n}\n\nimpl From<u8> for u64 {\n    fn from(value: u8) -> u64 {\n        value as u64\n    }\n}\nimpl From<u32> for u64 {\n    fn from(value: u32) -> u64 {\n        value as u64\n    }\n}\n\nimpl From<u8> for u128 {\n    fn from(value: u8) -> u128 {\n        value as u128\n    }\n}\nimpl From<u32> for u128 {\n    fn from(value: u32) -> u128 {\n        value as u128\n    }\n}\nimpl From<u64> for u128 {\n    fn from(value: u64) -> u128 {\n        value as u128\n    }\n}\n\nimpl From<u8> for Field {\n    fn from(value: u8) -> Field {\n        value as Field\n    }\n}\nimpl From<u32> for Field {\n    fn from(value: u32) -> Field {\n        value as Field\n    }\n}\nimpl From<u64> for Field {\n    fn from(value: u64) -> Field {\n        value as Field\n    }\n}\n\nimpl From<u128> for Field {\n    fn from(value: u128) -> Field {\n        value as Field\n    }\n}\n\n// Signed integers\n\nimpl From<i8> for i32 {\n    fn from(value: i8) -> i32 {\n        value as i32\n    }\n}\n\nimpl From<i8> for i64 {\n    fn from(value: i8) -> i64 {\n        value as i64\n    }\n}\nimpl From<i32> for i64 {\n    fn from(value: i32) -> i64 {\n        value as i64\n    }\n}\n\n// Booleans\nimpl From<bool> for u8 {\n    fn from(value: bool) -> u8 {\n        value as u8\n    }\n}\nimpl From<bool> for u32 {\n    fn from(value: bool) -> u32 {\n        value as u32\n    }\n}\nimpl From<bool> for u64 {\n    fn from(value: bool) -> u64 {\n        value as u64\n    }\n}\nimpl From<bool> for i8 {\n    fn from(value: bool) -> i8 {\n        value as i8\n    }\n}\nimpl From<bool> for i32 {\n    fn from(value: bool) -> i32 {\n        value as i32\n    }\n}\nimpl From<bool> for i64 {\n    fn from(value: bool) -> i64 {\n        value as i64\n    }\n}\nimpl From<bool> for Field {\n    fn from(value: bool) -> Field {\n        value as Field\n    }\n}\n// docs:end:from-impls\n\n/// A generic interface for casting between primitive types,\n/// equivalent of using the `as` keyword between values.\n///\n/// # Example\n///\n/// ```\n/// let x: Field = 1234567890;\n/// let y: u8 = x as u8;\n/// let z: u8 = x.as_();\n/// assert_eq(y, z);\n/// ```\npub trait AsPrimitive<T> {\n    /// The equivalent of doing `self as T`.\n    fn as_(self) -> T;\n}\n\n#[generate_as_primitive_impls]\ncomptime fn generate_as_primitive_impls(_: FunctionDefinition) -> Quoted {\n    let types = [\n        quote { bool },\n        quote { u8 },\n        quote { u16 },\n        quote { u32 },\n        quote { u64 },\n        quote { u128 },\n        quote { i8 },\n        quote { i16 },\n        quote { i32 },\n        quote { i64 },\n        quote { Field },\n    ];\n\n    let mut impls = &[];\n    for type1 in types {\n        for type2 in types {\n            impls = impls.push_back(\n                quote {\n                impl AsPrimitive<$type1> for $type2 {\n                    fn as_(self) -> $type1 {\n                        self as $type1\n                    }\n                }\n            },\n            );\n        }\n    }\n    impls.join(quote {})\n}\n"
    },
    "128": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/note/note_metadata.nr",
      "source": "use protocol_types::traits::Serialize;\n\n// There's temporarily quite a bit of boilerplate here because Noir does not yet support enums. This file will\n// eventually be simplified into something closer to:\n//\n// pub enum NoteMetadata {\n//   PendingSamePhase{ note_hash_counter: u32 },\n//   PendingOtherPhase{ note_hash_counter: u32, nonce: Field },\n//   Settled{ nonce: Field },\n// }\n//\n// For now, we have `NoteMetadata` acting as a sort of tagged union.\n\nstruct NoteStageEnum {\n    /// A note that was created in the transaction that is currently being executed, during the current execution phase,\n    /// i.e. non-revertible or revertible.\n    ///\n    /// These notes are not yet in the note hash tree, though they will be inserted unless nullified in this transaction\n    /// (becoming a transient note).\n    PENDING_SAME_PHASE: u8,\n    /// A note that was created in the transaction that is currently being executed, during the previous execution\n    /// phase. Because there are only two phases and their order is always the same (first non-revertible and then\n    /// revertible) this implies that the note was created in the non-revertible phase, and that the current phase is\n    /// the revertible phase.\n    ///\n    /// These notes are not yet in the note hash tree, though they will be inserted **even if nullified in this\n    /// transaction**. This means that they must be nullified as if they were settled (i.e. using the unique note hash)\n    /// in order to avoid double spends once they become settled.\n    PENDING_PREVIOUS_PHASE: u8,\n    /// A note that was created in a prior transaction and is therefore already in the note hash tree.\n    SETTLED: u8,\n}\n\nglobal NoteStage: NoteStageEnum =\n    NoteStageEnum { PENDING_SAME_PHASE: 1, PENDING_PREVIOUS_PHASE: 2, SETTLED: 3 };\n\n/// The metadata required to both prove a note's existence and destroy it, by computing the correct note hash for kernel\n/// read requests, as well as the correct nullifier to avoid double-spends.\n///\n/// This represents a note in any of the three valid stages (pending same phase, pending previous phase, or settled). In\n/// order to access the underlying fields callers must first find the appropriate stage (e.g. via `is_settled()`) and\n/// then convert this into the appropriate type (e.g. via `to_settled()`).\n#[derive(Eq, Serialize)]\npub struct NoteMetadata {\n    stage: u8,\n    maybe_nonce: Field,\n}\n\nimpl NoteMetadata {\n    /// Constructs a `NoteMetadata` object from optional note hash counter and nonce. Both a zero note hash counter and\n    /// a zero nonce are invalid, so those are used to signal non-existent values.\n    pub fn from_raw_data(nonzero_note_hash_counter: bool, maybe_nonce: Field) -> Self {\n        if nonzero_note_hash_counter {\n            if maybe_nonce == 0 {\n                Self { stage: NoteStage.PENDING_SAME_PHASE, maybe_nonce }\n            } else {\n                Self { stage: NoteStage.PENDING_PREVIOUS_PHASE, maybe_nonce }\n            }\n        } else if maybe_nonce != 0 {\n            Self { stage: NoteStage.SETTLED, maybe_nonce }\n        } else {\n            panic(\n                f\"Note has a zero note hash counter and no nonce - existence cannot be proven\",\n            )\n        }\n    }\n\n    /// Returns true if the note is pending **and** from the same phase, i.e. if it's been created in the current\n    /// transaction during the current execution phase (either non-revertible or revertible).\n    pub fn is_pending_same_phase(self) -> bool {\n        self.stage == NoteStage.PENDING_SAME_PHASE\n    }\n\n    /// Returns true if the note is pending **and** from the previous phase, i.e. if it's been created in the current\n    /// transaction during an execution phase prior to the current one. Because private execution only has two phases\n    /// with strict ordering, this implies that the note was created in the non-revertible phase, and that the current\n    /// phase is the revertible phase.\n    pub fn is_pending_previous_phase(self) -> bool {\n        self.stage == NoteStage.PENDING_PREVIOUS_PHASE\n    }\n\n    /// Returns true if the note is settled, i.e. if it's been created in a prior transaction and is therefore already\n    /// in the note hash tree.\n    pub fn is_settled(self) -> bool {\n        self.stage == NoteStage.SETTLED\n    }\n\n    /// Asserts that the metadata is that of a pending note from the same phase and converts it accordingly.\n    pub fn to_pending_same_phase(self) -> PendingSamePhaseNoteMetadata {\n        assert_eq(self.stage, NoteStage.PENDING_SAME_PHASE);\n        PendingSamePhaseNoteMetadata::new()\n    }\n\n    /// Asserts that the metadata is that of a pending note from a previous phase and converts it accordingly.\n    pub fn to_pending_previous_phase(self) -> PendingPreviousPhaseNoteMetadata {\n        assert_eq(self.stage, NoteStage.PENDING_PREVIOUS_PHASE);\n        PendingPreviousPhaseNoteMetadata::new(self.maybe_nonce)\n    }\n\n    /// Asserts that the metadata is that of a settled note and converts it accordingly.\n    pub fn to_settled(self) -> SettledNoteMetadata {\n        assert_eq(self.stage, NoteStage.SETTLED);\n        SettledNoteMetadata::new(self.maybe_nonce)\n    }\n}\n\nimpl From<PendingSamePhaseNoteMetadata> for NoteMetadata {\n    fn from(_value: PendingSamePhaseNoteMetadata) -> Self {\n        NoteMetadata::from_raw_data(true, std::mem::zeroed())\n    }\n}\n\nimpl From<PendingPreviousPhaseNoteMetadata> for NoteMetadata {\n    fn from(value: PendingPreviousPhaseNoteMetadata) -> Self {\n        NoteMetadata::from_raw_data(true, value.nonce())\n    }\n}\n\nimpl From<SettledNoteMetadata> for NoteMetadata {\n    fn from(value: SettledNoteMetadata) -> Self {\n        NoteMetadata::from_raw_data(false, value.nonce())\n    }\n}\n\n/// The metadata required to both prove a note's existence and destroy it, by computing the correct note hash for kernel\n/// read requests, as well as the correct nullifier to avoid double-spends.\n///\n/// This represents a pending same phase note, i.e. a note that was created in the transaction that is currently being\n/// executed during the current execution phase (either non-revertible or revertible).\npub struct PendingSamePhaseNoteMetadata {\n    // This struct contains no fields since there is no metadata associated with a pending same phase note: it has no\n    // nonce (since it may get squashed by a nullifier emitted in the same phase), and while it does have a note hash\n    // counter we cannot constrain its value (and don't need to - only that it is non-zero).\n}\n\nimpl PendingSamePhaseNoteMetadata {\n    pub fn new() -> Self {\n        Self {}\n    }\n}\n\n/// The metadata required to both prove a note's existence and destroy it, by computing the correct note hash for kernel\n/// read requests, as well as the correct nullifier to avoid double-spends.\n///\n/// This represents a pending previous phase note, i.e. a note that was created in the transaction that is currently\n/// being executed, during the previous execution phase. Because there are only two phases and their order is always the\n/// same (first non-revertible and then revertible) this implies that the note was created in the non-revertible phase,\n/// and that the current phase is the revertible phase.\npub struct PendingPreviousPhaseNoteMetadata {\n    nonce: Field,\n    // This struct does not contain a note hash counter, even though one exists for this note, because we cannot\n    // constrain its value (and don't need to - only that it is non-zero).\n}\n\nimpl PendingPreviousPhaseNoteMetadata {\n    pub fn new(nonce: Field) -> Self {\n        Self { nonce }\n    }\n\n    pub fn nonce(self) -> Field {\n        self.nonce\n    }\n}\n\n/// The metadata required to both prove a note's existence and destroy it, by computing the correct note hash for kernel\n/// read requests, as well as the correct nullifier to avoid double-spends.\n///\n/// This represents a settled note, i.e. a note that was created in a prior transaction and is therefore already in the\n/// note hash tree.\npub struct SettledNoteMetadata {\n    nonce: Field,\n}\n\nimpl SettledNoteMetadata {\n    pub fn new(nonce: Field) -> Self {\n        Self { nonce }\n    }\n\n    pub fn nonce(self) -> Field {\n        self.nonce\n    }\n}\n"
    },
    "131": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/note/utils.nr",
      "source": "use crate::{\n    context::PrivateContext,\n    note::{note_interface::NoteHash, retrieved_note::RetrievedNote},\n};\n\nuse dep::protocol_types::hash::{\n    compute_siloed_note_hash, compute_siloed_nullifier, compute_unique_note_hash,\n};\n\n/// Returns the note hash that must be used to issue a private kernel read request for a note.\npub fn compute_note_hash_for_read_request<Note>(\n    retrieved_note: RetrievedNote<Note>,\n    storage_slot: Field,\n) -> Field\nwhere\n    Note: NoteHash,\n{\n    let note_hash = retrieved_note.note.compute_note_hash(storage_slot);\n\n    if retrieved_note.metadata.is_settled() {\n        // Settled notes are read by siloing with contract address and nonce (resulting in the final unique note hash,\n        // which is already in the note hash tree).\n        let siloed_note_hash = compute_siloed_note_hash(retrieved_note.contract_address, note_hash);\n        compute_unique_note_hash(\n            retrieved_note.metadata.to_settled().nonce(),\n            siloed_note_hash,\n        )\n    } else {\n        // Pending notes (both same phase and previous phase ones)  re read by their non-siloed hash (not even by\n        // contract address), which is what is stored in the new note hashes array (at the position hinted by note hash\n        // counter).\n        note_hash\n    }\n}\n\n/// Returns the note hash that must be used to compute a note's nullifier when calling `NoteHash::compute_nullifier` or\n/// `NoteHash::compute_nullifier_unconstrained`.\npub fn compute_note_hash_for_nullify<Note>(\n    retrieved_note: RetrievedNote<Note>,\n    storage_slot: Field,\n) -> Field\nwhere\n    Note: NoteHash,\n{\n    compute_note_hash_for_nullify_from_read_request(\n        retrieved_note,\n        compute_note_hash_for_read_request(retrieved_note, storage_slot),\n    )\n}\n\n/// Same as `compute_note_hash_for_nullify`, except it takes the note hash used in a read request (i.e. what\n/// `compute_note_hash_for_read_request` would return). This is useful in scenarios where that hash has already been\n/// computed to reduce constraints by reusing this value.\npub fn compute_note_hash_for_nullify_from_read_request<Note>(\n    retrieved_note: RetrievedNote<Note>,\n    note_hash_for_read_request: Field,\n) -> Field {\n    // There is just one instance in which the note hash for nullification does not match the note hash used for a read\n    // request, which is when dealing with pending previous phase notes. These had their existence proven using their\n    // non-siloed note hash along with the note hash counter (like all pending notes), but since they will be\n    // unconditionally inserted in the note hash tree (since they cannot be squashed) they must be nullified using the\n    // *unique* note hash.\n    // If we didn't, it'd be possible to emit a second different nullifier for the same note in a follow up transaction,\n    // once the note is settled, resulting in a double spend.\n\n    if retrieved_note.metadata.is_pending_previous_phase() {\n        let siloed_note_hash =\n            compute_siloed_note_hash(retrieved_note.contract_address, note_hash_for_read_request);\n        let nonce = retrieved_note.metadata.to_pending_previous_phase().nonce();\n\n        compute_unique_note_hash(nonce, siloed_note_hash)\n    } else {\n        note_hash_for_read_request\n    }\n}\n\n/// Computes a note's siloed nullifier, i.e. the one that will be inserted into the nullifier tree.\npub fn compute_siloed_note_nullifier<Note>(\n    retrieved_note: RetrievedNote<Note>,\n    storage_slot: Field,\n    context: &mut PrivateContext,\n) -> Field\nwhere\n    Note: NoteHash,\n{\n    let note_hash_for_nullify = compute_note_hash_for_nullify(retrieved_note, storage_slot);\n    let inner_nullifier = retrieved_note.note.compute_nullifier(context, note_hash_for_nullify);\n\n    compute_siloed_nullifier(retrieved_note.contract_address, inner_nullifier)\n}\n"
    },
    "135": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/oracle/capsules.nr",
      "source": "use protocol_types::{address::AztecAddress, traits::{Deserialize, Serialize}};\n\n/// Stores arbitrary information in a per-contract non-volatile database, which can later be retrieved with `load`. If\n/// data was already stored at this slot, it is overwritten.\npub unconstrained fn store<T, let N: u32>(contract_address: AztecAddress, slot: Field, value: T)\nwhere\n    T: Serialize<N>,\n{\n    let serialized = value.serialize();\n    store_oracle(contract_address, slot, serialized);\n}\n\n/// Returns data previously stored via `storeCapsule` in the per-contract non-volatile database. Returns Option::none() if\n/// nothing was stored at the given slot.\npub unconstrained fn load<T, let N: u32>(contract_address: AztecAddress, slot: Field) -> Option<T>\nwhere\n    T: Deserialize<N>,\n{\n    let serialized_option = load_oracle::<N>(contract_address, slot, N);\n    serialized_option.map(|arr| Deserialize::deserialize(arr))\n}\n\n/// Deletes data in the per-contract non-volatile database. Does nothing if no data was present.\npub unconstrained fn delete(contract_address: AztecAddress, slot: Field) {\n    delete_oracle(contract_address, slot);\n}\n\n/// Copies a number of contiguous entries in the per-contract non-volatile database. This allows for efficient data\n/// structures by avoiding repeated calls to `loadCapsule` and `storeCapsule`.\n/// Supports overlapping source and destination regions (which will result in the overlapped source values being\n/// overwritten). All copied slots must exist in the database (i.e. have been stored and not deleted)\npub unconstrained fn copy(\n    contract_address: AztecAddress,\n    src_slot: Field,\n    dst_slot: Field,\n    num_entries: u32,\n) {\n    copy_oracle(contract_address, src_slot, dst_slot, num_entries);\n}\n\n#[oracle(storeCapsule)]\nunconstrained fn store_oracle<let N: u32>(\n    contract_address: AztecAddress,\n    slot: Field,\n    values: [Field; N],\n) {}\n\n/// We need to pass in `array_len` (the value of N) as a parameter to tell the oracle how many fields the response must\n/// have.\n///\n/// Note that the oracle returns an Option<[Field; N]> because we cannot return an Option<T> directly. That would\n/// require for the oracle resolver to know the shape of T (e.g. if T were a struct of 3 u32 values then the expected\n/// response shape would be 3 single items, whereas it were a struct containing `u32, [Field;10], u32` then the expected\n/// shape would be single, array, single.). Instead, we return the serialization and deserialize in Noir.\n#[oracle(loadCapsule)]\nunconstrained fn load_oracle<let N: u32>(\n    contract_address: AztecAddress,\n    slot: Field,\n    array_len: u32,\n) -> Option<[Field; N]> {}\n\n#[oracle(deleteCapsule)]\nunconstrained fn delete_oracle(contract_address: AztecAddress, slot: Field) {}\n\n#[oracle(copyCapsule)]\nunconstrained fn copy_oracle(\n    contract_address: AztecAddress,\n    src_slot: Field,\n    dst_slot: Field,\n    num_entries: u32,\n) {}\n\nmod test {\n    // These tests are sort of redundant since we already test the oracle implementation directly in TypeScript, but\n    // they are cheap regardless and help ensure both that the TXE implementation works accordingly and that the Noir\n    // oracles are hooked up correctly.\n\n    use crate::{\n        oracle::capsules::{copy, delete, load, store},\n        test::{helpers::test_environment::TestEnvironment, mocks::mock_struct::MockStruct},\n    };\n    use protocol_types::{address::AztecAddress, traits::{FromField, ToField}};\n\n    unconstrained fn setup() -> AztecAddress {\n        let env = TestEnvironment::new();\n        env.contract_address()\n    }\n\n    global SLOT: Field = 1;\n\n    #[test]\n    unconstrained fn stores_and_loads() {\n        let contract_address = setup();\n\n        let value = MockStruct::new(5, 6);\n        store(contract_address, SLOT, value);\n\n        assert_eq(load(contract_address, SLOT).unwrap(), value);\n    }\n\n    #[test]\n    unconstrained fn store_overwrites() {\n        let contract_address = setup();\n\n        let value = MockStruct::new(5, 6);\n        store(contract_address, SLOT, value);\n\n        let new_value = MockStruct::new(7, 8);\n        store(contract_address, SLOT, new_value);\n\n        assert_eq(load(contract_address, SLOT).unwrap(), new_value);\n    }\n\n    #[test]\n    unconstrained fn loads_empty_slot() {\n        let contract_address = setup();\n\n        let loaded_value: Option<MockStruct> = load(contract_address, SLOT);\n        assert_eq(loaded_value, Option::none());\n    }\n\n    #[test]\n    unconstrained fn deletes_stored_value() {\n        let contract_address = setup();\n\n        let value = MockStruct::new(5, 6);\n        store(contract_address, SLOT, value);\n        delete(contract_address, SLOT);\n\n        let loaded_value: Option<MockStruct> = load(contract_address, SLOT);\n        assert_eq(loaded_value, Option::none());\n    }\n\n    #[test]\n    unconstrained fn deletes_empty_slot() {\n        let contract_address = setup();\n\n        delete(contract_address, SLOT);\n        let loaded_value: Option<MockStruct> = load(contract_address, SLOT);\n        assert_eq(loaded_value, Option::none());\n    }\n\n    #[test]\n    unconstrained fn copies_non_overlapping_values() {\n        let contract_address = setup();\n\n        let src = 5;\n\n        let values = [MockStruct::new(5, 6), MockStruct::new(7, 8), MockStruct::new(9, 10)];\n        store(contract_address, src, values[0]);\n        store(contract_address, src + 1, values[1]);\n        store(contract_address, src + 2, values[2]);\n\n        let dst = 10;\n        copy(contract_address, src, dst, 3);\n\n        assert_eq(load(contract_address, dst).unwrap(), values[0]);\n        assert_eq(load(contract_address, dst + 1).unwrap(), values[1]);\n        assert_eq(load(contract_address, dst + 2).unwrap(), values[2]);\n    }\n\n    #[test]\n    unconstrained fn copies_overlapping_values_with_src_ahead() {\n        let contract_address = setup();\n\n        let src = 1;\n\n        let values = [MockStruct::new(5, 6), MockStruct::new(7, 8), MockStruct::new(9, 10)];\n        store(contract_address, src, values[0]);\n        store(contract_address, src + 1, values[1]);\n        store(contract_address, src + 2, values[2]);\n\n        let dst = 2;\n        copy(contract_address, src, dst, 3);\n\n        assert_eq(load(contract_address, dst).unwrap(), values[0]);\n        assert_eq(load(contract_address, dst + 1).unwrap(), values[1]);\n        assert_eq(load(contract_address, dst + 2).unwrap(), values[2]);\n\n        // src[1] and src[2] should have been overwritten since they are also dst[0] and dst[1]\n        assert_eq(load(contract_address, src).unwrap(), values[0]); // src[0] (unchanged)\n        assert_eq(load(contract_address, src + 1).unwrap(), values[0]); // dst[0]\n        assert_eq(load(contract_address, src + 2).unwrap(), values[1]); // dst[1]\n    }\n\n    #[test]\n    unconstrained fn copies_overlapping_values_with_dst_ahead() {\n        let contract_address = setup();\n\n        let src = 2;\n\n        let values = [MockStruct::new(5, 6), MockStruct::new(7, 8), MockStruct::new(9, 10)];\n        store(contract_address, src, values[0]);\n        store(contract_address, src + 1, values[1]);\n        store(contract_address, src + 2, values[2]);\n\n        let dst = 1;\n        copy(contract_address, src, dst, 3);\n\n        assert_eq(load(contract_address, dst).unwrap(), values[0]);\n        assert_eq(load(contract_address, dst + 1).unwrap(), values[1]);\n        assert_eq(load(contract_address, dst + 2).unwrap(), values[2]);\n\n        // src[0] and src[1] should have been overwritten since they are also dst[1] and dst[2]\n        assert_eq(load(contract_address, src).unwrap(), values[1]); // dst[1]\n        assert_eq(load(contract_address, src + 1).unwrap(), values[2]); // dst[2]\n        assert_eq(load(contract_address, src + 2).unwrap(), values[2]); // src[2] (unchanged)\n    }\n\n    #[test(should_fail_with = \"copy empty slot\")]\n    unconstrained fn cannot_copy_empty_values() {\n        let contract_address = setup();\n\n        copy(contract_address, SLOT, SLOT, 1);\n    }\n\n    #[test(should_fail_with = \"not allowed to access\")]\n    unconstrained fn cannot_store_other_contract() {\n        let contract_address = setup();\n        let other_contract_address = AztecAddress::from_field(contract_address.to_field() + 1);\n\n        let value = MockStruct::new(5, 6);\n        store(other_contract_address, SLOT, value);\n    }\n\n    #[test(should_fail_with = \"not allowed to access\")]\n    unconstrained fn cannot_load_other_contract() {\n        let contract_address = setup();\n        let other_contract_address = AztecAddress::from_field(contract_address.to_field() + 1);\n\n        let _: Option<MockStruct> = load(other_contract_address, SLOT);\n    }\n\n    #[test(should_fail_with = \"not allowed to access\")]\n    unconstrained fn cannot_delete_other_contract() {\n        let contract_address = setup();\n        let other_contract_address = AztecAddress::from_field(contract_address.to_field() + 1);\n\n        delete(other_contract_address, SLOT);\n    }\n\n    #[test(should_fail_with = \"not allowed to access\")]\n    unconstrained fn cannot_copy_other_contract() {\n        let contract_address = setup();\n        let other_contract_address = AztecAddress::from_field(contract_address.to_field() + 1);\n\n        copy(other_contract_address, SLOT, SLOT, 0);\n    }\n}\n"
    },
    "137": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/oracle/execution.nr",
      "source": "use dep::protocol_types::address::AztecAddress;\n\n#[oracle(getContractAddress)]\nunconstrained fn get_contract_address_oracle() -> AztecAddress {}\n\n#[oracle(getBlockNumber)]\nunconstrained fn get_block_number_oracle() -> u32 {}\n\n#[oracle(getChainId)]\nunconstrained fn get_chain_id_oracle() -> Field {}\n\n#[oracle(getVersion)]\nunconstrained fn get_version_oracle() -> Field {}\n\npub unconstrained fn get_contract_address() -> AztecAddress {\n    get_contract_address_oracle()\n}\n\npub unconstrained fn get_block_number() -> u32 {\n    get_block_number_oracle()\n}\n\npub unconstrained fn get_chain_id() -> Field {\n    get_chain_id_oracle()\n}\n\npub unconstrained fn get_version() -> Field {\n    get_version_oracle()\n}\n"
    },
    "144": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/oracle/key_validation_request.nr",
      "source": "use protocol_types::abis::validation_requests::KeyValidationRequest;\n\n#[oracle(getKeyValidationRequest)]\nunconstrained fn get_key_validation_request_oracle(\n    _pk_m_hash: Field,\n    _key_index: Field,\n) -> KeyValidationRequest {}\n\npub unconstrained fn get_key_validation_request(\n    pk_m_hash: Field,\n    key_index: Field,\n) -> KeyValidationRequest {\n    get_key_validation_request_oracle(pk_m_hash, key_index)\n}\n"
    },
    "145": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/oracle/keys.nr",
      "source": "use dep::protocol_types::{\n    address::{AztecAddress, PartialAddress},\n    point::Point,\n    public_keys::{IvpkM, NpkM, OvpkM, PublicKeys, TpkM},\n};\n\n#[oracle(getPublicKeysAndPartialAddress)]\nunconstrained fn get_public_keys_and_partial_address_oracle(_address: AztecAddress) -> [Field; 13] {}\n\npub unconstrained fn get_public_keys_and_partial_address(\n    address: AztecAddress,\n) -> (PublicKeys, PartialAddress) {\n    let result = get_public_keys_and_partial_address_oracle(address);\n\n    let keys = PublicKeys {\n        npk_m: NpkM { inner: Point { x: result[0], y: result[1], is_infinite: result[2] as bool } },\n        ivpk_m: IvpkM {\n            inner: Point { x: result[3], y: result[4], is_infinite: result[5] as bool },\n        },\n        ovpk_m: OvpkM {\n            inner: Point { x: result[6], y: result[7], is_infinite: result[8] as bool },\n        },\n        tpk_m: TpkM {\n            inner: Point { x: result[9], y: result[10], is_infinite: result[11] as bool },\n        },\n    };\n\n    let partial_address = PartialAddress::from_field(result[12]);\n\n    (keys, partial_address)\n}\n"
    },
    "146": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/oracle/logs.nr",
      "source": "use crate::messages::encoding::MAX_MESSAGE_CONTENT_LEN;\nuse protocol_types::{abis::event_selector::EventSelector, address::AztecAddress};\n\n/// The below only exists to broadcast the raw log, so we can provide it to the base rollup later to be constrained.\npub unconstrained fn notify_created_contract_class_log<let N: u32>(\n    contract_address: AztecAddress,\n    message: [Field; N],\n    length: u32,\n    counter: u32,\n) {\n    notify_created_contract_class_log_private_oracle(contract_address, message, length, counter)\n}\n\n#[oracle(notifyCreatedContractClassLog)]\nunconstrained fn notify_created_contract_class_log_private_oracle<let N: u32>(\n    contract_address: AztecAddress,\n    message: [Field; N],\n    length: u32,\n    counter: u32,\n) {}\n\npub unconstrained fn store_private_event_log(\n    contract_address: AztecAddress,\n    recipient: AztecAddress,\n    event_selector: EventSelector,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n    tx_hash: Field,\n    log_index_in_tx: Field,\n    tx_index_in_block: Field,\n) {\n    store_private_event_log_oracle(\n        contract_address,\n        recipient,\n        event_selector,\n        msg_content,\n        tx_hash,\n        log_index_in_tx,\n        tx_index_in_block,\n    )\n}\n\n#[oracle(storePrivateEventLog)]\nunconstrained fn store_private_event_log_oracle(\n    contract_address: AztecAddress,\n    recipient: AztecAddress,\n    event_selector: EventSelector,\n    msg_content: BoundedVec<Field, MAX_MESSAGE_CONTENT_LEN>,\n    tx_hash: Field,\n    log_index_in_tx: Field,\n    tx_index_in_block: Field,\n) {}\n"
    },
    "147": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/oracle/message_discovery.nr",
      "source": "use crate::messages::discovery::private_notes::MAX_NOTE_PACKED_LEN;\nuse dep::protocol_types::{\n    address::AztecAddress,\n    constants::{MAX_NOTE_HASHES_PER_TX, PUBLIC_LOG_SIZE_IN_FIELDS},\n};\n\n/// Finds new private logs that may have been sent to all registered accounts in PXE in the current contract and makes\n/// them available for later processing in Noir by storing them in a capsule array.\npub unconstrained fn sync_private_state(pending_tagged_log_array_base_slot: Field) {\n    sync_private_state_oracle(pending_tagged_log_array_base_slot);\n}\n\n#[oracle(syncPrivateState)]\nunconstrained fn sync_private_state_oracle(pending_tagged_log_array_base_slot: Field) {}\n\n/// Informs PXE of a note's existence so that it can later be retrieved by the `getNotes` oracle. The note will be\n/// scoped to `contract_address`, meaning other contracts will not be able to access it unless authorized.\n///\n/// The packed note is what `getNotes` will later return. PXE indexes notes by `storage_slot`, so this value\n/// is typically used to filter notes that correspond to different state variables. `note_hash` and `nullifier` are\n/// the inner hashes, i.e. the raw hashes returned by `NoteHash::compute_note_hash` and\n/// `NoteHash::compute_nullifier`. PXE will verify that the siloed unique note hash was inserted into the tree\n/// at `tx_hash`, and will store the nullifier to later check for nullification.\n///\n/// `recipient` is the account to which the note was sent to. Other accounts will not be able to access this note (e.g.\n/// other accounts will not be able to see one another's token balance notes, even in the same PXE) unless authorized.\n///\n/// Returns true if the note was successfully delivered and added to PXE's database.\npub unconstrained fn deliver_note(\n    contract_address: AztecAddress,\n    storage_slot: Field,\n    nonce: Field,\n    packed_note: BoundedVec<Field, MAX_NOTE_PACKED_LEN>,\n    note_hash: Field,\n    nullifier: Field,\n    tx_hash: Field,\n    recipient: AztecAddress,\n) -> bool {\n    deliver_note_oracle(\n        contract_address,\n        storage_slot,\n        nonce,\n        packed_note,\n        note_hash,\n        nullifier,\n        tx_hash,\n        recipient,\n    )\n}\n\n/// The contents of a public log, plus contextual information about the transaction in which the log was emitted. This\n/// is the data required in order to discover notes that are being delivered in a log.\n// TODO(#11639): this could also be used to fetch private logs, but the `BoundedVec` maximum length is that of a public\n// log.\npub struct LogWithTxData {\n    // The log fields length is PUBLIC_LOG_SIZE_IN_FIELDS. + 1 because the contract address is prepended to the content.\n    pub log_content: BoundedVec<Field, PUBLIC_LOG_SIZE_IN_FIELDS + 1>,\n    pub tx_hash: Field,\n    /// The array of new note hashes created by `tx_hash`\n    pub unique_note_hashes_in_tx: BoundedVec<Field, MAX_NOTE_HASHES_PER_TX>,\n    /// The first nullifier created by `tx_hash`\n    pub first_nullifier_in_tx: Field,\n}\n\n/// Fetches a log from the node that has the corresponding `tag`. The log can be either a public or a private log, and\n/// the tag is the first field in the log's content. Returns `Option::none` if no such log exists. Throws if more than\n/// one log with that tag exists.\n/// Public logs have an extra field included at the beginning with the address of the contract that emitted them.\n// TODO(#11627): handle multiple logs with the same tag.\n// TODO(#10273): improve contract siloing of logs, don't introduce an extra field.\npub unconstrained fn get_log_by_tag(tag: Field) -> Option<LogWithTxData> {\n    get_log_by_tag_oracle(tag)\n}\n\n#[oracle(deliverNote)]\nunconstrained fn deliver_note_oracle(\n    contract_address: AztecAddress,\n    storage_slot: Field,\n    nonce: Field,\n    packed_note: BoundedVec<Field, MAX_NOTE_PACKED_LEN>,\n    note_hash: Field,\n    nullifier: Field,\n    tx_hash: Field,\n    recipient: AztecAddress,\n) -> bool {}\n\n#[oracle(getLogByTag)]\nunconstrained fn get_log_by_tag_oracle(tag: Field) -> Option<LogWithTxData> {}\n"
    },
    "151": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/oracle/shared_secret.nr",
      "source": "use protocol_types::{address::aztec_address::AztecAddress, point::Point};\n\n// TODO(#12656): return an app-siloed secret + document this\n#[oracle(getSharedSecret)]\nunconstrained fn get_shared_secret_oracle(address: AztecAddress, ephPk: Point) -> Point {}\n\n/// Returns an app-siloed shared secret between `address` and someone who knows the secret key behind an\n/// ephemeral public key `ephPk`. The app-siloing means that contracts cannot retrieve secrets that belong to\n/// other contracts, and therefore cannot e.g. decrypt their messages. This is an important security consideration\n/// given that both the `address` and `ephPk` are public information.\n///\n/// The shared secret `S` is computed as:\n/// `let S =  (ivsk + h) * ephPk`\n/// where `ivsk + h` is the 'preaddress' i.e. the preimage of the address, also called the address secret.\n/// TODO(#12656): app-silo this secret\npub unconstrained fn get_shared_secret(address: AztecAddress, ephPk: Point) -> Point {\n    get_shared_secret_oracle(address, ephPk)\n}\n"
    },
    "16": {
      "path": "std/embedded_curve_ops.nr",
      "source": "use crate::cmp::Eq;\nuse crate::hash::Hash;\nuse crate::ops::arith::{Add, Neg, Sub};\n\n/// A point on the embedded elliptic curve\n/// By definition, the base field of the embedded curve is the scalar field of the proof system curve, i.e the Noir Field.\n/// x and y denotes the Weierstrass coordinates of the point, if is_infinite is false.\npub struct EmbeddedCurvePoint {\n    pub x: Field,\n    pub y: Field,\n    pub is_infinite: bool,\n}\n\nimpl EmbeddedCurvePoint {\n    /// Elliptic curve point doubling operation\n    /// returns the doubled point of a point P, i.e P+P\n    pub fn double(self) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, self)\n    }\n\n    /// Returns the null element of the curve; 'the point at infinity'\n    pub fn point_at_infinity() -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: 0, y: 0, is_infinite: true }\n    }\n\n    /// Returns the curve's generator point.\n    pub fn generator() -> EmbeddedCurvePoint {\n        // Generator point for the grumpkin curve (y^2 = x^3 - 17)\n        EmbeddedCurvePoint {\n            x: 1,\n            y: 17631683881184975370165255887551781615748388533673675138860, // sqrt(-16)\n            is_infinite: false,\n        }\n    }\n}\n\nimpl Add for EmbeddedCurvePoint {\n    /// Adds two points P+Q, using the curve addition formula, and also handles point at infinity\n    fn add(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, other)\n    }\n}\n\nimpl Sub for EmbeddedCurvePoint {\n    /// Points subtraction operation, using addition and negation\n    fn sub(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        self + other.neg()\n    }\n}\n\nimpl Neg for EmbeddedCurvePoint {\n    /// Negates a point P, i.e returns -P, by negating the y coordinate.\n    /// If the point is at infinity, then the result is also at infinity.\n    fn neg(self) -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: self.x, y: -self.y, is_infinite: self.is_infinite }\n    }\n}\n\nimpl Eq for EmbeddedCurvePoint {\n    /// Checks whether two points are equal\n    fn eq(self: Self, b: EmbeddedCurvePoint) -> bool {\n        (self.is_infinite & b.is_infinite)\n            | ((self.is_infinite == b.is_infinite) & (self.x == b.x) & (self.y == b.y))\n    }\n}\n\nimpl Hash for EmbeddedCurvePoint {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: crate::hash::Hasher,\n    {\n        if self.is_infinite {\n            self.is_infinite.hash(state);\n        } else {\n            self.x.hash(state);\n            self.y.hash(state);\n        }\n    }\n}\n\n/// Scalar for the embedded curve represented as low and high limbs\n/// By definition, the scalar field of the embedded curve is base field of the proving system curve.\n/// It may not fit into a Field element, so it is represented with two Field elements; its low and high limbs.\npub struct EmbeddedCurveScalar {\n    pub lo: Field,\n    pub hi: Field,\n}\n\nimpl EmbeddedCurveScalar {\n    pub fn new(lo: Field, hi: Field) -> Self {\n        EmbeddedCurveScalar { lo, hi }\n    }\n\n    #[field(bn254)]\n    pub fn from_field(scalar: Field) -> EmbeddedCurveScalar {\n        let (a, b) = crate::field::bn254::decompose(scalar);\n        EmbeddedCurveScalar { lo: a, hi: b }\n    }\n\n    //Bytes to scalar: take the first (after the specified offset) 16 bytes of the input as the lo value, and the next 16 bytes as the hi value\n    #[field(bn254)]\n    pub(crate) fn from_bytes(bytes: [u8; 64], offset: u32) -> EmbeddedCurveScalar {\n        let mut v = 1;\n        let mut lo = 0 as Field;\n        let mut hi = 0 as Field;\n        for i in 0..16 {\n            lo = lo + (bytes[offset + 31 - i] as Field) * v;\n            hi = hi + (bytes[offset + 15 - i] as Field) * v;\n            v = v * 256;\n        }\n        let sig_s = crate::embedded_curve_ops::EmbeddedCurveScalar { lo, hi };\n        sig_s\n    }\n}\n\nimpl Eq for EmbeddedCurveScalar {\n    fn eq(self, other: Self) -> bool {\n        (other.hi == self.hi) & (other.lo == self.lo)\n    }\n}\n\nimpl Hash for EmbeddedCurveScalar {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: crate::hash::Hasher,\n    {\n        self.hi.hash(state);\n        self.lo.hash(state);\n    }\n}\n\n// Computes a multi scalar multiplication over the embedded curve.\n// For bn254, We have Grumpkin and Baby JubJub.\n// For bls12-381, we have JubJub and Bandersnatch.\n//\n// The embedded curve being used is decided by the\n// underlying proof system.\n// docs:start:multi_scalar_mul\npub fn multi_scalar_mul<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N],\n) -> EmbeddedCurvePoint\n// docs:end:multi_scalar_mul\n{\n    multi_scalar_mul_array_return(points, scalars)[0]\n}\n\n#[foreign(multi_scalar_mul)]\npub(crate) fn multi_scalar_mul_array_return<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N],\n) -> [EmbeddedCurvePoint; 1] {}\n\n// docs:start:fixed_base_scalar_mul\npub fn fixed_base_scalar_mul(scalar: EmbeddedCurveScalar) -> EmbeddedCurvePoint\n// docs:end:fixed_base_scalar_mul\n{\n    multi_scalar_mul([EmbeddedCurvePoint::generator()], [scalar])\n}\n\n/// This function only assumes that the points are on the curve\n/// It handles corner cases around the infinity point causing some overhead compared to embedded_curve_add_not_nul and embedded_curve_add_unsafe\n// docs:start:embedded_curve_add\npub fn embedded_curve_add(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    // docs:end:embedded_curve_add\n    if crate::runtime::is_unconstrained() {\n        // `embedded_curve_add_unsafe` requires the inputs not to be the infinity point, so we check it here.\n        // This is because `embedded_curve_add_unsafe` uses the `embedded_curve_add` opcode.\n        // For efficiency, the backend does not check the inputs for the infinity point, but it assumes that they are not the infinity point\n        // so that it can apply the ec addition formula directly.\n        if point1.is_infinite {\n            point2\n        } else if point2.is_infinite {\n            point1\n        } else {\n            embedded_curve_add_unsafe(point1, point2)\n        }\n    } else {\n        // In a constrained context, we also need to check the inputs are not the infinity point because we also use `embedded_curve_add_unsafe`\n        // However we also need to identify the case where the two inputs are the same, because then\n        // the addition formula does not work and we need to use the doubling formula instead.\n        // In unconstrained context, we can check directly if the input values are the same when solving the opcode, so it is not an issue.\n\n        // x_coordinates_match is true if both abscissae are the same\n        let x_coordinates_match = point1.x == point2.x;\n        // y_coordinates_match is true if both ordinates are the same\n        let y_coordinates_match = point1.y == point2.y;\n        // double_predicate is true if both abscissae and ordinates are the same\n        let double_predicate = (x_coordinates_match & y_coordinates_match);\n        // If the abscissae are the same, but not the ordinates, then one point is the opposite of the other\n        let infinity_predicate = (x_coordinates_match & !y_coordinates_match);\n        let point1_1 = EmbeddedCurvePoint {\n            x: point1.x + (x_coordinates_match as Field),\n            y: point1.y,\n            is_infinite: false,\n        };\n        let point2_1 = EmbeddedCurvePoint { x: point2.x, y: point2.y, is_infinite: false };\n        // point1_1 is guaranteed to have a different abscissa than point2:\n        // - if x_coordinates_match is 0, that means point1.x != point2.x, and point1_1.x = point1.x + 0\n        // - if x_coordinates_match is 1, that means point1.x = point2.x, but point1_1.x = point1.x + 1 in this case\n        // Because the abscissa is different, the addition formula is guaranteed to succeed, so we can safely use `embedded_curve_add_unsafe`\n        // Note that this computation may be garbage: if x_coordinates_match is 1, or if one of the input is the point at infinity.\n        let mut result = embedded_curve_add_unsafe(point1_1, point2_1);\n\n        // `embedded_curve_add_unsafe` is doing a doubling if the input is the same variable, because in this case it is guaranteed (at 'compile time') that the input is the same.\n        let double = embedded_curve_add_unsafe(point1, point1);\n        // `embedded_curve_add_unsafe` would not perform doubling, even if the inputs point1 and point2 are the same, because it cannot know this without adding some logic (and some constraints)\n        // However we did this logic when we computed `double_predicate`, so we set the result to 2*point1 if point1 and point2 are the same\n        result = if double_predicate { double } else { result };\n\n        // Same logic as above for unconstrained context, we set the proper result when one of the inputs is the infinity point\n        if point1.is_infinite {\n            result = point2;\n        }\n        if point2.is_infinite {\n            result = point1;\n        }\n\n        // Finally, we set the is_infinity flag of the result:\n        // Opposite points should sum into the infinity point, however, if one of them is point at infinity, their coordinates are not meaningful\n        // so we should not use the fact that the inputs are opposite in this case:\n        let mut result_is_infinity =\n            infinity_predicate & (!point1.is_infinite & !point2.is_infinite);\n        // However, if both of them are at infinity, then the result is also at infinity\n        result.is_infinite = result_is_infinity | (point1.is_infinite & point2.is_infinite);\n        result\n    }\n}\n\n#[foreign(embedded_curve_add)]\nfn embedded_curve_add_array_return(\n    _point1: EmbeddedCurvePoint,\n    _point2: EmbeddedCurvePoint,\n) -> [EmbeddedCurvePoint; 1] {}\n\n/// This function assumes that:\n/// The points are on the curve, and\n/// The points don't share an x-coordinate, and\n/// Neither point is the infinity point.\n/// If it is used with correct input, the function ensures the correct non-zero result is returned.\n/// Except for points on the curve, the other assumptions are checked by the function. It will cause assertion failure if they are not respected.\npub fn embedded_curve_add_not_nul(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    assert(point1.x != point2.x);\n    assert(!point1.is_infinite);\n    assert(!point2.is_infinite);\n    embedded_curve_add_unsafe(point1, point2)\n}\n\n/// Unsafe ec addition\n/// If the inputs are the same, it will perform a doubling, but only if point1 and point2 are the same variable.\n/// If they have the same value but are different variables, the result will be incorrect because in this case\n/// it assumes (but does not check) that the points' x-coordinates are not equal.\n/// It also assumes neither point is the infinity point.\npub fn embedded_curve_add_unsafe(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    embedded_curve_add_array_return(point1, point2)[0]\n}\n"
    },
    "17": {
      "path": "std/field/bn254.nr",
      "source": "use crate::field::field_less_than;\nuse crate::runtime::is_unconstrained;\n\n// The low and high decomposition of the field modulus\nglobal PLO: Field = 53438638232309528389504892708671455233;\nglobal PHI: Field = 64323764613183177041862057485226039389;\n\npub(crate) global TWO_POW_128: Field = 0x100000000000000000000000000000000;\n\n// Decomposes a single field into two 16 byte fields.\nfn compute_decomposition(x: Field) -> (Field, Field) {\n    // Here's we're taking advantage of truncating 128 bit limbs from the input field\n    // and then subtracting them from the input such the field division is equivalent to integer division.\n    let low = (x as u128) as Field;\n    let high = (x - low) / TWO_POW_128;\n\n    (low, high)\n}\n\npub(crate) unconstrained fn decompose_hint(x: Field) -> (Field, Field) {\n    compute_decomposition(x)\n}\n\nunconstrained fn lte_hint(x: Field, y: Field) -> bool {\n    if x == y {\n        true\n    } else {\n        field_less_than(x, y)\n    }\n}\n\n// Assert that (alo > blo && ahi >= bhi) || (alo <= blo && ahi > bhi)\nfn assert_gt_limbs(a: (Field, Field), b: (Field, Field)) {\n    let (alo, ahi) = a;\n    let (blo, bhi) = b;\n    // Safety: borrow is enforced to be boolean due to its type.\n    // if borrow is 0, it asserts that (alo > blo && ahi >= bhi)\n    // if borrow is 1, it asserts that (alo <= blo && ahi > bhi)\n    unsafe {\n        let borrow = lte_hint(alo, blo);\n\n        let rlo = alo - blo - 1 + (borrow as Field) * TWO_POW_128;\n        let rhi = ahi - bhi - (borrow as Field);\n\n        rlo.assert_max_bit_size::<128>();\n        rhi.assert_max_bit_size::<128>();\n    }\n}\n\n/// Decompose a single field into two 16 byte fields.\npub fn decompose(x: Field) -> (Field, Field) {\n    if is_unconstrained() {\n        compute_decomposition(x)\n    } else {\n        // Safety: decomposition is properly checked below\n        unsafe {\n            // Take hints of the decomposition\n            let (xlo, xhi) = decompose_hint(x);\n\n            // Range check the limbs\n            xlo.assert_max_bit_size::<128>();\n            xhi.assert_max_bit_size::<128>();\n\n            // Check that the decomposition is correct\n            assert_eq(x, xlo + TWO_POW_128 * xhi);\n\n            // Assert that the decomposition of P is greater than the decomposition of x\n            assert_gt_limbs((PLO, PHI), (xlo, xhi));\n            (xlo, xhi)\n        }\n    }\n}\n\npub fn assert_gt(a: Field, b: Field) {\n    if is_unconstrained() {\n        assert(\n            // Safety: already unconstrained\n            unsafe { field_less_than(b, a) },\n        );\n    } else {\n        // Decompose a and b\n        let a_limbs = decompose(a);\n        let b_limbs = decompose(b);\n\n        // Assert that a_limbs is greater than b_limbs\n        assert_gt_limbs(a_limbs, b_limbs)\n    }\n}\n\npub fn assert_lt(a: Field, b: Field) {\n    assert_gt(b, a);\n}\n\npub fn gt(a: Field, b: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unsafe in unconstrained\n        unsafe {\n            field_less_than(b, a)\n        }\n    } else if a == b {\n        false\n    } else {\n        // Safety: Take a hint of the comparison and verify it\n        unsafe {\n            if field_less_than(a, b) {\n                assert_gt(b, a);\n                false\n            } else {\n                assert_gt(a, b);\n                true\n            }\n        }\n    }\n}\n\npub fn lt(a: Field, b: Field) -> bool {\n    gt(b, a)\n}\n\nmod tests {\n    // TODO: Allow imports from \"super\"\n    use crate::field::bn254::{assert_gt, decompose, gt, lte_hint, PHI, PLO, TWO_POW_128};\n\n    #[test]\n    fn check_decompose() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_decompose_unconstrained() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_lte_hint() {\n        assert(lte_hint(0, 1));\n        assert(lte_hint(0, 0x100));\n        assert(lte_hint(0x100, TWO_POW_128 - 1));\n        assert(!lte_hint(0 - 1, 0));\n\n        assert(lte_hint(0, 0));\n        assert(lte_hint(0x100, 0x100));\n        assert(lte_hint(0 - 1, 0 - 1));\n    }\n\n    #[test]\n    fn check_assert_gt() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    unconstrained fn check_assert_gt_unconstrained() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    fn check_gt() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    unconstrained fn check_gt_unconstrained() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    fn check_plo_phi() {\n        assert_eq(PLO + PHI * TWO_POW_128, 0);\n        let p_bytes = crate::field::modulus_le_bytes();\n        let mut p_low: Field = 0;\n        let mut p_high: Field = 0;\n\n        let mut offset = 1;\n        for i in 0..16 {\n            p_low += (p_bytes[i] as Field) * offset;\n            p_high += (p_bytes[i + 16] as Field) * offset;\n            offset *= 256;\n        }\n        assert_eq(p_low, PLO);\n        assert_eq(p_high, PHI);\n    }\n}\n"
    },
    "178": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/utils/array/append.nr",
      "source": "/// Appends two `BoundedVec`s together, returning one that contains all of the elements of the first one followed by all\n/// of the elements of the second one. The resulting `BoundedVec` can have any arbitrary maximum length, but it must be\n/// large enough to fit all of the elements of both the first and second vectors.\npub fn append<T, let A_LEN: u32, let B_LEN: u32, let DST_LEN: u32>(\n    a: BoundedVec<T, A_LEN>,\n    b: BoundedVec<T, B_LEN>,\n) -> BoundedVec<T, DST_LEN> {\n    let mut dst = BoundedVec::new();\n\n    dst.extend_from_bounded_vec(a);\n    dst.extend_from_bounded_vec(b);\n\n    dst\n}\n\nmod test {\n    use super::append;\n\n    #[test]\n    unconstrained fn append_empty_vecs() {\n        let a: BoundedVec<_, 3> = BoundedVec::new();\n        let b: BoundedVec<_, 14> = BoundedVec::new();\n\n        let result: BoundedVec<Field, 5> = append(a, b);\n\n        assert_eq(result.len(), 0);\n        assert_eq(result.storage(), std::mem::zeroed());\n    }\n\n    #[test]\n    unconstrained fn append_non_empty_vecs() {\n        let a: BoundedVec<_, 3> = BoundedVec::from_array([1, 2, 3]);\n        let b: BoundedVec<_, 14> = BoundedVec::from_array([4, 5, 6]);\n\n        let result: BoundedVec<Field, 8> = append(a, b);\n\n        assert_eq(result.len(), 6);\n        assert_eq(result.storage(), [1, 2, 3, 4, 5, 6, std::mem::zeroed(), std::mem::zeroed()]);\n    }\n\n    #[test(should_fail_with = \"out of bounds\")]\n    unconstrained fn append_non_empty_vecs_insufficient_max_len() {\n        let a: BoundedVec<_, 3> = BoundedVec::from_array([1, 2, 3]);\n        let b: BoundedVec<_, 14> = BoundedVec::from_array([4, 5, 6]);\n\n        let _: BoundedVec<Field, 5> = append(a, b);\n    }\n}\n"
    },
    "18": {
      "path": "std/field/mod.nr",
      "source": "pub mod bn254;\nuse crate::{runtime::is_unconstrained, static_assert};\nuse bn254::lt as bn254_lt;\n\nimpl Field {\n    /// Asserts that `self` can be represented in `bit_size` bits.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{bit_size}`.\n    // docs:start:assert_max_bit_size\n    pub fn assert_max_bit_size<let BIT_SIZE: u32>(self) {\n        // docs:end:assert_max_bit_size\n        static_assert(\n            BIT_SIZE < modulus_num_bits() as u32,\n            \"BIT_SIZE must be less than modulus_num_bits\",\n        );\n        self.__assert_max_bit_size(BIT_SIZE);\n    }\n\n    #[builtin(apply_range_constraint)]\n    fn __assert_max_bit_size(self, bit_size: u32) {}\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This slice will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_le_bits)]\n    fn _to_le_bits<let N: u32>(self: Self) -> [u1; N] {}\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_be_bits)]\n    fn _to_be_bits<let N: u32>(self: Self) -> [u1; N] {}\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This slice will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_le_bits\n    pub fn to_le_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_le_bits\n        let bits = self._to_le_bits();\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[N - 1 - i] != p[N - 1 - i]) {\n                        assert(p[N - 1 - i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_be_bits\n    pub fn to_be_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_be_bits\n        let bits = self._to_be_bits();\n\n        if !is_unconstrained() {\n            // Ensure that the decomposition does not overflow the modulus\n            let p = modulus_be_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[i] != p[i]) {\n                        assert(p[i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its little endian byte decomposition as a `[u8;N]` array\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_le_bytes\n    pub fn to_le_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_le_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_le_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[N - 1 - i] != p[N - 1 - i]) {\n                        assert(bytes[N - 1 - i] < p[N - 1 - i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    /// Decomposes `self` into its big endian byte decomposition as a `[u8;N]` array of length required to represent the field modulus\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_be_bytes\n    pub fn to_be_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_be_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_be_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_be_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[i] != p[i]) {\n                        assert(bytes[i] < p[i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    // docs:start:to_le_radix\n    pub fn to_le_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            static_assert(1 < radix, \"radix must be greater than 1\");\n            static_assert(radix <= 256, \"radix must be less than or equal to 256\");\n            static_assert(radix & (radix - 1) == 0, \"radix must be a power of 2\");\n        }\n        self.__to_le_radix(radix)\n    }\n    // docs:end:to_le_radix\n\n    // docs:start:to_be_radix\n    pub fn to_be_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            crate::assert_constant(radix);\n        }\n        self.__to_be_radix(radix)\n    }\n    // docs:end:to_be_radix\n\n    // `_radix` must be less than 256\n    #[builtin(to_le_radix)]\n    fn __to_le_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    // `_radix` must be less than 256\n    #[builtin(to_be_radix)]\n    fn __to_be_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    // Returns self to the power of the given exponent value.\n    // Caution: we assume the exponent fits into 32 bits\n    // using a bigger bit size impacts negatively the performance and should be done only if the exponent does not fit in 32 bits\n    pub fn pow_32(self, exponent: Field) -> Field {\n        let mut r: Field = 1;\n        let b: [u1; 32] = exponent.to_le_bits();\n\n        for i in 1..33 {\n            r *= r;\n            r = (b[32 - i] as Field) * (r * self) + (1 - b[32 - i] as Field) * r;\n        }\n        r\n    }\n\n    // Parity of (prime) Field element, i.e. sgn0(x mod p) = 0 if x `elem` {0, ..., p-1} is even, otherwise sgn0(x mod p) = 1.\n    pub fn sgn0(self) -> u1 {\n        self as u1\n    }\n\n    pub fn lt(self, another: Field) -> bool {\n        if crate::compat::is_bn254() {\n            bn254_lt(self, another)\n        } else {\n            lt_fallback(self, another)\n        }\n    }\n\n    /// Convert a little endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_le_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n\n    /// Convert a big endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_be_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[N - 1 - i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n}\n\n#[builtin(modulus_num_bits)]\npub comptime fn modulus_num_bits() -> u64 {}\n\n#[builtin(modulus_be_bits)]\npub comptime fn modulus_be_bits() -> [u1] {}\n\n#[builtin(modulus_le_bits)]\npub comptime fn modulus_le_bits() -> [u1] {}\n\n#[builtin(modulus_be_bytes)]\npub comptime fn modulus_be_bytes() -> [u8] {}\n\n#[builtin(modulus_le_bytes)]\npub comptime fn modulus_le_bytes() -> [u8] {}\n\n/// An unconstrained only built in to efficiently compare fields.\n#[builtin(field_less_than)]\nunconstrained fn __field_less_than(x: Field, y: Field) -> bool {}\n\npub(crate) unconstrained fn field_less_than(x: Field, y: Field) -> bool {\n    __field_less_than(x, y)\n}\n\n// Convert a 32 byte array to a field element by modding\npub fn bytes32_to_field(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..16 {\n        high = high + (bytes32[15 - i] as Field) * v;\n        low = low + (bytes32[16 + 15 - i] as Field) * v;\n        v = v * 256;\n    }\n    // Abuse that a % p + b % p = (a + b) % p and that low < p\n    low + high * v\n}\n\nfn lt_fallback(x: Field, y: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unconstrained context\n        unsafe {\n            field_less_than(x, y)\n        }\n    } else {\n        let x_bytes: [u8; 32] = x.to_le_bytes();\n        let y_bytes: [u8; 32] = y.to_le_bytes();\n        let mut x_is_lt = false;\n        let mut done = false;\n        for i in 0..32 {\n            if (!done) {\n                let x_byte = x_bytes[32 - 1 - i] as u8;\n                let y_byte = y_bytes[32 - 1 - i] as u8;\n                let bytes_match = x_byte == y_byte;\n                if !bytes_match {\n                    x_is_lt = x_byte < y_byte;\n                    done = true;\n                }\n            }\n        }\n        x_is_lt\n    }\n}\n\nmod tests {\n    use crate::{panic::panic, runtime};\n    use super::field_less_than;\n\n    #[test]\n    // docs:start:to_be_bits_example\n    fn test_to_be_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_be_bits();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 1, 0]);\n    }\n    // docs:end:to_be_bits_example\n\n    #[test]\n    // docs:start:to_le_bits_example\n    fn test_to_le_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_le_bits();\n        assert_eq(bits, [0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_bits_example\n\n    #[test]\n    // docs:start:to_be_bytes_example\n    fn test_to_be_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_be_bytes();\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_bytes_example\n\n    #[test]\n    // docs:start:to_le_bytes_example\n    fn test_to_le_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_le_bytes();\n        assert_eq(bytes, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_bytes_example\n\n    #[test]\n    // docs:start:to_be_radix_example\n    fn test_to_be_radix() {\n        // 259, in base 256, big endian, is [1, 3].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_be_radix(256);\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 1, 3]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_radix_example\n\n    #[test]\n    // docs:start:to_le_radix_example\n    fn test_to_le_radix() {\n        // 259, in base 256, little endian, is [3, 1].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_le_radix(256);\n        assert_eq(bytes, [3, 1, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_radix_example\n\n    #[test(should_fail_with = \"radix must be greater than 1\")]\n    fn test_to_le_radix_1() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(1);\n        } else {\n            panic(f\"radix must be greater than 1\");\n        }\n    }\n\n    // TODO: Update this test to account for the Brillig restriction that the radix must be greater than 2\n    //#[test]\n    //fn test_to_le_radix_brillig_1() {\n    //    // this test should only fail in constrained mode\n    //    if runtime::is_unconstrained() {\n    //        let field = 1;\n    //        let out: [u8; 8] = field.to_le_radix(1);\n    //        crate::println(out);\n    //        let expected = [0; 8];\n    //        assert(out == expected, \"unexpected result\");\n    //    }\n    //}\n\n    #[test(should_fail_with = \"radix must be a power of 2\")]\n    fn test_to_le_radix_3() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(3);\n        } else {\n            panic(f\"radix must be a power of 2\");\n        }\n    }\n\n    #[test]\n    fn test_to_le_radix_brillig_3() {\n        // this test should only fail in constrained mode\n        if runtime::is_unconstrained() {\n            let field = 1;\n            let out: [u8; 8] = field.to_le_radix(3);\n            let mut expected = [0; 8];\n            expected[0] = 1;\n            assert(out == expected, \"unexpected result\");\n        }\n    }\n\n    #[test(should_fail_with = \"radix must be less than or equal to 256\")]\n    fn test_to_le_radix_512() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(512);\n        } else {\n            panic(f\"radix must be less than or equal to 256\")\n        }\n    }\n\n    // TODO: Update this test to account for the Brillig restriction that the radix must be less than 512\n    //#[test]\n    //fn test_to_le_radix_brillig_512() {\n    //    // this test should only fail in constrained mode\n    //    if runtime::is_unconstrained() {\n    //        let field = 1;\n    //        let out: [u8; 8] = field.to_le_radix(512);\n    //        let mut expected = [0; 8];\n    //        expected[0] = 1;\n    //        assert(out == expected, \"unexpected result\");\n    //    }\n    //}\n\n    #[test]\n    unconstrained fn test_field_less_than() {\n        assert(field_less_than(0, 1));\n        assert(field_less_than(0, 0x100));\n        assert(field_less_than(0x100, 0 - 1));\n        assert(!field_less_than(0 - 1, 0));\n    }\n}\n"
    },
    "181": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/utils/array/subarray.nr",
      "source": "/// Returns `DST_LEN` elements from a source array, starting at `offset`. `DST_LEN` must not be larger than the number\n/// of elements past `offset`.\n///\n/// Examples:\n/// ```\n/// let foo: [Field; 2] = subarray([1, 2, 3, 4, 5], 2);\n/// assert_eq(foo, [3, 4]);\n///\n/// let bar: [Field; 5] = subarray([1, 2, 3, 4, 5], 2); // fails - we can't return 5 elements since only 3 remain\n/// ```\npub fn subarray<T, let SRC_LEN: u32, let DST_LEN: u32>(\n    src: [T; SRC_LEN],\n    offset: u32,\n) -> [T; DST_LEN] {\n    assert(offset + DST_LEN <= SRC_LEN, \"DST_LEN too large for offset\");\n\n    let mut dst: [T; DST_LEN] = std::mem::zeroed();\n    for i in 0..DST_LEN {\n        dst[i] = src[i + offset];\n    }\n\n    dst\n}\n\nmod test {\n    use super::subarray;\n\n    #[test]\n    unconstrained fn subarray_into_empty() {\n        // In all of these cases we're setting DST_LEN to be 0, so we always get back an emtpy array.\n        assert_eq(subarray::<Field, _, _>([], 0), []);\n        assert_eq(subarray([1, 2, 3, 4, 5], 0), []);\n        assert_eq(subarray([1, 2, 3, 4, 5], 2), []);\n    }\n\n    #[test]\n    unconstrained fn subarray_complete() {\n        assert_eq(subarray::<Field, _, _>([], 0), []);\n        assert_eq(subarray([1, 2, 3, 4, 5], 0), [1, 2, 3, 4, 5]);\n    }\n\n    #[test]\n    unconstrained fn subarray_different_end_sizes() {\n        // We implicitly select how many values to read in the size of the return array\n        assert_eq(subarray([1, 2, 3, 4, 5], 1), [2, 3, 4, 5]);\n        assert_eq(subarray([1, 2, 3, 4, 5], 1), [2, 3, 4]);\n        assert_eq(subarray([1, 2, 3, 4, 5], 1), [2, 3]);\n        assert_eq(subarray([1, 2, 3, 4, 5], 1), [2]);\n    }\n\n    #[test(should_fail_with = \"DST_LEN too large for offset\")]\n    unconstrained fn subarray_offset_too_large() {\n        // With an offset of 1 we can only request up to 4 elements\n        let _: [_; 5] = subarray([1, 2, 3, 4, 5], 1);\n    }\n\n    #[test(should_fail)]\n    unconstrained fn subarray_bad_return_value() {\n        assert_eq(subarray([1, 2, 3, 4, 5], 1), [3, 3, 4, 5]);\n    }\n}\n"
    },
    "182": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/utils/array/subbvec.nr",
      "source": "use crate::utils::array;\n\n/// Returns `DST_MAX_LEN` elements from a source BoundedVec, starting at `offset`. `offset` must not be larger than the\n/// original length, and `DST_LEN` must not be larger than the total number of elements past `offset` (including the\n/// zeroed elements past `len()`).\n///\n/// Only elements at the beginning of the vector can be removed: it is not possible to also remove elements at the end\n/// of the vector by passing a value for `DST_LEN` that is smaller than `len() - offset`.\n///\n/// Examples:\n/// ```\n/// let foo = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n/// assert_eq(subbvec(foo, 2), BoundedVec::<_, 8>::from_array([3, 4, 5]));\n///\n/// let bar: BoundedVec<_, 1> = subbvec(foo, 2); // fails - we can't return just 1 element since 3 remain\n/// let baz: BoundedVec<_, 10> = subbvec(foo, 3); // fails - we can't return 10 elements since only 7 remain\n/// ```\npub fn subbvec<T, let SRC_MAX_LEN: u32, let DST_MAX_LEN: u32>(\n    bvec: BoundedVec<T, SRC_MAX_LEN>,\n    offset: u32,\n) -> BoundedVec<T, DST_MAX_LEN> {\n    // from_parts_unchecked does not verify that the elements past len are zeroed, but that is not an issue in our case\n    // because we're constructing the new storage array as a subarray of the original one (which should have zeroed\n    // storage past len), guaranteeing correctness. This is because `subarray` does not allow extending arrays past\n    // their original length.\n    BoundedVec::from_parts_unchecked(array::subarray(bvec.storage(), offset), bvec.len() - offset)\n}\n\nmod test {\n    use super::subbvec;\n\n    #[test]\n    unconstrained fn subbvec_empty() {\n        let bvec = BoundedVec::<Field, 0>::from_array([]);\n        assert_eq(subbvec(bvec, 0), bvec);\n    }\n\n    #[test]\n    unconstrained fn subbvec_complete() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n        assert_eq(subbvec(bvec, 0), bvec);\n\n        let smaller_capacity = BoundedVec::<_, 5>::from_array([1, 2, 3, 4, 5]);\n        assert_eq(subbvec(bvec, 0), smaller_capacity);\n    }\n\n    #[test]\n    unconstrained fn subbvec_partial() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n\n        assert_eq(subbvec(bvec, 2), BoundedVec::<_, 8>::from_array([3, 4, 5]));\n        assert_eq(subbvec(bvec, 2), BoundedVec::<_, 3>::from_array([3, 4, 5]));\n    }\n\n    #[test]\n    unconstrained fn subbvec_into_empty() {\n        let bvec: BoundedVec<_, 10> = BoundedVec::from_array([1, 2, 3, 4, 5]);\n        assert_eq(subbvec(bvec, 5), BoundedVec::<_, 5>::from_array([]));\n    }\n\n    #[test(should_fail)]\n    unconstrained fn subbvec_offset_past_len() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n        let _: BoundedVec<_, 1> = subbvec(bvec, 6);\n    }\n\n    #[test(should_fail)]\n    unconstrained fn subbvec_insufficient_dst_len() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n\n        // We're not providing enough space to hold all of the items inside the original BoundedVec. subbvec can cause\n        // for the capacity to reduce, but not the length (other than by len - offset).\n        let _: BoundedVec<_, 1> = subbvec(bvec, 2);\n    }\n\n    #[test(should_fail_with = \"DST_LEN too large for offset\")]\n    unconstrained fn subbvec_dst_len_causes_enlarge() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n\n        // subbvec does not supprt capacity increases\n        let _: BoundedVec<_, 11> = subbvec(bvec, 0);\n    }\n\n    #[test(should_fail_with = \"DST_LEN too large for offset\")]\n    unconstrained fn subbvec_dst_len_too_large_for_offset() {\n        let bvec = BoundedVec::<_, 10>::from_array([1, 2, 3, 4, 5]);\n\n        // This effectively requests a capacity increase, since there'd be just one element plus the 5 empty slots,\n        // which is less than 7.\n        let _: BoundedVec<_, 7> = subbvec(bvec, 4);\n    }\n}\n"
    },
    "184": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/utils/conversion/bytes_to_fields.nr",
      "source": "use std::static_assert;\n\n// These functions are used to facilitate the conversion of log ciphertext between byte and field representations.\n//\n// `bytes_to_fields` uses fixed-size arrays since encryption contexts have compile-time size information.\n// `bytes_from_fields` uses BoundedVec for flexibility in unconstrained contexts where sizes are dynamic.\n//\n// Together they provide bidirectional conversion between bytes and fields when processing encrypted logs.\n\n/// Converts the input bytes into an array of fields. A Field is ~254 bits meaning that each field can store 31 whole\n/// bytes. Use `bytes_from_fields` to obtain the original bytes array.\n///\n/// The input bytes are chunked into chunks of 31 bytes. Each 31-byte chunk is viewed as big-endian, and is converted\n/// into a Field.\n/// For example, [1, 10, 3, ..., 0] (31 bytes) is encoded as [1 * 256^30 + 10 * 256^29 + 3 * 256^28 + ... + 0]\n/// Note: N must be a multiple of 31 bytes\npub fn bytes_to_fields<let N: u32>(bytes: [u8; N]) -> [Field; N / 31] {\n    // Assert that N is a multiple of 31\n    static_assert(N % 31 == 0, \"N must be a multiple of 31\");\n\n    let mut fields = [0; N / 31];\n\n    // Since N is a multiple of 31, we can simply process all chunks fully\n    for i in 0..N / 31 {\n        let mut field = 0;\n        for j in 0..31 {\n            // Shift the existing value left by 8 bits and add the new byte\n            field = field * 256 + bytes[i * 31 + j] as Field;\n        }\n        fields[i] = field;\n    }\n\n    fields\n}\n\n/// Converts an input BoundedVec of fields into a BoundedVec of bytes in big-endian order. Arbitrary Field arrays\n/// are not allowed: this is assumed to be an array obtained via `bytes_to_fields`, i.e. one that actually represents\n/// bytes. To convert a Field array into bytes, use `fields_to_bytes`.\n///\n/// Each input field must contain at most 31 bytes (this is constrained to be so).\n/// Each field is converted into 31 big-endian bytes, and the resulting 31-byte chunks are concatenated\n/// back together in the order of the original fields.\npub fn bytes_from_fields<let N: u32>(fields: BoundedVec<Field, N>) -> BoundedVec<u8, N * 31> {\n    let mut bytes = BoundedVec::new();\n\n    for i in 0..fields.len() {\n        let field = fields.get(i);\n\n        // We expect that the field contains at most 31 bytes of information.\n        field.assert_max_bit_size::<248>();\n\n        // Now we can safely convert the field to 31 bytes.\n        let field_as_bytes: [u8; 31] = field.to_be_bytes();\n\n        for j in 0..31 {\n            bytes.push(field_as_bytes[j]);\n        }\n    }\n\n    bytes\n}\n\nmod tests {\n    use crate::utils::array::subarray;\n    use super::{bytes_from_fields, bytes_to_fields};\n\n    #[test]\n    unconstrained fn random_bytes_to_fields_and_back(input: [u8; 93]) {\n        let fields = bytes_to_fields(input);\n\n        // At this point in production, the log flies through the system and we get a BoundedVec on the other end.\n        // So we need to convert the field array to a BoundedVec to be able to feed it to the `bytes_from_fields`\n        // function.\n        let fields_as_bounded_vec = BoundedVec::<_, 6>::from_array(fields);\n\n        let bytes_back = bytes_from_fields(fields_as_bounded_vec);\n\n        // Compare the original input with the round-tripped result\n        assert_eq(bytes_back.len(), input.len());\n        assert_eq(subarray(bytes_back.storage(), 0), input);\n    }\n\n    #[test(should_fail_with = \"N must be a multiple of 31\")]\n    unconstrained fn bytes_to_fields_input_length_not_multiple_of_31() {\n        // Try to convert 32 bytes (not a multiple of 31) to fields\n        let _fields = bytes_to_fields([0; 32]);\n    }\n\n}\n"
    },
    "185": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/utils/conversion/fields_to_bytes.nr",
      "source": "// These functions are used to facilitate the conversion of log plaintext represented as fields into bytes and back.\n//\n// `fields_to_bytes` uses fixed-size arrays since encryption contexts have compile-time size information.\n// `fields_from_bytes` uses BoundedVec for flexibility in unconstrained contexts where sizes are dynamic.\n//\n// Together they provide bidirectional conversion between fields and bytes.\n\n/// Converts an input array of fields into a single array of bytes. Use `fields_from_bytes` to obtain the original\n/// field array.\n/// Each field is converted to a 32-byte big-endian array.\n///\n/// For example, if you have a field array [123, 456], it will be converted to a 64-byte array:\n/// [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,123,  // First field (32 bytes)\n///  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,200]  // Second field (32 bytes)\n///\n/// Since a field is ~254 bits, you'll end up with a subtle 2-bit \"gap\" at the big end, every 32 bytes. Be careful\n/// that such a gap doesn't leak information! This could happen if you for example expected the output to be\n/// indistinguishable from random bytes.\npub fn fields_to_bytes<let N: u32>(fields: [Field; N]) -> [u8; 32 * N] {\n    let mut bytes = [0; 32 * N];\n\n    for i in 0..N {\n        let field_as_bytes: [u8; 32] = fields[i].to_be_bytes();\n\n        for j in 0..32 {\n            bytes[i * 32 + j] = field_as_bytes[j];\n        }\n    }\n\n    bytes\n}\n\n/// Converts an input BoundedVec of bytes into a BoundedVec of fields. Arbitrary byte arrays are not allowed: this\n/// is assumed to be an array obtained via `fields_to_bytes`, i.e. one that actually represents fields. To convert\n/// a byte array into Fields, use `bytes_to_fields`.\n///\n/// The input bytes are chunked into chunks of 32 bytes. Each 32-byte chunk is viewed as big-endian, and is converted\n/// into a Field.\n/// For example, [1, 10, 3, ..., 0] (32 bytes) is encoded as [1 * 256^31 + 10 * 256^30 + 3 * 256^29 + ... + 0]\n/// Note 1: N must be a multiple of 32 bytes\n/// Note 2: The max value check code was taken from std::field::to_be_bytes function.\npub fn fields_from_bytes<let N: u32>(bytes: BoundedVec<u8, N>) -> BoundedVec<Field, N / 32> {\n    // Assert that input length is a multiple of 32\n    assert(bytes.len() % 32 == 0, \"Input length must be a multiple of 32\");\n\n    let mut fields = BoundedVec::new();\n\n    let p = std::field::modulus_be_bytes();\n\n    // Since input length is a multiple of 32, we can simply process all chunks fully\n    for i in 0..bytes.len() / 32 {\n        let mut field = 0;\n\n        // Process each byte in the 32-byte chunk\n        let mut ok = false;\n\n        for j in 0..32 {\n            let next_byte = bytes.get(i * 32 + j);\n            field = field * 256 + next_byte as Field;\n\n            if !ok {\n                if next_byte != p[j] {\n                    assert(next_byte < p[j], \"Value does not fit in field\");\n                    ok = true;\n                }\n            }\n        }\n        assert(ok, \"Value does not fit in field\");\n\n        fields.push(field);\n    }\n\n    fields\n}\n\nmod tests {\n    use crate::utils::array::subarray;\n    use super::{fields_from_bytes, fields_to_bytes};\n\n    #[test]\n    unconstrained fn random_fields_to_bytes_and_back(input: [Field; 3]) {\n        // Convert to bytes\n        let bytes = fields_to_bytes(input);\n\n        // At this point in production, the log flies through the system and we get a BoundedVec on the other end.\n        // So we need to convert the field array to a BoundedVec to be able to feed it to the `fields_from_bytes`\n        // function.\n        // 113 is an arbitrary max length that is larger than the input length of 96.\n        let bytes_as_bounded_vec = BoundedVec::<_, 113>::from_array(bytes);\n\n        // Convert back to fields\n        let fields_back = fields_from_bytes(bytes_as_bounded_vec);\n\n        // Compare the original input with the round-tripped result\n        assert_eq(fields_back.len(), input.len());\n        assert_eq(subarray(fields_back.storage(), 0), input);\n    }\n\n    #[test(should_fail_with = \"Input length must be a multiple of 32\")]\n    unconstrained fn to_fields_assert() {\n        // 143 is an arbitrary max length that is larger than 33\n        let input = BoundedVec::<_, 143>::from_array([\n            1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n            25, 26, 27, 28, 29, 30, 31, 32, 33,\n        ]);\n\n        // This should fail since 33 is not a multiple of 32\n        let _fields = fields_from_bytes(input);\n    }\n\n    #[test]\n    unconstrained fn fields_from_bytes_max_value() {\n        let max_field_as_bytes: [u8; 32] = (-1).to_be_bytes();\n        let input = BoundedVec::<_, 32>::from_array(max_field_as_bytes);\n\n        let fields = fields_from_bytes(input);\n\n        // The result should be a largest value storable in a field (-1 since we are modulo-ing)\n        assert_eq(fields.get(0), -1);\n    }\n\n    // In this test we verify that overflow check works by taking the max allowed value, bumping a random byte\n    // and then feeding it to `fields_from_bytes` as input.\n    #[test(should_fail_with = \"Value does not fit in field\")]\n    unconstrained fn fields_from_bytes_overflow(random_value: u8) {\n        let index_of_byte_to_bump = random_value % 32;\n\n        // Obtain the byte representation of the maximum field value\n        let max_field_value_as_bytes: [u8; 32] = (-1).to_be_bytes();\n\n        let byte_to_bump = max_field_value_as_bytes[index_of_byte_to_bump as u32];\n\n        // Skip test execution if the selected byte is already at maximum value (255).\n        // This is acceptable since we are using fuzz testing to generate many test cases.\n        if byte_to_bump != 255 {\n            let mut input = BoundedVec::<_, 32>::from_array(max_field_value_as_bytes);\n\n            // Increment the selected byte to exceed the field's maximum value\n            input.set(index_of_byte_to_bump as u32, byte_to_bump + 1);\n\n            // Attempt the conversion, which should fail due to the value exceeding the field's capacity\n            let _fields = fields_from_bytes(input);\n        }\n    }\n\n}\n"
    },
    "187": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/utils/field.nr",
      "source": "use std::option::Option;\n\nglobal KNOWN_NON_RESIDUE: Field = 5; // This is a non-residue in Noir's native Field.\n\nglobal C1: u32 = 28;\nglobal C3: Field = 40770029410420498293352137776570907027550720424234931066070132305055;\nglobal C5: Field = 19103219067921713944291392827692070036145651957329286315305642004821462161904;\n\n// Power function of two Field arguments of arbitrary size.\n// Adapted from std::field::pow_32.\npub fn pow(x: Field, y: Field) -> Field {\n    let mut r = 1 as Field;\n    let b: [u1; 254] = y.to_le_bits();\n\n    for i in 0..254 {\n        r *= r;\n        r *= (b[254 - 1 - i] as Field) * x + (1 - b[254 - 1 - i] as Field);\n    }\n\n    r\n}\n\n// Boolean indicating whether Field element is a square, i.e. whether there exists a y in Field s.t. x = y*y.\nunconstrained fn is_square(x: Field) -> bool {\n    let v = pow(x, -1 / 2);\n    v * (v - 1) == 0\n}\n\n// Tonelli-Shanks algorithm for computing the square root of a Field element.\n// Requires C1 = max{c: 2^c divides (p-1)}, where p is the order of Field\n// as well as C3 = (C2 - 1)/2, where C2 = (p-1)/(2^c1),\n// and C5 = ZETA^C2, where ZETA is a non-square element of Field.\n// These are pre-computed above as globals.\nunconstrained fn tonelli_shanks_sqrt(x: Field) -> Field {\n    let mut z = pow(x, C3);\n    let mut t = z * z * x;\n    z *= x;\n    let mut b = t;\n    let mut c = C5;\n\n    for i in 0..(C1 - 1) {\n        for _j in 1..(C1 - i - 1) {\n            b *= b;\n        }\n\n        z *= if b == 1 { 1 } else { c };\n\n        c *= c;\n\n        t *= if b == 1 { 1 } else { c };\n\n        b = t;\n    }\n\n    z\n}\n\n// NB: this doesn't return an option, because in the case of there _not_ being a square root, we still want to return a field element that allows us to then assert in the _constrained_ sqrt function that there is no sqrt.\npub unconstrained fn __sqrt(x: Field) -> (bool, Field) {\n    let is_sq = is_square(x);\n    if is_sq {\n        let sqrt = tonelli_shanks_sqrt(x);\n        (true, sqrt)\n    } else {\n        // Demonstrate that x is not a square (a.k.a. a \"quadratic non-residue\").\n        // Facts:\n        // The Legendre symbol (\"LS\") of x, is x^((p-1)/2) (mod p).\n        // - If x is a square, LS(x) = 1\n        // - If x is not a square, LS(x) = -1\n        // - If x = 0, LS(x) = 0.\n        //\n        // Hence:\n        // sq * sq = sq // 1 * 1 = 1\n        // non-sq * non-sq = sq // -1 * -1 = 1\n        // sq * non-sq = non-sq // -1 * 1 = -1\n        //\n        // See: https://en.wikipedia.org/wiki/Legendre_symbol\n        let demo_x_not_square = x * KNOWN_NON_RESIDUE;\n        let not_sqrt = tonelli_shanks_sqrt(demo_x_not_square);\n        (false, not_sqrt)\n    }\n}\n\n// Returns (false, 0) if there is no square root.\n// Returns (true, sqrt) if there is a square root.\npub fn sqrt(x: Field) -> Option<Field> {\n    // Safety: if the hint returns the square root of x, then we simply square it\n    // check the result equals x. If x is not square, we return a value that\n    // enables us to prove that fact (see the `else` clause below).\n    let (is_sq, maybe_sqrt) = unsafe { __sqrt(x) };\n\n    if is_sq {\n        let sqrt = maybe_sqrt;\n        validate_sqrt_hint(x, sqrt);\n        Option::some(sqrt)\n    } else {\n        let not_sqrt_hint = maybe_sqrt;\n        validate_not_sqrt_hint(x, not_sqrt_hint);\n        Option::none()\n    }\n}\n\nfn validate_sqrt_hint(x: Field, hint: Field) {\n    assert(hint * hint == x, f\"The claimed_sqrt {hint} is not the sqrt of x {x}\");\n}\n\nfn validate_not_sqrt_hint(x: Field, hint: Field) {\n    // We need this assertion, because x = 0 would pass the other assertions in this\n    // function, and we don't want people to be able to prove that 0 is not square!\n    assert(x != 0, \"0 has a square root; you cannot claim it is not square\");\n    // Demonstrate that x is not a square (a.k.a. a \"quadratic non-residue\").\n    //\n    // Facts:\n    // The Legendre symbol (\"LS\") of x, is x^((p-1)/2) (mod p).\n    // - If x is a square, LS(x) = 1\n    // - If x is not a square, LS(x) = -1\n    // - If x = 0, LS(x) = 0.\n    //\n    // Hence:\n    // 1. sq * sq = sq // 1 * 1 = 1\n    // 2. non-sq * non-sq = sq // -1 * -1 = 1\n    // 3. sq * non-sq = non-sq // -1 * 1 = -1\n    //\n    // See: https://en.wikipedia.org/wiki/Legendre_symbol\n    //\n    // We want to demonstrate that this below multiplication falls under bullet-point (2):\n    let demo_x_not_square = x * KNOWN_NON_RESIDUE;\n    // I.e. we want to demonstrate that `demo_x_not_square` has Legendre symbol 1\n    // (i.e. that it is a square), so we prove that it is square below.\n    // Why do we want to prove that it has LS 1?\n    // Well, since it was computed with a known-non-residue, its squareness implies we're\n    // in case 2 (something multiplied by a known-non-residue yielding a result which\n    // has a LS of 1), which implies that x must be a non-square. The unconstrained\n    // function gave us the sqrt of demo_x_not_square, so all we need to do is\n    // assert its squareness:\n    assert(\n        hint * hint == demo_x_not_square,\n        f\"The hint {hint} does not demonstrate that {x} is not a square\",\n    );\n}\n\n#[test]\nfn test_sqrt() {\n    let x = 9;\n    let maybe_sqrt = sqrt(x);\n    assert(maybe_sqrt.is_some());\n    let sqrt = maybe_sqrt.unwrap_unchecked();\n    assert((sqrt == 3) | (sqrt == -3));\n}\n\n#[test]\nfn test_non_square() {\n    let x = 5;\n    let maybe_sqrt = sqrt(x);\n    assert(maybe_sqrt.is_none());\n}\n\n#[test]\nunconstrained fn test_known_non_residue_is_actually_a_non_residue_in_the_field() {\n    assert(!is_square(KNOWN_NON_RESIDUE));\n}\n\n#[test]\nfn test_sqrt_0() {\n    let x = 0;\n    let sqrt = sqrt(x).unwrap();\n    assert(sqrt == 0);\n}\n\n#[test]\nfn test_sqrt_1() {\n    let x = 1;\n    let sqrt = sqrt(x).unwrap();\n    assert((sqrt == 1) | (sqrt == -1));\n}\n\n#[test(should_fail_with = \"The claimed_sqrt 0x04 is not the sqrt of x 0x09\")]\nfn test_bad_sqrt_hint_fails() {\n    validate_sqrt_hint(9, 4);\n}\n\n#[test(should_fail_with = \"The hint 0x04 does not demonstrate that 0x0a is not a square\")]\nfn test_bad_not_sqrt_hint_fails() {\n    validate_not_sqrt_hint(10, 4);\n}\n\n#[test(should_fail_with = \"0 has a square root; you cannot claim it is not square\")]\nfn test_0_not_sqrt_hint_fails() {\n    validate_not_sqrt_hint(0, 0);\n}\n\n#[test]\nunconstrained fn test_is_square() {\n    assert(is_square(25));\n}\n\n#[test]\nunconstrained fn test_is_not_square() {\n    assert(!is_square(10));\n}\n"
    },
    "189": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/utils/point.nr",
      "source": "use crate::utils::field::sqrt;\nuse dep::protocol_types::point::Point;\n\n// I am storing the modulus minus 1 divided by 2 here because full modulus would throw \"String literal too large\" error\n// Full modulus is 21888242871839275222246405745257275088548364400416034343698204186575808495617\nglobal BN254_FR_MODULUS_DIV_2: Field =\n    10944121435919637611123202872628637544274182200208017171849102093287904247808;\n\n/// Converts a point to a byte array.\n///\n/// We don't serialize the point at infinity flag because this function is used in situations where we do not want\n/// to waste the extra byte (encrypted log).\npub fn point_to_bytes(p: Point) -> [u8; 32] {\n    // Note that there is 1 more free bit in the 32 bytes (254 bits currently occupied by the x coordinate, 1 bit for\n    // the \"sign\") so it's possible to use that last bit as an \"is_infinite\" flag if desired in the future.\n    assert(!p.is_infinite, \"Cannot serialize point at infinity as bytes.\");\n\n    let mut result: [u8; 32] = p.x.to_be_bytes();\n\n    if get_sign_of_point(p) {\n        // y is <= (modulus - 1) / 2 so we set the sign bit to 1\n        // Here we leverage that field fits into 254 bits (log2(Fr.MODULUS) < 254) and given that we serialize Fr to 32\n        // bytes and we use big-endian the 2 most significant bits are never populated. Hence we can use one of\n        // the bits as a sign bit.\n        result[0] += 128;\n    }\n\n    result\n}\n\n/**\n * Returns: true if p.y <= MOD_DIV_2, else false.\n */\npub fn get_sign_of_point(p: Point) -> bool {\n    // We store only a \"sign\" of the y coordinate because the rest can be derived from the x coordinate. To get\n    // the sign we check if the y coordinate is less or equal than the curve's order minus 1 divided by 2.\n    // Ideally we'd do `y <= MOD_DIV_2`, but there's no `lte` function, so instead we do `!(y > MOD_DIV_2)`, which is\n    // equivalent, and then rewrite that as `!(MOD_DIV_2 < y)`, since we also have no `gt` function.\n    !BN254_FR_MODULUS_DIV_2.lt(p.y)\n}\n\npub fn point_from_x_coord(x: Field) -> Point {\n    // y ^ 2 = x ^ 3 - 17\n    let rhs = x * x * x - 17;\n    let y = sqrt(rhs).unwrap();\n    Point { x, y, is_infinite: false }\n}\n\n/// Uses the x coordinate and sign flag (+/-) to reconstruct the point.\n/// The y coordinate can be derived from the x coordinate and the \"sign\" flag by solving the grumpkin curve\n/// equation for y.\n/// @param x - The x coordinate of the point\n/// @param sign - The \"sign\" of the y coordinate - determines whether y <= (Fr.MODULUS - 1) / 2\npub fn point_from_x_coord_and_sign(x: Field, sign: bool) -> Point {\n    // y ^ 2 = x ^ 3 - 17\n    let rhs = x * x * x - 17;\n    let y = sqrt(rhs).unwrap();\n\n    // If y > MOD_DIV_2 and we want positive sign (or vice versa), negate y\n    let y_is_positive = !BN254_FR_MODULUS_DIV_2.lt(y);\n    let final_y = if y_is_positive == sign { y } else { -y };\n\n    Point { x, y: final_y, is_infinite: false }\n}\n\nmod test {\n    use crate::utils::point::{point_from_x_coord_and_sign, point_to_bytes};\n    use dep::protocol_types::point::Point;\n\n    #[test]\n    unconstrained fn test_point_to_bytes_positive_sign() {\n        let p = Point {\n            x: 0x1af41f5de96446dc3776a1eb2d98bb956b7acd9979a67854bec6fa7c2973bd73,\n            y: 0x07fc22c7f2c7057571f137fe46ea9c95114282bc95d37d71ec4bfb88de457d4a,\n            is_infinite: false,\n        };\n\n        let compressed_point = point_to_bytes(p);\n\n        let expected_compressed_point_positive_sign = [\n            154, 244, 31, 93, 233, 100, 70, 220, 55, 118, 161, 235, 45, 152, 187, 149, 107, 122,\n            205, 153, 121, 166, 120, 84, 190, 198, 250, 124, 41, 115, 189, 115,\n        ];\n        assert_eq(expected_compressed_point_positive_sign, compressed_point);\n    }\n\n    #[test]\n    unconstrained fn test_point_to_bytes_negative_sign() {\n        let p = Point {\n            x: 0x247371652e55dd74c9af8dbe9fb44931ba29a9229994384bd7077796c14ee2b5,\n            y: 0x26441aec112e1ae4cee374f42556932001507ad46e255ffb27369c7e3766e5c0,\n            is_infinite: false,\n        };\n\n        let compressed_point = point_to_bytes(p);\n\n        let expected_compressed_point_negative_sign = [\n            36, 115, 113, 101, 46, 85, 221, 116, 201, 175, 141, 190, 159, 180, 73, 49, 186, 41, 169,\n            34, 153, 148, 56, 75, 215, 7, 119, 150, 193, 78, 226, 181,\n        ];\n\n        assert_eq(expected_compressed_point_negative_sign, compressed_point);\n    }\n\n    #[test]\n    unconstrained fn test_point_from_x_coord_and_sign() {\n        // Test positive y coordinate\n        let x = 0x1af41f5de96446dc3776a1eb2d98bb956b7acd9979a67854bec6fa7c2973bd73;\n        let sign = true;\n        let p = point_from_x_coord_and_sign(x, sign);\n\n        assert_eq(p.x, x);\n        assert_eq(p.y, 0x07fc22c7f2c7057571f137fe46ea9c95114282bc95d37d71ec4bfb88de457d4a);\n        assert_eq(p.is_infinite, false);\n\n        // Test negative y coordinate\n        let x2 = 0x247371652e55dd74c9af8dbe9fb44931ba29a9229994384bd7077796c14ee2b5;\n        let sign2 = false;\n        let p2 = point_from_x_coord_and_sign(x2, sign2);\n\n        assert_eq(p2.x, x2);\n        assert_eq(p2.y, 0x26441aec112e1ae4cee374f42556932001507ad46e255ffb27369c7e3766e5c0);\n        assert_eq(p2.is_infinite, false);\n    }\n}\n"
    },
    "200": {
      "path": "/Users/satyam/nargo/github.com/noir-lang/poseidon/v0.1.0/src/poseidon2.nr",
      "source": "use std::default::Default;\nuse std::hash::Hasher;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field; 3],\n    state: [Field; 4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        Poseidon2::hash_internal(input, message_size, message_size != N)\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result =\n            Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(\n        input: [Field; N],\n        in_len: u32,\n        is_variable_length: bool,\n    ) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv: Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher {\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv: Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n"
    },
    "217": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/noir-protocol-circuits/crates/types/src/abis/event_selector.nr",
      "source": "use crate::traits::{Deserialize, Empty, FromField, Serialize, ToField};\n\npub struct EventSelector {\n    // 1st 4-bytes (big-endian leftmost) of abi-encoding of an event.\n    inner: u32,\n}\n\nimpl Eq for EventSelector {\n    fn eq(self, other: EventSelector) -> bool {\n        other.inner == self.inner\n    }\n}\n\nimpl Serialize<1> for EventSelector {\n    fn serialize(self: Self) -> [Field; 1] {\n        [self.inner as Field]\n    }\n}\n\nimpl Deserialize<1> for EventSelector {\n    fn deserialize(fields: [Field; 1]) -> Self {\n        Self { inner: fields[0] as u32 }\n    }\n}\n\nimpl FromField for EventSelector {\n    fn from_field(field: Field) -> Self {\n        Self { inner: field as u32 }\n    }\n}\n\nimpl ToField for EventSelector {\n    fn to_field(self) -> Field {\n        self.inner as Field\n    }\n}\n\nimpl Empty for EventSelector {\n    fn empty() -> Self {\n        Self { inner: 0 as u32 }\n    }\n}\n\nimpl EventSelector {\n    pub fn from_u32(value: u32) -> Self {\n        Self { inner: value }\n    }\n\n    pub fn from_signature<let N: u32>(signature: str<N>) -> Self {\n        let bytes = signature.as_bytes();\n        let hash = crate::hash::poseidon2_hash_bytes(bytes);\n\n        // `hash` is automatically truncated to fit within 32 bits.\n        EventSelector::from_field(hash)\n    }\n\n    pub fn zero() -> Self {\n        Self { inner: 0 }\n    }\n}\n"
    },
    "262": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/noir-protocol-circuits/crates/types/src/address/aztec_address.nr",
      "source": "use crate::{\n    address::{\n        partial_address::PartialAddress, salted_initialization_hash::SaltedInitializationHash,\n    },\n    constants::{\n        AZTEC_ADDRESS_LENGTH, GENERATOR_INDEX__CONTRACT_ADDRESS_V1, MAX_FIELD_VALUE,\n        MAX_PROTOCOL_CONTRACTS,\n    },\n    contract_class_id::ContractClassId,\n    hash::poseidon2_hash_with_separator,\n    public_keys::{IvpkM, NpkM, OvpkM, PublicKeys, ToPoint, TpkM},\n    traits::{Deserialize, Empty, FromField, Packable, Serialize, ToField},\n    utils::field::{pow, sqrt},\n};\n\n// We do below because `use crate::point::Point;` does not work\nuse dep::std::embedded_curve_ops::EmbeddedCurvePoint as Point;\n\nuse crate::public_keys::AddressPoint;\nuse std::{\n    embedded_curve_ops::{EmbeddedCurveScalar, fixed_base_scalar_mul as derive_public_key},\n    ops::Add,\n};\n\n// Aztec address\npub struct AztecAddress {\n    pub inner: Field,\n}\n\nimpl Eq for AztecAddress {\n    fn eq(self, other: Self) -> bool {\n        self.to_field() == other.to_field()\n    }\n}\n\nimpl Empty for AztecAddress {\n    fn empty() -> Self {\n        Self { inner: 0 }\n    }\n}\n\nimpl ToField for AztecAddress {\n    fn to_field(self) -> Field {\n        self.inner\n    }\n}\n\nimpl FromField for AztecAddress {\n    fn from_field(value: Field) -> AztecAddress {\n        AztecAddress { inner: value }\n    }\n}\n\nimpl Serialize<AZTEC_ADDRESS_LENGTH> for AztecAddress {\n    fn serialize(self: Self) -> [Field; AZTEC_ADDRESS_LENGTH] {\n        [self.to_field()]\n    }\n}\n\nimpl Deserialize<AZTEC_ADDRESS_LENGTH> for AztecAddress {\n    fn deserialize(fields: [Field; AZTEC_ADDRESS_LENGTH]) -> Self {\n        FromField::from_field(fields[0])\n    }\n}\n\n/// We implement the Packable trait for AztecAddress because it can be stored in contract's storage (and there\n/// the implementation of Packable is required).\nimpl Packable<AZTEC_ADDRESS_LENGTH> for AztecAddress {\n    fn pack(self) -> [Field; AZTEC_ADDRESS_LENGTH] {\n        self.serialize()\n    }\n\n    fn unpack(fields: [Field; AZTEC_ADDRESS_LENGTH]) -> Self {\n        Self::deserialize(fields)\n    }\n}\n\nimpl AztecAddress {\n    pub fn zero() -> Self {\n        Self { inner: 0 }\n    }\n\n    pub fn to_address_point(self) -> AddressPoint {\n        // We compute the address point by taking our address, setting it to x, and then solving for y in the\n        // equation which defines our bn curve:\n        // y^2 = x^3 - 17; x = address\n        let x = self.inner;\n        let y_squared = pow(x, 3) - 17;\n\n        // TODO (#8970): Handle cases where we cannot recover a point from an address\n        let mut y = sqrt(y_squared);\n\n        // If we get a negative y coordinate (any y where y > MAX_FIELD_VALUE / 2), we pin it to the\n        // positive one (any value where y <= MAX_FIELD_VALUE / 2) by subtracting it from the Field modulus\n        // note: The field modulus is MAX_FIELD_VALUE + 1\n        if (!(y.lt(MAX_FIELD_VALUE / 2) | y.eq(MAX_FIELD_VALUE / 2))) {\n            y = (MAX_FIELD_VALUE + 1) - y;\n        }\n\n        AddressPoint { inner: Point { x: self.inner, y, is_infinite: false } }\n    }\n\n    pub fn compute(public_keys: PublicKeys, partial_address: PartialAddress) -> AztecAddress {\n        let public_keys_hash = public_keys.hash();\n\n        let pre_address = poseidon2_hash_with_separator(\n            [public_keys_hash.to_field(), partial_address.to_field()],\n            GENERATOR_INDEX__CONTRACT_ADDRESS_V1,\n        );\n\n        let address_point = derive_public_key(EmbeddedCurveScalar::from_field(pre_address)).add(\n            public_keys.ivpk_m.to_point(),\n        );\n\n        // Note that our address is only the x-coordinate of the full address_point. This is okay because when people want to encrypt something and send it to us\n        // they can recover our full point using the x-coordinate (our address itself). To do this, they recompute the y-coordinate according to the equation y^2 = x^3 - 17.\n        // When they do this, they may get a positive y-coordinate (a value that is less than or equal to MAX_FIELD_VALUE / 2) or\n        // a negative y-coordinate (a value that is more than MAX_FIELD_VALUE), and we cannot dictate which one they get and hence the recovered point may sometimes be different than the one\n        // our secret can decrypt. Regardless though, they should and will always encrypt using point with the positive y-coordinate by convention.\n        // This ensures that everyone encrypts to the same point given an arbitrary x-coordinate (address). This is allowed because even though our original point may not have a positive y-coordinate,\n        // with our original secret, we will be able to derive the secret to the point with the flipped (and now positive) y-coordinate that everyone encrypts to.\n        AztecAddress::from_field(address_point.x)\n    }\n\n    pub fn compute_from_class_id(\n        contract_class_id: ContractClassId,\n        salted_initialization_hash: SaltedInitializationHash,\n        public_keys: PublicKeys,\n    ) -> Self {\n        let partial_address = PartialAddress::compute_from_salted_initialization_hash(\n            contract_class_id,\n            salted_initialization_hash,\n        );\n\n        AztecAddress::compute(public_keys, partial_address)\n    }\n\n    pub fn is_protocol_contract(self) -> bool {\n        self.inner.lt(MAX_PROTOCOL_CONTRACTS as Field)\n    }\n\n    pub fn is_zero(self) -> bool {\n        self.inner == 0\n    }\n\n    pub fn assert_is_zero(self) {\n        assert(self.to_field() == 0);\n    }\n}\n\n#[test]\nfn compute_address_from_partial_and_pub_keys() {\n    let public_keys = PublicKeys {\n        npk_m: NpkM {\n            inner: Point {\n                x: 0x22f7fcddfa3ce3e8f0cc8e82d7b94cdd740afa3e77f8e4a63ea78a239432dcab,\n                y: 0x0471657de2b6216ade6c506d28fbc22ba8b8ed95c871ad9f3e3984e90d9723a7,\n                is_infinite: false,\n            },\n        },\n        ivpk_m: IvpkM {\n            inner: Point {\n                x: 0x111223493147f6785514b1c195bb37a2589f22a6596d30bb2bb145fdc9ca8f1e,\n                y: 0x273bbffd678edce8fe30e0deafc4f66d58357c06fd4a820285294b9746c3be95,\n                is_infinite: false,\n            },\n        },\n        ovpk_m: OvpkM {\n            inner: Point {\n                x: 0x09115c96e962322ffed6522f57194627136b8d03ac7469109707f5e44190c484,\n                y: 0x0c49773308a13d740a7f0d4f0e6163b02c5a408b6f965856b6a491002d073d5b,\n                is_infinite: false,\n            },\n        },\n        tpk_m: TpkM {\n            inner: Point {\n                x: 0x00d3d81beb009873eb7116327cf47c612d5758ef083d4fda78e9b63980b2a762,\n                y: 0x2f567d22d2b02fe1f4ad42db9d58a36afd1983e7e2909d1cab61cafedad6193a,\n                is_infinite: false,\n            },\n        },\n    };\n\n    let partial_address = PartialAddress::from_field(\n        0x0a7c585381b10f4666044266a02405bf6e01fa564c8517d4ad5823493abd31de,\n    );\n\n    let address = AztecAddress::compute(public_keys, partial_address);\n\n    // The following value was generated by `derivation.test.ts`.\n    // --> Run the test with AZTEC_GENERATE_TEST_DATA=1 flag to update test data.\n    let expected_computed_address_from_partial_and_pubkeys =\n        0x24e4646f58b9fbe7d38e317db8d5636c423fbbdfbe119fc190fe9c64747e0c62;\n    assert(address.to_field() == expected_computed_address_from_partial_and_pubkeys);\n}\n\n#[test]\nfn compute_preaddress_from_partial_and_pub_keys() {\n    let pre_address = poseidon2_hash_with_separator([1, 2], GENERATOR_INDEX__CONTRACT_ADDRESS_V1);\n    let expected_computed_preaddress_from_partial_and_pubkey =\n        0x23ce9be3fa3c846b0f9245cc796902e731d04f086e8a42473bb29e405fc98075;\n    assert(pre_address == expected_computed_preaddress_from_partial_and_pubkey);\n}\n\n#[test]\nfn from_field_to_field() {\n    let address = AztecAddress { inner: 37 };\n    assert_eq(FromField::from_field(address.to_field()), address);\n}\n\n#[test]\nfn serde() {\n    let address = AztecAddress { inner: 37 };\n    assert_eq(Deserialize::deserialize(address.serialize()), address);\n}\n"
    },
    "279": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/noir-protocol-circuits/crates/types/src/debug_log.nr",
      "source": "/// Utility function to console.log data in the acir simulator.\n/// Example:\n///   debug_log(\"blah blah this is a debug string\");\npub fn debug_log<let N: u32>(msg: str<N>) {\n    debug_log_format(msg, []);\n}\n\n/// Utility function to console.log data in the acir simulator. This variant receives a format string in which the\n/// `${k}` tokens will be replaced with the k-eth value in the `args` array.\n/// Examples:\n///   debug_log_format(\"get_2(slot:{0}) =>\\n\\t0:{1}\\n\\t1:{2}\", [storage_slot, note0_hash, note1_hash]);\n///   debug_log_format(\"whole array: {}\", [e1, e2, e3, e4]);\npub fn debug_log_format<let M: u32, let N: u32>(msg: str<M>, args: [Field; N]) {\n    // Safety: This oracle call returns nothing: we only call it for its side effects. It is therefore always safe\n    // to call.\n    unsafe { debug_log_oracle_wrapper(msg, args) };\n}\n\npub unconstrained fn debug_log_oracle_wrapper<let M: u32, let N: u32>(\n    msg: str<M>,\n    args: [Field; N],\n) {\n    debug_log_oracle(msg, args.as_slice());\n}\n\n// WARNING: sometimes when using debug logs the ACVM errors with: `thrown: \"solver opcode resolution error: cannot solve opcode: expression has too many unknowns x155\"`\n#[oracle(debugLog)]\nunconstrained fn debug_log_oracle<let M: u32>(_msg: str<M>, args: [Field]) {}\n"
    },
    "280": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/noir-protocol-circuits/crates/types/src/hash.nr",
      "source": "use crate::{\n    abis::{\n        contract_class_function_leaf_preimage::ContractClassFunctionLeafPreimage,\n        contract_class_log::ContractClassLog,\n        function_selector::FunctionSelector,\n        note_hash::ScopedNoteHash,\n        nullifier::ScopedNullifier,\n        private_log::{PrivateLog, PrivateLogData},\n        side_effect::{OrderedValue, scoped::Scoped},\n    },\n    address::{AztecAddress, EthAddress},\n    constants::{\n        CONTRACT_CLASS_LOG_SIZE_IN_FIELDS, FUNCTION_TREE_HEIGHT, GENERATOR_INDEX__NOTE_HASH_NONCE,\n        GENERATOR_INDEX__OUTER_NULLIFIER, GENERATOR_INDEX__SILOED_NOTE_HASH,\n        GENERATOR_INDEX__UNIQUE_NOTE_HASH, TWO_POW_64,\n    },\n    merkle_tree::root::root_from_sibling_path,\n    messaging::l2_to_l1_message::{L2ToL1Message, ScopedL2ToL1Message},\n    poseidon2::Poseidon2Sponge,\n    traits::{FromField, Hash, ToField},\n    utils::{arrays::array_concat, field::{field_from_bytes, field_from_bytes_32_trunc}},\n};\n\npub fn sha256_to_field<let N: u32>(bytes_to_hash: [u8; N]) -> Field {\n    let sha256_hashed = sha256::digest(bytes_to_hash);\n    let hash_in_a_field = field_from_bytes_32_trunc(sha256_hashed);\n\n    hash_in_a_field\n}\n\npub fn private_functions_root_from_siblings(\n    selector: FunctionSelector,\n    vk_hash: Field,\n    function_leaf_index: Field,\n    function_leaf_sibling_path: [Field; FUNCTION_TREE_HEIGHT],\n) -> Field {\n    let function_leaf_preimage = ContractClassFunctionLeafPreimage { selector, vk_hash };\n    let function_leaf = function_leaf_preimage.hash();\n    root_from_sibling_path(\n        function_leaf,\n        function_leaf_index,\n        function_leaf_sibling_path,\n    )\n}\n\npub fn compute_note_hash_nonce(first_nullifier_in_tx: Field, note_index_in_tx: u32) -> Field {\n    // Hashing the first nullifier with note index in tx is guaranteed to be unique (because all nullifiers are also\n    // unique).\n    poseidon2_hash_with_separator(\n        [first_nullifier_in_tx, note_index_in_tx as Field],\n        GENERATOR_INDEX__NOTE_HASH_NONCE,\n    )\n}\n\npub fn compute_unique_note_hash(nonce: Field, siloed_note_hash: Field) -> Field {\n    let inputs = [nonce, siloed_note_hash];\n    poseidon2_hash_with_separator(inputs, GENERATOR_INDEX__UNIQUE_NOTE_HASH)\n}\n\npub fn compute_siloed_note_hash(app: AztecAddress, note_hash: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [app.to_field(), note_hash],\n        GENERATOR_INDEX__SILOED_NOTE_HASH,\n    )\n}\n\n/// Computes unique note hashes from siloed note hashes\npub fn compute_unique_siloed_note_hash(\n    siloed_note_hash: Field,\n    first_nullifier: Field,\n    note_index_in_tx: u32,\n) -> Field {\n    if siloed_note_hash == 0 {\n        0\n    } else {\n        let nonce = compute_note_hash_nonce(first_nullifier, note_index_in_tx);\n        compute_unique_note_hash(nonce, siloed_note_hash)\n    }\n}\n\n/// Siloing in the context of Aztec refers to the process of hashing a note hash with a contract address (this way\n/// the note hash is scoped to a specific contract). This is used to prevent intermingling of notes between contracts.\npub fn silo_note_hash(note_hash: ScopedNoteHash) -> Field {\n    if note_hash.contract_address.is_zero() {\n        0\n    } else {\n        compute_siloed_note_hash(note_hash.contract_address, note_hash.value())\n    }\n}\n\npub fn compute_siloed_nullifier(app: AztecAddress, nullifier: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [app.to_field(), nullifier],\n        GENERATOR_INDEX__OUTER_NULLIFIER,\n    )\n}\n\npub fn silo_nullifier(nullifier: ScopedNullifier) -> Field {\n    if nullifier.contract_address.is_zero() {\n        nullifier.value() // Return value instead of 0 because the first nullifier's contract address is zero.\n    } else {\n        compute_siloed_nullifier(nullifier.contract_address, nullifier.value())\n    }\n}\n\npub fn compute_siloed_private_log_field(contract_address: AztecAddress, field: Field) -> Field {\n    poseidon2_hash([contract_address.to_field(), field])\n}\n\npub fn silo_private_log(private_log: Scoped<PrivateLogData>) -> PrivateLog {\n    if private_log.contract_address.is_zero() {\n        private_log.inner.log\n    } else {\n        let mut fields = private_log.inner.log.fields;\n        fields[0] = compute_siloed_private_log_field(private_log.contract_address, fields[0]);\n        PrivateLog::new(fields, private_log.inner.log.length)\n    }\n}\n\npub fn compute_siloed_contract_class_log_field(\n    contract_address: AztecAddress,\n    first_field: Field,\n) -> Field {\n    poseidon2_hash([contract_address.to_field(), first_field])\n}\n\npub fn silo_contract_class_log(contract_class_log: ContractClassLog) -> ContractClassLog {\n    if contract_class_log.contract_address.is_zero() {\n        contract_class_log\n    } else {\n        let mut log = contract_class_log;\n        log.log.fields[0] = compute_siloed_contract_class_log_field(\n            contract_class_log.contract_address,\n            log.log.fields[0],\n        );\n        log\n    }\n}\n\npub fn compute_contract_class_log_hash(log: [Field; CONTRACT_CLASS_LOG_SIZE_IN_FIELDS]) -> Field {\n    poseidon2_hash(log)\n}\n\npub fn merkle_hash(left: Field, right: Field) -> Field {\n    poseidon2_hash([left, right])\n}\n\npub fn compute_l2_to_l1_hash(\n    contract_address: AztecAddress,\n    recipient: EthAddress,\n    content: Field,\n    rollup_version_id: Field,\n    chain_id: Field,\n) -> Field {\n    let mut bytes: [u8; 160] = std::mem::zeroed();\n\n    let inputs =\n        [contract_address.to_field(), rollup_version_id, recipient.to_field(), chain_id, content];\n    for i in 0..5 {\n        // TODO are bytes be in fr.to_buffer() ?\n        let item_bytes: [u8; 32] = inputs[i].to_be_bytes();\n        for j in 0..32 {\n            bytes[32 * i + j] = item_bytes[j];\n        }\n    }\n\n    sha256_to_field(bytes)\n}\n\npub fn silo_l2_to_l1_message(\n    msg: ScopedL2ToL1Message,\n    rollup_version_id: Field,\n    chain_id: Field,\n) -> Field {\n    if msg.contract_address.is_zero() {\n        0\n    } else {\n        compute_l2_to_l1_hash(\n            msg.contract_address,\n            msg.message.recipient,\n            msg.message.content,\n            rollup_version_id,\n            chain_id,\n        )\n    }\n}\n\n// Computes sha256 hash of 2 input hashes.\n//\n// NB: This method now takes in two 31 byte fields - it assumes that any input\n// is the result of a sha_to_field hash and => is truncated\n//\n// TODO(Jan and David): This is used for the encrypted_log hashes.\n// Can we check to see if we can just use hash_to_field or pedersen_compress here?\n//\npub fn accumulate_sha256(input: [Field; 2]) -> Field {\n    // This is a note about the cpp code, since it takes an array of Fields\n    // instead of a u128.\n    // 4 Field elements when converted to bytes will usually\n    // occupy 4 * 32 = 128 bytes.\n    // However, this function is making the assumption that each Field\n    // only occupies 128 bits.\n    //\n    // TODO(David): This does not seem to be getting guaranteed anywhere in the code?\n    // Concatentate two fields into 32x2 = 64 bytes\n    // accumulate_sha256 assumes that the inputs are pre-truncated 31 byte numbers\n    let mut hash_input_flattened = [0; 64];\n    for offset in 0..input.len() {\n        let input_as_bytes: [u8; 32] = input[offset].to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n\n    sha256_to_field(hash_input_flattened)\n}\n\npub fn verification_key_hash<let N: u32>(key: [Field; N]) -> Field {\n    crate::hash::poseidon2_hash(key)\n}\n\n#[inline_always]\npub fn pedersen_hash<let N: u32>(inputs: [Field; N], hash_index: u32) -> Field {\n    std::hash::pedersen_hash_with_separator(inputs, hash_index)\n}\n\npub fn poseidon2_hash<let N: u32>(inputs: [Field; N]) -> Field {\n    poseidon::poseidon2::Poseidon2::hash(inputs, N)\n}\n\n#[no_predicates]\npub fn poseidon2_hash_with_separator<let N: u32, T>(inputs: [Field; N], separator: T) -> Field\nwhere\n    T: ToField,\n{\n    let inputs_with_separator = array_concat([separator.to_field()], inputs);\n    poseidon2_hash(inputs_with_separator)\n}\n\n// Performs a fixed length hash with a subarray of the given input.\n// Useful for SpongeBlob in which we aborb M things and want to check it vs a hash of M elts of an N-len array.\n// Using stdlib poseidon, this will always absorb an extra 1 as a 'variable' hash, and not match spongeblob.squeeze()\n// or any ts implementation. Also checks that any remaining elts not hashed are empty.\n#[no_predicates]\npub fn poseidon2_hash_subarray<let N: u32>(input: [Field; N], in_len: u32) -> Field {\n    let mut sponge = poseidon2_absorb_chunks(input, in_len, false);\n    sponge.squeeze()\n}\n\n// NB the below is the same as poseidon::poseidon2::Poseidon2::hash(), but replacing a range check with a bit check,\n// and absorbing in chunks of 3 below.\n#[no_predicates]\npub fn poseidon2_cheaper_variable_hash<let N: u32>(input: [Field; N], in_len: u32) -> Field {\n    let mut sponge = poseidon2_absorb_chunks(input, in_len, true);\n    // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n    // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n    // fixed-length and variable-length hashes do not collide)\n    if in_len != N {\n        sponge.absorb(1);\n    }\n    sponge.squeeze()\n}\n\n// The below fn reduces gates of a conditional poseidon2 hash by approx 3x (thank you ~* Giant Brain Dev @IlyasRidhuan *~ for the idea)\n// Why? Because when we call stdlib poseidon, we call absorb for each item. When absorbing is conditional, it seems the compiler does not know\n// what cache_size will be when calling absorb, so it assigns the permutation gates for /each i/ rather than /every 3rd i/, which is actually required.\n// The below code forces the compiler to:\n//  - absorb normally up to 2 times to set cache_size to 1\n//  - absorb in chunks of 3 to ensure perm. only happens every 3rd absorb\n//  - absorb normally up to 2 times to add any remaining values to the hash\n// In fixed len hashes, the compiler is able to tell that it will only need to perform the permutation every 3 absorbs.\n// NB: it also replaces unnecessary range checks (i < thing) with a bit check (&= i != thing), which alone reduces the gates of a var. hash by half.\n\n#[no_predicates]\nfn poseidon2_absorb_chunks<let N: u32>(\n    input: [Field; N],\n    in_len: u32,\n    variable: bool,\n) -> Poseidon2Sponge {\n    let iv: Field = (in_len as Field) * TWO_POW_64;\n    let mut sponge = Poseidon2Sponge::new(iv);\n    // Even though shift is always 1 here, if we input in_len = 0 we get an underflow\n    // since we cannot isolate computation branches. The below is just to avoid that.\n    let shift = if in_len == 0 { 0 } else { 1 };\n    if in_len != 0 {\n        // cache_size = 0, init absorb\n        sponge.cache[0] = input[0];\n        sponge.cache_size = 1;\n        // shift = num elts already added to make cache_size 1 = 1 for a fresh sponge\n        // M = max_chunks = (N - 1 - (N - 1) % 3) / 3: (must be written as a fn of N to compile)\n        // max_remainder = (N - 1) % 3;\n        // max_chunks = (N - 1 - max_remainder) / 3;\n        sponge = poseidon2_absorb_chunks_loop::<N, (N - 1 - (N - 1) % 3) / 3>(\n            sponge,\n            input,\n            in_len,\n            variable,\n            shift,\n        );\n    }\n    sponge\n}\n\n// NB: If it's not required to check that the non-absorbed elts of 'input' are 0s, set skip_0_check=true\n#[no_predicates]\npub fn poseidon2_absorb_chunks_existing_sponge<let N: u32>(\n    in_sponge: Poseidon2Sponge,\n    input: [Field; N],\n    in_len: u32,\n    skip_0_check: bool,\n) -> Poseidon2Sponge {\n    let mut sponge = in_sponge;\n    // 'shift' is to account for already added inputs\n    let mut shift = 0;\n    // 'stop' is to avoid an underflow when inputting in_len = 0\n    let mut stop = false;\n    for i in 0..3 {\n        if shift == in_len {\n            stop = true;\n        }\n        if (sponge.cache_size != 1) & (!stop) {\n            sponge.absorb(input[i]);\n            shift += 1;\n        }\n    }\n    sponge = if stop {\n        sponge\n    } else {\n        // max_chunks = (N - (N % 3)) / 3;\n        poseidon2_absorb_chunks_loop::<N, (N - (N % 3)) / 3>(\n            sponge,\n            input,\n            in_len,\n            skip_0_check,\n            shift,\n        )\n    };\n    sponge\n}\n\n// The below is the loop to absorb elts into a poseidon sponge in chunks of 3\n// shift - the num of elts already absorbed to ensure the sponge's cache_size = 1\n// M - the max number of chunks required to absorb N things (must be comptime to compile)\n// NB: The 0 checks ('Found non-zero field...') are messy, but having a separate loop over N to check\n// for 0s costs 3N gates. Current approach is approx 2N gates.\n#[no_predicates]\nfn poseidon2_absorb_chunks_loop<let N: u32, let M: u32>(\n    in_sponge: Poseidon2Sponge,\n    input: [Field; N],\n    in_len: u32,\n    variable: bool,\n    shift: u32,\n) -> Poseidon2Sponge {\n    assert(in_len <= N, \"Given in_len to absorb is larger than the input array len\");\n    // When we have an existing sponge, we may have a shift of 0, and the final 'k+2' below = N\n    // The below avoids an overflow\n    let skip_last = 3 * M == N;\n    // Writing in_sponge: &mut does not compile\n    let mut sponge = in_sponge;\n    let mut should_add = true;\n    // The num of things left over after absorbing in 3s\n    let remainder = (in_len - shift) % 3;\n    // The num of chunks of 3 to absorb (maximum M)\n    let chunks = (in_len - shift - remainder) / 3;\n    for i in 0..M {\n        // Now we loop through cache size = 1 -> 3\n        should_add &= i != chunks;\n        // This is the index at the start of the chunk (for readability)\n        let k = 3 * i + shift;\n        if should_add {\n            // cache_size = 1, 2 => just assign\n            sponge.cache[1] = input[k];\n            sponge.cache[2] = input[k + 1];\n            // cache_size = 3 => duplex + perm\n            for j in 0..3 {\n                sponge.state[j] += sponge.cache[j];\n            }\n            sponge.state = std::hash::poseidon2_permutation(sponge.state, 4);\n            sponge.cache[0] = input[k + 2];\n            // cache_size is now 1 again, repeat loop\n        } else if (!variable) & (i != chunks) {\n            // if we are hashing a fixed len array which is a subarray, we check the remaining elts are 0\n            // NB: we don't check at i == chunks, because that chunk contains elts to be absorbed or checked below\n            let last_0 = if (i == M - 1) & (skip_last) {\n                0\n            } else {\n                input[k + 2]\n            };\n            let all_0 = (input[k] == 0) & (input[k + 1] == 0) & (last_0 == 0);\n            assert(all_0, \"Found non-zero field after breakpoint\");\n        }\n    }\n    // we have 'remainder' num of items left to absorb\n    should_add = true;\n    // below is to avoid overflows (i.e. if inlen is close to N)\n    let mut should_check = !variable;\n    for i in 0..3 {\n        should_add &= i != remainder;\n        should_check &= in_len - remainder + i != N;\n        if should_add {\n            // we want to absorb the final 'remainder' items\n            sponge.absorb(input[in_len - remainder + i]);\n        } else if should_check {\n            assert(input[in_len - remainder + i] == 0, \"Found non-zero field after breakpoint\");\n        }\n    }\n    sponge\n}\n\npub fn poseidon2_hash_with_separator_slice<T>(inputs: [Field], separator: T) -> Field\nwhere\n    T: ToField,\n{\n    let in_len = inputs.len() + 1;\n    let iv: Field = (in_len as Field) * TWO_POW_64;\n    let mut sponge = Poseidon2Sponge::new(iv);\n    sponge.absorb(separator.to_field());\n\n    for i in 0..inputs.len() {\n        sponge.absorb(inputs[i]);\n    }\n\n    sponge.squeeze()\n}\n\n#[no_predicates]\npub fn poseidon2_hash_bytes<let N: u32>(inputs: [u8; N]) -> Field {\n    let mut fields = [0; (N + 30) / 31];\n    let mut field_index = 0;\n    let mut current_field = [0; 31];\n    for i in 0..inputs.len() {\n        let index = i % 31;\n        current_field[index] = inputs[i];\n        if index == 30 {\n            fields[field_index] = field_from_bytes(current_field, false);\n            current_field = [0; 31];\n            field_index += 1;\n        }\n    }\n    if field_index != fields.len() {\n        fields[field_index] = field_from_bytes(current_field, false);\n    }\n    poseidon2_hash(fields)\n}\n\n#[test]\nfn poseidon_chunks_matches_fixed() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut fixed_input = [3; 501];\n    assert(in_len == fixed_input.len()); // sanity check\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    let sub_chunk_hash = poseidon2_hash_subarray(input, in_len);\n    let fixed_len_hash = poseidon::poseidon2::Poseidon2::hash(fixed_input, fixed_input.len());\n    assert(sub_chunk_hash == fixed_len_hash);\n}\n\n#[test]\nfn poseidon_chunks_matches_variable() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    let variable_chunk_hash = poseidon2_cheaper_variable_hash(input, in_len);\n    let variable_len_hash = poseidon::poseidon2::Poseidon2::hash(input, in_len);\n    assert(variable_chunk_hash == variable_len_hash);\n}\n\n#[test]\nfn existing_sponge_poseidon_chunks_matches_fixed() {\n    let in_len = 501;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut fixed_input = [3; 501];\n    assert(in_len == fixed_input.len()); // sanity check\n    for i in 0..in_len {\n        input[i] = 3;\n    }\n    // absorb 250 of the 501 things\n    let empty_sponge = Poseidon2Sponge::new((in_len as Field) * TWO_POW_64);\n    let first_sponge = poseidon2_absorb_chunks_existing_sponge(empty_sponge, input, 250, true);\n    // now absorb the final 251 (since they are all 3s, im being lazy and not making a new array)\n    let mut final_sponge = poseidon2_absorb_chunks_existing_sponge(first_sponge, input, 251, true);\n    let fixed_len_hash = Poseidon2Sponge::hash(fixed_input, fixed_input.len());\n    assert(final_sponge.squeeze() == fixed_len_hash);\n}\n\n#[test]\nfn poseidon_chunks_empty_inputs() {\n    let in_len = 0;\n    let mut input: [Field; 4096] = [0; 4096];\n    let mut constructed_empty_sponge = poseidon2_absorb_chunks(input, in_len, true);\n    let mut first_sponge =\n        poseidon2_absorb_chunks_existing_sponge(constructed_empty_sponge, input, in_len, true);\n    assert(first_sponge.squeeze() == constructed_empty_sponge.squeeze());\n}\n\n#[test]\nfn smoke_sha256_to_field() {\n    let full_buffer = [\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n        25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n        48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n        71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93,\n        94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n        113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148,\n        149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n    ];\n    let result = sha256_to_field(full_buffer);\n\n    assert(result == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184c7);\n\n    // to show correctness of the current ver (truncate one byte) vs old ver (mod full bytes):\n    let result_bytes = sha256::digest(full_buffer);\n    let truncated_field = crate::utils::field::field_from_bytes_32_trunc(result_bytes);\n    assert(truncated_field == result);\n    let mod_res = result + (result_bytes[31] as Field);\n    assert(mod_res == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184e0);\n}\n\n#[test]\nfn compute_l2_l1_hash() {\n    // All zeroes\n    let hash_result =\n        compute_l2_to_l1_hash(AztecAddress::from_field(0), EthAddress::zero(), 0, 0, 0);\n    assert(hash_result == 0xb393978842a0fa3d3e1470196f098f473f9678e72463cb65ec4ab5581856c2);\n\n    // Non-zero case\n    let hash_result = compute_l2_to_l1_hash(\n        AztecAddress::from_field(1),\n        EthAddress::from_field(3),\n        5,\n        2,\n        4,\n    );\n    assert(hash_result == 0x3f88c1044a05e5340ed20466276500f6d45ca5603913b9091e957161734e16);\n}\n\n#[test]\nfn silo_l2_to_l1_message_matches_typescript() {\n    let version = 4;\n    let chainId = 5;\n\n    let hash = silo_l2_to_l1_message(\n        ScopedL2ToL1Message {\n            message: L2ToL1Message { recipient: EthAddress::from_field(1), content: 2, counter: 0 },\n            contract_address: AztecAddress::from_field(3),\n        },\n        version,\n        chainId,\n    );\n\n    // The following value was generated by `l2_to_l1_message.test.ts`\n    let hash_from_typescript = 0x00c6155d69febb9d5039b374dd4f77bf57b7c881709aa524a18acaa0bd57476a;\n\n    assert_eq(hash, hash_from_typescript);\n}\n"
    },
    "294": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/noir-protocol-circuits/crates/types/src/meta/mod.nr",
      "source": "use super::traits::{Deserialize, Packable, Serialize};\n\n/// Returns the typed expression of a trait method implementation.\n///\n/// This helper function is preferred over directly inlining with `$typ::target_method()` in a quote,\n/// as direct inlining would result in missing import warnings in the generated code (specifically,\n/// warnings that the trait implementation is not in scope).\n///\n/// # Note\n/// A copy of this function exists in `aztec-nr/aztec/src/macros/utils.nr`. We maintain separate copies\n/// because importing it there from here would cause the `target_trait` to be interpreted in the context\n/// of this crate, making it impossible to compile code for traits from that crate (e.g. NoteType).\ncomptime fn get_trait_impl_method(\n    typ: Type,\n    target_trait: Quoted,\n    target_method: Quoted,\n) -> TypedExpr {\n    let trait_constraint = target_trait.as_trait_constraint();\n    typ\n        .get_trait_impl(trait_constraint)\n        .expect(f\"Could not find impl for {target_trait} for type {typ}\")\n        .methods()\n        .filter(|m| m.name() == target_method)[0]\n        .as_typed_expr()\n}\n\n/// Generates code that deserializes a struct, primitive type, array or string from a field array.\n///\n/// # Parameters\n/// - `name`: The name of the current field being processed, used to identify fields for replacement.\n/// - `typ`: The type of the struct or field being deserialized (e.g., a custom struct, array, or primitive).\n/// - `field_array_name`: The name of the field array containing serialized field data (e.g., `\"values\"`).\n/// - `num_already_consumed`: The number of fields already processed in previous recursion calls.\n/// - `should_unpack`: A boolean indicating whether the type should be unpacked (see description of `Packable`\n/// and `Serialize` trait for more information about the difference between packing and serialization).\n///\n/// # Returns\n/// A tuple containing:\n/// - `Quoted`: A code that deserializes a given struct, primitive type, array, or string from the field array.\n/// - `u32`: The total number of fields consumed during deserialization (used for recursion).\n///\n/// # Nested Struct Example\n/// Given the following setup:\n/// ```\n/// struct UintNote {\n///     value: u128,\n///     owner: AztecAddress,\n///     randomness: Field,\n/// }\n///\n/// struct AztecAddress {\n///     inner: Field,\n/// }\n/// ```\n///\n/// If `UintNote` is the input type, the function will generate the following deserialization code:\n/// ```\n/// UintNote {\n///     value: fields[0] as u128,\n///     owner: AztecAddress {\n///         inner: fields[1],\n///     },\n///     randomness: fields[2],\n/// }\n/// ```\n/// # Nested Struct Example with Unpacking\n/// - given the same setup as above and given that u128, AztecAddress and Field implement the `Packable` trait\n///   the result we get is:\n/// ```\n/// UintNote {\n///     value: aztec::protocol_types::traits::Packable::unpack([fields[0]]),\n///     owner: aztec::protocol_types::traits::Packable::unpack([fields[1]]),\n///     randomness: aztec::protocol_types::traits::Packable::unpack([fields[2]]),\n/// }\n/// ```\n///\n/// # Panics\n/// - If the deserialization logic encounters a type it does not support.\n/// - If an incorrect number of fields are consumed when deserializing a string.\npub comptime fn generate_deserialize_from_fields(\n    name: Quoted,\n    typ: Type,\n    field_array_name: Quoted,\n    num_already_consumed: u32,\n    should_unpack: bool,\n) -> (Quoted, u32) {\n    let mut result = quote {};\n    // Counter for the number of fields consumed\n    let mut consumed_counter: u32 = 0;\n\n    // If the type implements `Packable`, its length will be assigned to the `maybe_packed_len_typ` variable.\n    let maybe_packed_len_typ = std::meta::typ::fresh_type_variable();\n    let packable_constraint = quote { Packable<$maybe_packed_len_typ> }.as_trait_constraint();\n\n    if (should_unpack & typ.implements(packable_constraint)) {\n        // Unpacking is enabled and the given type implements the `Packable` trait so we call the `unpack()`\n        // method, add the resulting field array to `aux_vars` and each field to `fields`.\n        let packed_len = maybe_packed_len_typ.as_constant().unwrap();\n\n        // We copy the packed fields into a new array and pass that to the unpack function in a quote\n        let mut packed_fields_quotes = &[];\n        for i in 0..packed_len {\n            let index_in_field_array = i + num_already_consumed;\n            packed_fields_quotes =\n                packed_fields_quotes.push_back(quote { $field_array_name[$index_in_field_array] });\n        }\n        let packed_fields = packed_fields_quotes.join(quote {,});\n\n        // Now we call unpack on the type\n        let unpack_method = get_trait_impl_method(typ, quote { Packable<_> }, quote { unpack });\n        result = quote { $unpack_method([ $packed_fields ]) };\n\n        consumed_counter = packed_len;\n    } else if typ.is_field() | typ.as_integer().is_some() | typ.is_bool() {\n        // The field is a primitive so we just reference it in the field array\n        result = quote { $field_array_name[$num_already_consumed] as $typ };\n        consumed_counter = 1;\n    } else if typ.as_data_type().is_some() {\n        // The field is a struct so we iterate over each struct field and recursively call\n        // `generate_deserialize_from_fields`\n        let (nested_def, generics) = typ.as_data_type().unwrap();\n        let nested_name = nested_def.name();\n        let mut deserialized_fields_list = &[];\n\n        // Iterate over each field in the struct\n        for field in nested_def.fields(generics) {\n            let (field_name, field_type) = field;\n            // Recursively call `generate_deserialize_from_fields` for each field in the struct\n            let (deserialized_field, num_consumed_in_recursion) = generate_deserialize_from_fields(\n                field_name,\n                field_type,\n                field_array_name,\n                consumed_counter + num_already_consumed,\n                should_unpack,\n            );\n            // We increment the consumed counter by the number of fields consumed in the recursion\n            consumed_counter += num_consumed_in_recursion;\n            // We add the deserialized field to the list of deserialized fields.\n            // E.g. `value: u128 { lo: fields[0], hi: fields[1] }`\n            deserialized_fields_list =\n                deserialized_fields_list.push_back(quote { $field_name: $deserialized_field });\n        }\n\n        // We can construct the struct from the deserialized fields\n        let deserialized_fields = deserialized_fields_list.join(quote {,});\n        result = quote {\n                $nested_name {\n                    $deserialized_fields\n                }\n            };\n    } else if typ.as_array().is_some() {\n        // The field is an array so we iterate over each element and recursively call\n        // `generate_deserialize_from_fields`\n        let (element_type, array_len) = typ.as_array().unwrap();\n        let array_len = array_len.as_constant().unwrap();\n        let mut array_fields_list = &[];\n\n        // Iterate over each element in the array\n        for _ in 0..array_len {\n            // Recursively call `generate_deserialize_from_fields` for each element in the array\n            let (deserialized_field, num_consumed_in_recursion) = generate_deserialize_from_fields(\n                name,\n                element_type,\n                field_array_name,\n                consumed_counter + num_already_consumed,\n                should_unpack,\n            );\n            // We increment the consumed counter by the number of fields consumed in the recursion\n            consumed_counter += num_consumed_in_recursion;\n            // We add the deserialized field to the list of deserialized fields.\n            array_fields_list = array_fields_list.push_back(deserialized_field);\n        }\n\n        // We can construct the array from the deserialized fields\n        let array_fields = array_fields_list.join(quote {,});\n        result = quote { [ $array_fields ] };\n    } else if typ.as_str().is_some() {\n        // The field is a string and we expect each byte of the string to be represented as 1 field in the field\n        // array. So we iterate over the string length and deserialize each character as u8 in the recursive call\n        // to `generate_deserialize_from_fields`.\n        let length_type = typ.as_str().unwrap();\n        let str_len = length_type.as_constant().unwrap();\n        let mut byte_list = &[];\n\n        // Iterate over each character in the string\n        for _ in 0..str_len {\n            // Recursively call `generate_deserialize_from_fields` for each character in the string\n            let (deserialized_field, num_consumed_in_recursion) = generate_deserialize_from_fields(\n                name,\n                quote {u8}.as_type(),\n                field_array_name,\n                consumed_counter + num_already_consumed,\n                should_unpack,\n            );\n\n            // We should consume just one field in the recursion so we sanity check that\n            assert_eq(\n                num_consumed_in_recursion,\n                1,\n                \"Incorrect number of fields consumed in string deserialization\",\n            );\n\n            // We increment the consumed counter by 1 as we have consumed one field\n            consumed_counter += 1;\n\n            // We add the deserialized field to the list of deserialized fields.\n            // E.g. `fields[6] as u8`\n            byte_list = byte_list.push_back(deserialized_field);\n        }\n\n        // We construct the string from the deserialized fields\n        let bytes = byte_list.join(quote {,});\n        result = quote { [ $bytes ].as_str_unchecked() };\n    } else {\n        panic(\n            f\"Unsupported type for serialization of argument {name} and type {typ}\",\n        )\n    }\n\n    (result, consumed_counter)\n}\n\n/// Generates code that serializes a type into an array of fields. Also generates auxiliary variables if necessary\n/// for serialization. If `should_pack` is true, we check if the type implements the `Packable` trait and pack it\n/// if it does.\n///\n/// # Parameters\n/// - `name`: The base identifier (e.g., `self`, `some_var`).\n/// - `typ`: The type being serialized (e.g., a custom struct, array, or primitive type).\n/// - `should_pack`: A boolean indicating whether the type should be packed.\n///\n/// # Returns\n/// A tuple containing:\n/// - A flattened array of `Quoted` field references representing the serialized fields.\n/// - An array of `Quoted` auxiliary variables needed for serialization, such as byte arrays for strings.\n///\n/// # Examples\n///\n/// ## Struct\n/// Given the following struct:\n/// ```rust\n/// struct MockStruct {\n///     a: Field,\n///     b: Field,\n/// }\n/// ```\n///\n/// Serializing the struct:\n/// ```rust\n/// generate_serialize_to_fields(quote { my_mock_struct }, MockStruct, false)\n/// // Returns:\n/// // ([`my_mock_struct.a`, `my_mock_struct.b`], [])\n/// ```\n///\n/// ## Nested Struct\n/// For a more complex struct:\n/// ```rust\n/// struct NestedStruct {\n///     m1: MockStruct,\n///     m2: MockStruct,\n/// }\n/// ```\n///\n/// Serialization output:\n/// ```rust\n/// generate_serialize_to_fields(quote { self }, NestedStruct, false)\n/// // Returns:\n/// // ([`self.m1.a`, `self.m1.b`, `self.m2.a`, `self.m2.b`], [])\n/// ```\n///\n/// ## Array\n/// For an array type:\n/// ```rust\n/// generate_serialize_to_fields(quote { my_array }, [Field; 3], false)\n/// // Returns:\n/// // ([`my_array[0]`, `my_array[1]`, `my_array[2]`], [])\n/// ```\n///\n/// ## String\n/// For a string field, where each character is serialized as a `Field`:\n/// ```rust\n/// generate_serialize_to_fields(quote { my_string }, StringType, false)\n/// // Returns:\n/// // ([`my_string_as_bytes[0] as Field`, `my_string_as_bytes[1] as Field`, ...],\n/// // [`let my_string_as_bytes = my_string.as_bytes()`])\n/// ```\n///\n/// ## Nested Struct with packing enabled\n/// - u128 has a `Packable` implementation hence it will be packed.\n///\n/// For a more complex struct:\n/// ```rust\n/// struct MyStruct {\n///     value: u128,\n///     value2: Field,\n/// }\n/// ```\n///\n/// # Panics\n/// - If the type is unsupported for serialization.\n/// - If the provided `typ` contains invalid constants or incompatible structures.\npub comptime fn generate_serialize_to_fields(\n    name: Quoted,\n    typ: Type,\n    should_pack: bool,\n) -> ([Quoted], [Quoted]) {\n    let mut fields = &[];\n    let mut aux_vars = &[];\n\n    // If the type implements `Packable`, its length will be assigned to the `maybe_packed_len_typ` variable.\n    let maybe_packed_len_typ = std::meta::typ::fresh_type_variable();\n    let packable_constraint =\n        quote { crate::traits::Packable<$maybe_packed_len_typ> }.as_trait_constraint();\n\n    if (should_pack & typ.implements(packable_constraint)) {\n        // Packing is enabled and the given type implements the `Packable` trait so we call the `pack()`\n        // method, add the resulting field array to `aux_vars` and each field to `fields`.\n        let packed_len = maybe_packed_len_typ.as_constant().unwrap();\n\n        // We collapse the name to a one that gets tokenized as a single token (e.g. \"self.value\" -> \"self_value\").\n        let name_at_one_token = collapse_to_one_token(name);\n        let packed_struct_name = f\"{name_at_one_token}_aux_var\".quoted_contents();\n\n        // We add the individual fields to the fields array\n        let pack_method = get_trait_impl_method(\n            typ,\n            quote { crate::traits::Packable<$packed_len> },\n            quote { pack },\n        );\n        let packed_struct = quote { let $packed_struct_name = $pack_method($name) };\n        for i in 0..packed_len {\n            fields = fields.push_back(quote { $packed_struct_name[$i] });\n        }\n\n        // We add the new auxiliary variable to the aux_vars array\n        aux_vars = aux_vars.push_back(packed_struct);\n    } else if typ.is_field() {\n        // For field we just add the value to fields\n        fields = fields.push_back(name);\n    } else if typ.as_integer().is_some() | typ.is_bool() {\n        // For integer and bool we just cast to Field and add the value to fields\n        fields = fields.push_back(quote { $name as Field });\n    } else if typ.as_data_type().is_some() {\n        // For struct we pref\n        let nested_struct = typ.as_data_type().unwrap();\n        let params = nested_struct.0.fields(nested_struct.1);\n        let struct_flattened = params.map(|(param_name, param_type): (Quoted, Type)| {\n            let maybe_prefixed_name = if name == quote {} {\n                // Triggered when the param name is of a value available in the current scope (e.g. a function\n                // argument) --> then we don't prefix the name with anything.\n                param_name\n            } else {\n                // Triggered when we want to prefix the param name with the `name` from function input. This\n                // can typically be `self` when implementing a method on a struct.\n                quote { $name.$param_name }\n            };\n            generate_serialize_to_fields(quote {$maybe_prefixed_name}, param_type, should_pack)\n        });\n        let struct_flattened_fields = struct_flattened.fold(\n            &[],\n            |acc: [Quoted], (fields, _): (_, [Quoted])| acc.append(fields),\n        );\n        let struct_flattened_aux_vars = struct_flattened.fold(\n            &[],\n            |acc: [Quoted], (_, aux_vars): ([Quoted], _)| acc.append(aux_vars),\n        );\n        fields = fields.append(struct_flattened_fields);\n        aux_vars = aux_vars.append(struct_flattened_aux_vars);\n    } else if typ.as_array().is_some() {\n        // For array we recursively call `generate_serialize_to_fields(...)` for each element\n        let (element_type, array_len) = typ.as_array().unwrap();\n        let array_len = array_len.as_constant().unwrap();\n        for i in 0..array_len {\n            let (element_fields, element_aux_vars) =\n                generate_serialize_to_fields(quote { $name[$i] }, element_type, should_pack);\n            fields = fields.append(element_fields);\n            aux_vars = aux_vars.append(element_aux_vars);\n        }\n    } else if typ.as_str().is_some() {\n        // For string we convert the value to bytes, we store the `as_bytes` in an auxiliary variables and\n        // then we add each byte to fields as a Field\n        let length_type = typ.as_str().unwrap();\n        let str_len = length_type.as_constant().unwrap();\n        let as_member = name.as_expr().unwrap().as_member_access();\n        let var_name = if as_member.is_some() {\n            as_member.unwrap().1\n        } else {\n            name\n        };\n        let as_bytes_name = f\"{var_name}_as_bytes\".quoted_contents();\n        let as_bytes = quote { let $as_bytes_name = $name.as_bytes() };\n        for i in 0..str_len {\n            fields = fields.push_back(quote { $as_bytes_name[$i] as Field });\n        }\n        aux_vars = aux_vars.push_back(as_bytes);\n    } else {\n        panic(\n            f\"Unsupported type for serialization of argument {name} and type {typ}\",\n        )\n    }\n\n    (fields, aux_vars)\n}\n\n/// From a quote that gets tokenized to a multiple tokens we collapse it to a single token by replacing all `.` with `_`.\n/// E.g. \"self.values[0]\" -> \"self_values_0_\"\ncomptime fn collapse_to_one_token(q: Quoted) -> Quoted {\n    let tokens = q.tokens();\n\n    let mut single_token = quote {};\n    for token in tokens {\n        let new_token = if ((token == quote {.}) | (token == quote {[}) | (token == quote {]})) {\n            quote {_}\n        } else {\n            token\n        };\n        single_token = f\"{single_token}{new_token}\".quoted_contents();\n    }\n    single_token\n}\n\npub(crate) comptime fn derive_serialize(s: TypeDefinition) -> Quoted {\n    let typ = s.as_type();\n    let (fields, aux_vars) = generate_serialize_to_fields(quote { self }, typ, false);\n    let aux_vars_for_serialization = if aux_vars.len() > 0 {\n        let joint = aux_vars.join(quote {;});\n        quote { $joint; }\n    } else {\n        quote {}\n    };\n\n    let field_serializations = fields.join(quote {,});\n    let serialized_len = fields.len();\n    quote {\n        impl Serialize<$serialized_len> for $typ {\n            #[inline_always]\n            fn serialize(self) -> [Field; $serialized_len] {\n                $aux_vars_for_serialization\n                [ $field_serializations ]\n            }\n        }\n    }\n}\n\npub(crate) comptime fn derive_deserialize(s: TypeDefinition) -> Quoted {\n    let typ = s.as_type();\n    let (fields, _) = generate_serialize_to_fields(quote { self }, typ, false);\n    let serialized_len = fields.len();\n    let (deserialized, _) =\n        generate_deserialize_from_fields(quote { self }, typ, quote { serialized }, 0, false);\n    quote {\n        impl Deserialize<$serialized_len> for $typ {\n            #[inline_always]\n            fn deserialize(serialized: [Field; $serialized_len]) -> Self {\n                $deserialized\n            }\n        }\n    }\n}\n\n/// Generates `Packable` implementation for a given struct and returns the packed length.\n///\n/// Note: We are having this function separate from `derive_packable` because we use this in the note macros to get\n/// the packed length of a note as well as the `Packable` implementation. We need the length to be able to register\n/// the note in the global `NOTES` map. There the length is used to generate partial note helper functions.\npub comptime fn derive_packable_and_get_packed_len(s: TypeDefinition) -> (Quoted, u32) {\n    let packing_enabled = true;\n\n    let typ = s.as_type();\n    let (fields, aux_vars) = generate_serialize_to_fields(quote { self }, typ, packing_enabled);\n    let aux_vars_for_packing = if aux_vars.len() > 0 {\n        let joint = aux_vars.join(quote {;});\n        quote { $joint; }\n    } else {\n        quote {}\n    };\n\n    let (unpacked, _) =\n        generate_deserialize_from_fields(quote { self }, typ, quote { packed }, 0, packing_enabled);\n\n    let field_packings = fields.join(quote {,});\n    let packed_len = fields.len();\n    let packable_trait: TraitConstraint = quote { Packable<$packed_len> }.as_trait_constraint();\n    (\n        quote {\n        impl $packable_trait for $typ {\n            fn pack(self) -> [Field; $packed_len] {\n                $aux_vars_for_packing\n                [ $field_packings ]\n            }\n\n            fn unpack(packed: [Field; $packed_len]) -> Self {\n                $unpacked\n            }\n        }\n    },\n        packed_len,\n    )\n}\n\npub(crate) comptime fn derive_packable(s: TypeDefinition) -> Quoted {\n    let (packable_impl, _) = derive_packable_and_get_packed_len(s);\n    packable_impl\n}\n\n#[derive(Packable, Serialize, Deserialize, Eq)]\npub struct Smol {\n    a: Field,\n    b: Field,\n}\n\n#[derive(Serialize, Deserialize, Eq)]\npub struct HasArray {\n    a: [Field; 2],\n    b: bool,\n}\n\n#[derive(Serialize, Deserialize, Eq)]\npub struct Fancier {\n    a: Smol,\n    b: [Field; 2],\n    c: [u8; 3],\n    d: str<16>,\n}\n\nfn main() {\n    assert(false);\n}\n\n#[test]\nfn smol_test() {\n    let smol = Smol { a: 1, b: 2 };\n    let serialized = smol.serialize();\n    assert(serialized == [1, 2], serialized);\n    let deserialized = Smol::deserialize(serialized);\n    assert(deserialized == smol);\n\n    // None of the struct members implements the `Packable` trait so the packed and serialized data should be the same\n    let packed = smol.pack();\n    assert_eq(packed, serialized, \"Packed does not match serialized\");\n}\n\n#[test]\nfn has_array_test() {\n    let has_array = HasArray { a: [1, 2], b: true };\n    let serialized = has_array.serialize();\n    assert(serialized == [1, 2, 1], serialized);\n    let deserialized = HasArray::deserialize(serialized);\n    assert(deserialized == has_array);\n}\n\n#[test]\nfn fancier_test() {\n    let fancier =\n        Fancier { a: Smol { a: 1, b: 2 }, b: [0, 1], c: [1, 2, 3], d: \"metaprogramming!\" };\n    let serialized = fancier.serialize();\n    assert(\n        serialized\n            == [\n                1, 2, 0, 1, 1, 2, 3, 0x6d, 0x65, 0x74, 0x61, 0x70, 0x72, 0x6f, 0x67, 0x72, 0x61,\n                0x6d, 0x6d, 0x69, 0x6e, 0x67, 0x21,\n            ],\n        serialized,\n    );\n    let deserialized = Fancier::deserialize(serialized);\n    assert(deserialized == fancier);\n}\n"
    },
    "296": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/noir-protocol-circuits/crates/types/src/point.nr",
      "source": "pub use dep::std::embedded_curve_ops::EmbeddedCurvePoint as Point;\nuse crate::{hash::poseidon2_hash, traits::{Deserialize, Empty, Hash, Packable, Serialize}};\n\npub global POINT_LENGTH: u32 = 3;\n\nimpl Serialize<POINT_LENGTH> for Point {\n    fn serialize(self: Self) -> [Field; POINT_LENGTH] {\n        [self.x, self.y, self.is_infinite as Field]\n    }\n}\n\nimpl Hash for Point {\n    fn hash(self) -> Field {\n        poseidon2_hash(self.serialize())\n    }\n}\n\nimpl Empty for Point {\n    /// Note: Does not return a valid point on curve - instead represents an empty/\"unpopulated\" point struct (e.g.\n    /// empty/unpopulated value in an array of points).\n    fn empty() -> Self {\n        Point { x: 0, y: 0, is_infinite: false }\n    }\n}\n\nimpl Deserialize<POINT_LENGTH> for Point {\n    fn deserialize(serialized: [Field; POINT_LENGTH]) -> Point {\n        Point { x: serialized[0], y: serialized[1], is_infinite: serialized[2] as bool }\n    }\n}\n// TODO(#11356): use compact representation here.\nimpl Packable<POINT_LENGTH> for Point {\n    fn pack(self) -> [Field; POINT_LENGTH] {\n        self.serialize()\n    }\n\n    fn unpack(packed: [Field; POINT_LENGTH]) -> Self {\n        Self::deserialize(packed)\n    }\n}\n"
    },
    "307": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/noir-protocol-circuits/crates/types/src/public_keys.nr",
      "source": "use crate::{\n    address::public_keys_hash::PublicKeysHash,\n    constants::{\n        DEFAULT_IVPK_M_X, DEFAULT_IVPK_M_Y, DEFAULT_NPK_M_X, DEFAULT_NPK_M_Y, DEFAULT_OVPK_M_X,\n        DEFAULT_OVPK_M_Y, DEFAULT_TPK_M_X, DEFAULT_TPK_M_Y, GENERATOR_INDEX__PUBLIC_KEYS_HASH,\n    },\n    hash::poseidon2_hash_with_separator,\n    point::POINT_LENGTH,\n    traits::{Deserialize, Hash, Serialize},\n};\n\nuse dep::std::embedded_curve_ops::EmbeddedCurvePoint as Point;\nuse std::default::Default;\n\npub global PUBLIC_KEYS_LENGTH: u32 = 12;\n\npub struct PublicKeys {\n    pub npk_m: NpkM,\n    pub ivpk_m: IvpkM,\n    pub ovpk_m: OvpkM,\n    pub tpk_m: TpkM,\n}\n\npub trait ToPoint {\n    fn to_point(self) -> Point;\n}\n\npub struct NpkM {\n    pub inner: Point,\n}\n\nimpl ToPoint for NpkM {\n    fn to_point(self) -> Point {\n        self.inner\n    }\n}\n\nimpl Serialize<POINT_LENGTH> for NpkM {\n    fn serialize(self) -> [Field; POINT_LENGTH] {\n        self.inner.serialize()\n    }\n}\n\n// Note: If we store npk_m_hash directly we can remove this trait implementation. See #8091\nimpl Hash for NpkM {\n    fn hash(self) -> Field {\n        self.inner.hash()\n    }\n}\n\npub struct IvpkM {\n    pub inner: Point,\n}\n\nimpl ToPoint for IvpkM {\n    fn to_point(self) -> Point {\n        self.inner\n    }\n}\n\nimpl Serialize<POINT_LENGTH> for IvpkM {\n    fn serialize(self) -> [Field; POINT_LENGTH] {\n        self.inner.serialize()\n    }\n}\n\npub struct OvpkM {\n    pub inner: Point,\n}\n\nimpl Hash for OvpkM {\n    fn hash(self) -> Field {\n        self.inner.hash()\n    }\n}\n\nimpl ToPoint for OvpkM {\n    fn to_point(self) -> Point {\n        self.inner\n    }\n}\n\nimpl Serialize<POINT_LENGTH> for OvpkM {\n    fn serialize(self) -> [Field; POINT_LENGTH] {\n        self.inner.serialize()\n    }\n}\n\npub struct TpkM {\n    pub inner: Point,\n}\n\nimpl ToPoint for TpkM {\n    fn to_point(self) -> Point {\n        self.inner\n    }\n}\n\nimpl Serialize<POINT_LENGTH> for TpkM {\n    fn serialize(self) -> [Field; POINT_LENGTH] {\n        self.inner.serialize()\n    }\n}\n\nimpl Default for PublicKeys {\n    fn default() -> Self {\n        PublicKeys {\n            npk_m: NpkM {\n                inner: Point { x: DEFAULT_NPK_M_X, y: DEFAULT_NPK_M_Y, is_infinite: false },\n            },\n            ivpk_m: IvpkM {\n                inner: Point { x: DEFAULT_IVPK_M_X, y: DEFAULT_IVPK_M_Y, is_infinite: false },\n            },\n            ovpk_m: OvpkM {\n                inner: Point { x: DEFAULT_OVPK_M_X, y: DEFAULT_OVPK_M_Y, is_infinite: false },\n            },\n            tpk_m: TpkM {\n                inner: Point { x: DEFAULT_TPK_M_X, y: DEFAULT_TPK_M_Y, is_infinite: false },\n            },\n        }\n    }\n}\n\nimpl Eq for PublicKeys {\n    fn eq(self, other: PublicKeys) -> bool {\n        (self.npk_m.inner == other.npk_m.inner)\n            & (self.ivpk_m.inner == other.ivpk_m.inner)\n            & (self.ovpk_m.inner == other.ovpk_m.inner)\n            & (self.tpk_m.inner == other.tpk_m.inner)\n    }\n}\n\nimpl PublicKeys {\n    pub fn hash(self) -> PublicKeysHash {\n        PublicKeysHash::from_field(poseidon2_hash_with_separator(\n            self.serialize(),\n            GENERATOR_INDEX__PUBLIC_KEYS_HASH as Field,\n        ))\n    }\n}\n\nimpl Serialize<PUBLIC_KEYS_LENGTH> for PublicKeys {\n    fn serialize(self) -> [Field; PUBLIC_KEYS_LENGTH] {\n        [\n            self.npk_m.inner.x,\n            self.npk_m.inner.y,\n            self.npk_m.inner.is_infinite as Field,\n            self.ivpk_m.inner.x,\n            self.ivpk_m.inner.y,\n            self.ivpk_m.inner.is_infinite as Field,\n            self.ovpk_m.inner.x,\n            self.ovpk_m.inner.y,\n            self.ovpk_m.inner.is_infinite as Field,\n            self.tpk_m.inner.x,\n            self.tpk_m.inner.y,\n            self.tpk_m.inner.is_infinite as Field,\n        ]\n    }\n}\n\nimpl Deserialize<PUBLIC_KEYS_LENGTH> for PublicKeys {\n    fn deserialize(serialized: [Field; PUBLIC_KEYS_LENGTH]) -> PublicKeys {\n        PublicKeys {\n            npk_m: NpkM {\n                inner: Point {\n                    x: serialized[0],\n                    y: serialized[1],\n                    is_infinite: serialized[2] as bool,\n                },\n            },\n            ivpk_m: IvpkM {\n                inner: Point {\n                    x: serialized[3],\n                    y: serialized[4],\n                    is_infinite: serialized[5] as bool,\n                },\n            },\n            ovpk_m: OvpkM {\n                inner: Point {\n                    x: serialized[6],\n                    y: serialized[7],\n                    is_infinite: serialized[8] as bool,\n                },\n            },\n            tpk_m: TpkM {\n                inner: Point {\n                    x: serialized[9],\n                    y: serialized[10],\n                    is_infinite: serialized[11] as bool,\n                },\n            },\n        }\n    }\n}\n\npub struct AddressPoint {\n    pub inner: Point,\n}\n\nimpl ToPoint for AddressPoint {\n    fn to_point(self) -> Point {\n        self.inner\n    }\n}\n\n#[test]\nunconstrained fn compute_public_keys_hash() {\n    let keys = PublicKeys {\n        npk_m: NpkM { inner: Point { x: 1, y: 2, is_infinite: false } },\n        ivpk_m: IvpkM { inner: Point { x: 3, y: 4, is_infinite: false } },\n        ovpk_m: OvpkM { inner: Point { x: 5, y: 6, is_infinite: false } },\n        tpk_m: TpkM { inner: Point { x: 7, y: 8, is_infinite: false } },\n    };\n\n    let actual = keys.hash();\n    let expected_public_keys_hash =\n        0x0fecd9a32db731fec1fded1b9ff957a1625c069245a3613a2538bd527068b0ad;\n\n    assert(actual.to_field() == expected_public_keys_hash);\n}\n\n#[test]\nunconstrained fn compute_default_hash() {\n    let keys = PublicKeys::default();\n\n    let actual = keys.hash();\n    let test_data_default_hash = 0x1d3bf1fb93ae0e9cda83b203dd91c3bfb492a9aecf30ec90e1057eced0f0e62d;\n\n    assert(actual.to_field() == test_data_default_hash);\n}\n\n#[test]\nunconstrained fn test_public_keys_serialization() {\n    let keys = PublicKeys {\n        npk_m: NpkM { inner: Point { x: 1, y: 2, is_infinite: false } },\n        ivpk_m: IvpkM { inner: Point { x: 3, y: 4, is_infinite: false } },\n        ovpk_m: OvpkM { inner: Point { x: 5, y: 6, is_infinite: false } },\n        tpk_m: TpkM { inner: Point { x: 7, y: 8, is_infinite: false } },\n    };\n\n    let serialized = keys.serialize();\n    let deserialized = PublicKeys::deserialize(serialized);\n\n    assert_eq(keys.npk_m.inner.x, deserialized.npk_m.inner.x);\n    assert_eq(keys.npk_m.inner.y, deserialized.npk_m.inner.y);\n    assert_eq(keys.ivpk_m.inner.x, deserialized.ivpk_m.inner.x);\n    assert_eq(keys.ivpk_m.inner.y, deserialized.ivpk_m.inner.y);\n    assert_eq(keys.ovpk_m.inner.x, deserialized.ovpk_m.inner.x);\n    assert_eq(keys.ovpk_m.inner.y, deserialized.ovpk_m.inner.y);\n    assert_eq(keys.tpk_m.inner.x, deserialized.tpk_m.inner.x);\n    assert_eq(keys.tpk_m.inner.y, deserialized.tpk_m.inner.y);\n}\n"
    },
    "332": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/noir-protocol-circuits/crates/types/src/traits.nr",
      "source": "use crate::meta::{derive_deserialize, derive_packable, derive_serialize};\nuse crate::utils::field::field_from_bytes;\n\n// Trait: is_empty\n//\n// The general is_empty trait checks if a data type is is empty,\n// and it defines empty for the basic data types as 0.\n//\n// If a Field is equal to zero, then it is regarded as zero.\n// We will go with this definition for now, however it can be problematic\n// if a value can actually be zero. In a future refactor, we can\n// use the optional type for safety. Doing it now would lead to a worse devex\n// and would make it harder to sync up with the cpp code.\n// Preferred over Default trait to convey intent, as default doesn't necessarily mean empty.\npub trait Empty {\n    fn empty() -> Self;\n}\n\nimpl Empty for Field {\n    #[inline_always]\n    fn empty() -> Self {\n        0\n    }\n}\n\nimpl Empty for u1 {\n    #[inline_always]\n    fn empty() -> Self {\n        0\n    }\n}\nimpl Empty for u8 {\n    #[inline_always]\n    fn empty() -> Self {\n        0\n    }\n}\nimpl Empty for u32 {\n    #[inline_always]\n    fn empty() -> Self {\n        0\n    }\n}\nimpl Empty for u64 {\n    #[inline_always]\n    fn empty() -> Self {\n        0\n    }\n}\nimpl Empty for u128 {\n    #[inline_always]\n    fn empty() -> Self {\n        0\n    }\n}\n\nimpl<T, let N: u32> Empty for [T; N]\nwhere\n    T: Empty,\n{\n    #[inline_always]\n    fn empty() -> Self {\n        [T::empty(); N]\n    }\n}\n\nimpl<T> Empty for Option<T> {\n    #[inline_always]\n    fn empty() -> Self {\n        Option::none()\n    }\n}\n\npub fn is_empty<T>(item: T) -> bool\nwhere\n    T: Empty + Eq,\n{\n    item.eq(T::empty())\n}\n\npub fn is_empty_array<T, let N: u32>(array: [T; N]) -> bool\nwhere\n    T: Empty + Eq,\n{\n    array.all(|elem| is_empty(elem))\n}\n\npub trait Hash {\n    fn hash(self) -> Field;\n}\n\npub trait ToField {\n    fn to_field(self) -> Field;\n}\n\nimpl ToField for Field {\n    #[inline_always]\n    fn to_field(self) -> Field {\n        self\n    }\n}\n\nimpl ToField for bool {\n    #[inline_always]\n    fn to_field(self) -> Field {\n        self as Field\n    }\n}\nimpl ToField for u1 {\n    #[inline_always]\n    fn to_field(self) -> Field {\n        self as Field\n    }\n}\nimpl ToField for u8 {\n    #[inline_always]\n    fn to_field(self) -> Field {\n        self as Field\n    }\n}\nimpl ToField for u32 {\n    #[inline_always]\n    fn to_field(self) -> Field {\n        self as Field\n    }\n}\nimpl ToField for u64 {\n    #[inline_always]\n    fn to_field(self) -> Field {\n        self as Field\n    }\n}\nimpl ToField for u128 {\n    #[inline_always]\n    fn to_field(self) -> Field {\n        self as Field\n    }\n}\nimpl<let N: u32> ToField for str<N> {\n    #[inline_always]\n    fn to_field(self) -> Field {\n        assert(N < 32, \"String doesn't fit in a field, consider using Serialize instead\");\n        field_from_bytes(self.as_bytes(), true)\n    }\n}\n\npub trait FromField {\n    fn from_field(value: Field) -> Self;\n}\n\nimpl FromField for Field {\n    #[inline_always]\n    fn from_field(value: Field) -> Self {\n        value\n    }\n}\n\nimpl FromField for bool {\n    #[inline_always]\n    fn from_field(value: Field) -> Self {\n        value as bool\n    }\n}\nimpl FromField for u1 {\n    #[inline_always]\n    fn from_field(value: Field) -> Self {\n        value as u1\n    }\n}\nimpl FromField for u8 {\n    #[inline_always]\n    fn from_field(value: Field) -> Self {\n        value as u8\n    }\n}\nimpl FromField for u32 {\n    #[inline_always]\n    fn from_field(value: Field) -> Self {\n        value as u32\n    }\n}\nimpl FromField for u64 {\n    #[inline_always]\n    fn from_field(value: Field) -> Self {\n        value as u64\n    }\n}\nimpl FromField for u128 {\n    #[inline_always]\n    fn from_field(value: Field) -> Self {\n        value as u128\n    }\n}\n\n// docs:start:serialize\n/// Trait for serializing Noir types into arrays of Fields.\n///\n/// An implementation of the Serialize trait has to follow Noir's intrinsic serialization (each member of a struct\n/// converted directly into one or more Fields without any packing or compression). This trait (and Deserialize) are\n/// typically used to communicate between Noir and TypeScript (via oracles and function arguments).\n///\n/// # On Following Noir's Intrinsic Serialization\n/// When calling a Noir function from TypeScript (TS), first the function arguments are serialized into an array\n/// of fields. This array is then included in the initial witness. Noir's intrinsic serialization is then used\n/// to deserialize the arguments from the witness. When the same Noir function is called from Noir this Serialize trait\n/// is used instead of the serialization in TS. For this reason we need to have a match between TS serialization,\n/// Noir's intrinsic serialization and the implementation of this trait. If there is a mismatch, the function calls\n/// fail with an arguments hash mismatch error message.\n///\n/// # Type Parameters\n/// * `N` - The length of the output Field array, known at compile time\n///\n/// # Example\n/// ```\n/// impl<let N: u32> Serialize<N> for str<N> {\n///     fn serialize(self) -> [Field; N] {\n///         let bytes = self.as_bytes();\n///         let mut fields = [0; N];\n///         for i in 0..bytes.len() {\n///             fields[i] = bytes[i] as Field;  // Each byte gets its own Field\n///         }\n///         fields\n///     }\n/// }\n/// ```\n#[derive_via(derive_serialize)]\npub trait Serialize<let N: u32> {\n    fn serialize(self) -> [Field; N];\n}\n// docs:end:serialize\n\nimpl<let N: u32> Serialize<N> for str<N> {\n    #[inline_always]\n    fn serialize(self) -> [Field; N] {\n        let bytes = self.as_bytes();\n        let mut fields = [0; N];\n        for i in 0..bytes.len() {\n            fields[i] = bytes[i] as Field;\n        }\n        fields\n    }\n}\n\n// T = type of item in BoundedVec\n// M = max length of BoundedVec\n// O = field length of T\n// O * M + 1 = total serialized length of BoundedVec<T, M> (the +1 is for length of the BoundedVec)\nimpl<T, let M: u32, let O: u32> Deserialize<O * M + 1> for BoundedVec<T, M>\nwhere\n    T: Deserialize<O>,\n{\n    #[inline_always]\n    fn deserialize(fields: [Field; O * M + 1]) -> Self {\n        let mut new_bounded_vec: BoundedVec<T, M> = BoundedVec::new();\n\n        let len = fields[0] as u32;\n        let mut index = 1;\n\n        for _ in 0..len {\n            let mut nested_fields = [0; O];\n            for j in 0..O {\n                nested_fields[j] = fields[index];\n                index += 1;\n            }\n\n            let item = T::deserialize(nested_fields);\n            new_bounded_vec.push(item);\n        }\n\n        new_bounded_vec\n    }\n}\n\nimpl<T, let M: u32, let O: u32> Serialize<O * M + 1> for BoundedVec<T, M>\nwhere\n    T: Serialize<O>,\n{\n    #[inline_always]\n    fn serialize(self) -> [Field; O * M + 1] {\n        let mut fields = [0; O * M + 1];\n\n        let len = self.len();\n        fields[0] = len as Field;\n\n        let mut index: u32 = 1;\n\n        for i in 0..len {\n            let item = self.get_unchecked(i);\n            let serialized_item = item.serialize();\n\n            for j in 0..O {\n                fields[index] = serialized_item[j];\n                index += 1;\n            }\n        }\n\n        fields\n    }\n}\n\n// docs:start:deserialize\n/// Trait for deserializing Noir types from arrays of Fields.\n///\n/// An implementation of the Deserialize trait has to follow Noir's intrinsic serialization (each member of a struct\n/// converted directly into one or more Fields without any packing or compression). This trait is typically used when\n/// deserializing return values from function calls in Noir. Since the same function could be called from TypeScript\n/// (TS), in which case the TS deserialization would get used, we need to have a match between the 2.\n///\n/// # Type Parameters\n/// * `N` - The length of the input Field array, known at compile time\n///\n/// # Example\n/// ```\n/// impl<let N: u32> Deserialize<N> for str<N> {\n///     fn deserialize(fields: [Field; N]) -> Self {\n///         str<N>::from(fields.map(|value| value as u8))\n///     }\n/// }\n/// ```\n#[derive_via(derive_deserialize)]\npub trait Deserialize<let N: u32> {\n    fn deserialize(fields: [Field; N]) -> Self;\n}\n// docs:end:deserialize\n\nimpl<let N: u32> Deserialize<N> for str<N> {\n    #[inline_always]\n    fn deserialize(fields: [Field; N]) -> Self {\n        str::<N>::from(fields.map(|value| value as u8))\n    }\n}\n\n/// Trait for efficiently packing and unpacking Noir types into and from arrays of Fields.\n///\n/// The `Packable` trait allows types to be serialized and deserialized with a focus on minimizing the size of\n/// the resulting Field array. This trait is used when storage efficiency is critical (e.g. when storing data\n/// in the contract's public storage).\n///\n/// # Type Parameters\n/// * `N` - The length of the Field array, known at compile time.\n#[derive_via(derive_packable)]\npub trait Packable<let N: u32> {\n    /// Packs the current value into a compact array of `Field` elements.\n    fn pack(self) -> [Field; N];\n\n    /// Unpacks a compact array of `Field` elements into the original value.\n    fn unpack(fields: [Field; N]) -> Self;\n}\n"
    },
    "336": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/noir-protocol-circuits/crates/types/src/type_packing.nr",
      "source": "use crate::traits::Packable;\n\nglobal BOOL_PACKED_LEN: u32 = 1;\nglobal U8_PACKED_LEN: u32 = 1;\nglobal U16_PACKED_LEN: u32 = 1;\nglobal U32_PACKED_LEN: u32 = 1;\nglobal U64_PACKED_LEN: u32 = 1;\nglobal U128_PACKED_LEN: u32 = 1;\nglobal FIELD_PACKED_LEN: u32 = 1;\nglobal I8_PACKED_LEN: u32 = 1;\nglobal I16_PACKED_LEN: u32 = 1;\nglobal I32_PACKED_LEN: u32 = 1;\nglobal I64_PACKED_LEN: u32 = 1;\n\nimpl Packable<BOOL_PACKED_LEN> for bool {\n    fn pack(self) -> [Field; BOOL_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; BOOL_PACKED_LEN]) -> bool {\n        fields[0] as bool\n    }\n}\n\nimpl Packable<U8_PACKED_LEN> for u8 {\n    fn pack(self) -> [Field; U8_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; U8_PACKED_LEN]) -> Self {\n        fields[0] as u8\n    }\n}\n\nimpl Packable<U16_PACKED_LEN> for u16 {\n    fn pack(self) -> [Field; U16_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; U16_PACKED_LEN]) -> Self {\n        fields[0] as u16\n    }\n}\n\nimpl Packable<U32_PACKED_LEN> for u32 {\n    fn pack(self) -> [Field; U32_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; U32_PACKED_LEN]) -> Self {\n        fields[0] as u32\n    }\n}\n\nimpl Packable<U64_PACKED_LEN> for u64 {\n    fn pack(self) -> [Field; U64_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; U64_PACKED_LEN]) -> Self {\n        fields[0] as u64\n    }\n}\n\nimpl Packable<U128_PACKED_LEN> for u128 {\n    fn pack(self) -> [Field; U128_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; U128_PACKED_LEN]) -> Self {\n        fields[0] as u128\n    }\n}\n\nimpl Packable<FIELD_PACKED_LEN> for Field {\n    fn pack(self) -> [Field; FIELD_PACKED_LEN] {\n        [self]\n    }\n\n    fn unpack(fields: [Field; FIELD_PACKED_LEN]) -> Self {\n        fields[0]\n    }\n}\n\nimpl Packable<I8_PACKED_LEN> for i8 {\n    fn pack(self) -> [Field; I8_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; I8_PACKED_LEN]) -> Self {\n        fields[0] as i8\n    }\n}\n\nimpl Packable<I16_PACKED_LEN> for i16 {\n    fn pack(self) -> [Field; I16_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; I16_PACKED_LEN]) -> Self {\n        fields[0] as i16\n    }\n}\n\nimpl Packable<I32_PACKED_LEN> for i32 {\n    fn pack(self) -> [Field; I32_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; I32_PACKED_LEN]) -> Self {\n        fields[0] as i32\n    }\n}\n\nimpl Packable<I64_PACKED_LEN> for i64 {\n    fn pack(self) -> [Field; I64_PACKED_LEN] {\n        [self as Field]\n    }\n\n    fn unpack(fields: [Field; I64_PACKED_LEN]) -> Self {\n        fields[0] as i64\n    }\n}\n\nimpl<T, let N: u32, let M: u32> Packable<N * M> for [T; N]\nwhere\n    T: Packable<M>,\n{\n    fn pack(self) -> [Field; N * M] {\n        let mut result: [Field; N * M] = std::mem::zeroed();\n        let mut serialized: [Field; M] = std::mem::zeroed();\n        for i in 0..N {\n            serialized = self[i].pack();\n            for j in 0..M {\n                result[i * M + j] = serialized[j];\n            }\n        }\n        result\n    }\n\n    fn unpack(fields: [Field; N * M]) -> Self {\n        let mut reader = crate::utils::reader::Reader::new(fields);\n        let mut result: [T; N] = std::mem::zeroed();\n        reader.read_struct_array::<T, M, N>(Packable::unpack, result)\n    }\n}\n\n#[test]\nfn test_u16_packing() {\n    let a: u16 = 10;\n    assert_eq(a, u16::unpack(a.pack()));\n}\n\n#[test]\nfn test_i8_packing() {\n    let a: i8 = -10;\n    assert_eq(a, i8::unpack(a.pack()));\n}\n\n#[test]\nfn test_i16_packing() {\n    let a: i16 = -10;\n    assert_eq(a, i16::unpack(a.pack()));\n}\n\n#[test]\nfn test_i32_packing() {\n    let a: i32 = -10;\n    assert_eq(a, i32::unpack(a.pack()));\n}\n\n#[test]\nfn test_i64_packing() {\n    let a: i64 = -10;\n    assert_eq(a, i64::unpack(a.pack()));\n}\n"
    },
    "337": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/noir-protocol-circuits/crates/types/src/type_serialization.nr",
      "source": "use crate::traits::{Deserialize, Serialize};\n\nglobal BOOL_SERIALIZED_LEN: u32 = 1;\nglobal U8_SERIALIZED_LEN: u32 = 1;\nglobal U16_SERIALIZED_LEN: u32 = 1;\nglobal U32_SERIALIZED_LEN: u32 = 1;\nglobal U64_SERIALIZED_LEN: u32 = 1;\nglobal U128_SERIALIZED_LEN: u32 = 1;\nglobal FIELD_SERIALIZED_LEN: u32 = 1;\nglobal I8_SERIALIZED_LEN: u32 = 1;\nglobal I16_SERIALIZED_LEN: u32 = 1;\nglobal I32_SERIALIZED_LEN: u32 = 1;\nglobal I64_SERIALIZED_LEN: u32 = 1;\n\nimpl Serialize<BOOL_SERIALIZED_LEN> for bool {\n    fn serialize(self) -> [Field; BOOL_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<BOOL_SERIALIZED_LEN> for bool {\n    fn deserialize(fields: [Field; BOOL_SERIALIZED_LEN]) -> bool {\n        fields[0] as bool\n    }\n}\n\nimpl Serialize<U8_SERIALIZED_LEN> for u8 {\n    fn serialize(self) -> [Field; U8_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U8_SERIALIZED_LEN> for u8 {\n    fn deserialize(fields: [Field; U8_SERIALIZED_LEN]) -> Self {\n        fields[0] as u8\n    }\n}\n\nimpl Serialize<U16_SERIALIZED_LEN> for u16 {\n    fn serialize(self) -> [Field; U16_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U16_SERIALIZED_LEN> for u16 {\n    fn deserialize(fields: [Field; U16_SERIALIZED_LEN]) -> Self {\n        fields[0] as u16\n    }\n}\n\nimpl Serialize<U32_SERIALIZED_LEN> for u32 {\n    fn serialize(self) -> [Field; U32_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U32_SERIALIZED_LEN> for u32 {\n    fn deserialize(fields: [Field; U32_SERIALIZED_LEN]) -> Self {\n        fields[0] as u32\n    }\n}\n\nimpl Serialize<U64_SERIALIZED_LEN> for u64 {\n    fn serialize(self) -> [Field; U64_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U64_SERIALIZED_LEN> for u64 {\n    fn deserialize(fields: [Field; U64_SERIALIZED_LEN]) -> Self {\n        fields[0] as u64\n    }\n}\n\nimpl Serialize<U128_SERIALIZED_LEN> for u128 {\n    fn serialize(self) -> [Field; U128_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<U128_SERIALIZED_LEN> for u128 {\n    fn deserialize(fields: [Field; U128_SERIALIZED_LEN]) -> Self {\n        fields[0] as u128\n    }\n}\n\nimpl Serialize<FIELD_SERIALIZED_LEN> for Field {\n    fn serialize(self) -> [Field; FIELD_SERIALIZED_LEN] {\n        [self]\n    }\n}\n\nimpl Deserialize<FIELD_SERIALIZED_LEN> for Field {\n    fn deserialize(fields: [Field; FIELD_SERIALIZED_LEN]) -> Self {\n        fields[0]\n    }\n}\n\nimpl Serialize<I8_SERIALIZED_LEN> for i8 {\n    fn serialize(self) -> [Field; I8_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I8_SERIALIZED_LEN> for i8 {\n    fn deserialize(fields: [Field; I8_SERIALIZED_LEN]) -> Self {\n        fields[0] as i8\n    }\n}\n\nimpl Serialize<I16_SERIALIZED_LEN> for i16 {\n    fn serialize(self) -> [Field; I16_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I16_SERIALIZED_LEN> for i16 {\n    fn deserialize(fields: [Field; I16_SERIALIZED_LEN]) -> Self {\n        fields[0] as i16\n    }\n}\n\nimpl Serialize<I32_SERIALIZED_LEN> for i32 {\n    fn serialize(self) -> [Field; I32_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I32_SERIALIZED_LEN> for i32 {\n    fn deserialize(fields: [Field; I32_SERIALIZED_LEN]) -> Self {\n        fields[0] as i32\n    }\n}\n\nimpl Serialize<I64_SERIALIZED_LEN> for i64 {\n    fn serialize(self) -> [Field; I64_SERIALIZED_LEN] {\n        [self as Field]\n    }\n}\n\nimpl Deserialize<I64_SERIALIZED_LEN> for i64 {\n    fn deserialize(fields: [Field; I64_SERIALIZED_LEN]) -> Self {\n        fields[0] as i64\n    }\n}\n\nimpl<T, let N: u32, let M: u32> Serialize<N * M> for [T; N]\nwhere\n    T: Serialize<M>,\n{\n    fn serialize(self) -> [Field; N * M] {\n        let mut result: [Field; N * M] = std::mem::zeroed();\n        let mut serialized: [Field; M] = std::mem::zeroed();\n        for i in 0..N {\n            serialized = self[i].serialize();\n            for j in 0..M {\n                result[i * M + j] = serialized[j];\n            }\n        }\n        result\n    }\n}\n\nimpl<T, let N: u32, let M: u32> Deserialize<N * M> for [T; N]\nwhere\n    T: Deserialize<M>,\n{\n    fn deserialize(fields: [Field; N * M]) -> Self {\n        let mut reader = crate::utils::reader::Reader::new(fields);\n        let mut result: [T; N] = std::mem::zeroed();\n        reader.read_struct_array::<T, M, N>(Deserialize::deserialize, result)\n    }\n}\n\n#[test]\nfn test_u16_serialization() {\n    let a: u16 = 10;\n    assert_eq(a, u16::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i8_serialization() {\n    let a: i8 = -10;\n    assert_eq(a, i8::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i16_serialization() {\n    let a: i16 = -10;\n    assert_eq(a, i16::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i32_serialization() {\n    let a: i32 = -10;\n    assert_eq(a, i32::deserialize(a.serialize()));\n}\n\n#[test]\nfn test_i64_serialization() {\n    let a: i64 = -10;\n    assert_eq(a, i64::deserialize(a.serialize()));\n}\n"
    },
    "353": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/noir-protocol-circuits/crates/types/src/utils/arrays.nr",
      "source": "pub mod assert_array_appended;\npub mod assert_array_prepended;\npub mod assert_combined_array;\npub mod assert_combined_transformed_array;\npub mod assert_exposed_sorted_transformed_value_array;\npub mod assert_sorted_array;\npub mod assert_sorted_transformed_value_array;\npub mod assert_split_sorted_transformed_value_arrays;\npub mod assert_split_transformed_value_arrays;\npub mod get_sorted_result;\npub mod get_sorted_tuple;\npub mod sort_by;\npub mod sort_by_counter;\n\n// Re-exports.\npub use assert_array_appended::{\n    assert_array_appended, assert_array_appended_and_scoped, assert_array_appended_reversed,\n    assert_array_appended_scoped,\n};\npub use assert_array_prepended::assert_array_prepended;\npub use assert_combined_array::{assert_combined_array, combine_arrays};\npub use assert_combined_transformed_array::{\n    assert_combined_transformed_array, combine_and_transform_arrays,\n};\npub use assert_exposed_sorted_transformed_value_array::{\n    assert_exposed_sorted_transformed_value_array,\n    get_order_hints::{get_order_hints_asc, OrderHint},\n};\npub use assert_sorted_array::assert_sorted_array;\npub use assert_sorted_transformed_value_array::{\n    assert_sorted_transformed_value_array, assert_sorted_transformed_value_array_capped_size,\n};\npub use assert_split_sorted_transformed_value_arrays::{\n    assert_split_sorted_transformed_value_arrays_asc,\n    get_split_order_hints::{get_split_order_hints_asc, SplitOrderHints},\n};\npub use assert_split_transformed_value_arrays::assert_split_transformed_value_arrays;\npub use get_sorted_result::{get_sorted_result, SortedResult};\npub use sort_by_counter::sort_by_counter_asc;\n\nuse crate::traits::{Empty, is_empty};\n\npub fn subarray<let SRC_LEN: u32, let DST_LEN: u32>(\n    src: [Field; SRC_LEN],\n    offset: u32,\n) -> [Field; DST_LEN] {\n    assert(offset + DST_LEN <= SRC_LEN, \"offset too large\");\n\n    let mut dst: [Field; DST_LEN] = std::mem::zeroed();\n    for i in 0..DST_LEN {\n        dst[i] = src[i + offset];\n    }\n\n    dst\n}\n\n// Helper function to convert a validated array to BoundedVec.\n// Important: Only use it for validated arrays: validate_array(array) should be true.\npub unconstrained fn array_to_bounded_vec<T, let N: u32>(array: [T; N]) -> BoundedVec<T, N>\nwhere\n    T: Empty + Eq,\n{\n    let len = array_length(array);\n    BoundedVec::from_parts_unchecked(array, len)\n}\n\n// Helper function to find the index of the first element in an array that satisfies a given predicate. If the element\n// is not found, the function returns N as the index.\npub unconstrained fn find_index_hint<T, let N: u32, Env>(\n    array: [T; N],\n    find: fn[Env](T) -> bool,\n) -> u32 {\n    let mut index = N;\n    for i in 0..N {\n        // We check `index == N` to ensure that we only update the index if we haven't found a match yet.\n        if (index == N) & find(array[i]) {\n            index = i;\n        }\n    }\n    index\n}\n\n// Routine which validates that all zero values of an array form a contiguous region at the end, i.e.,\n// of the form: [*,*,*...,0,0,0,0] where any * is non-zero. Note that a full array of non-zero values is\n// valid.\npub fn validate_array<T, let N: u32>(array: [T; N]) -> u32\nwhere\n    T: Empty + Eq,\n{\n    let mut seen_empty = false;\n    let mut length = 0;\n    for i in 0..N {\n        if is_empty(array[i]) {\n            seen_empty = true;\n        } else {\n            assert(seen_empty == false, \"invalid array\");\n            length += 1;\n        }\n    }\n    length\n}\n\n// Helper function to count the number of non-empty elements in a validated array.\n// Important: Only use it for validated arrays where validate_array(array) returns true,\n// which ensures that:\n// 1. All elements before the first empty element are non-empty\n// 2. All elements after and including the first empty element are empty\n// 3. The array forms a contiguous sequence of non-empty elements followed by empty elements\npub fn array_length<T, let N: u32>(array: [T; N]) -> u32\nwhere\n    T: Empty + Eq,\n{\n    // We get the length by checking the index of the first empty element.\n\n    // Safety: This is safe because we have validated the array (see function doc above) and the emptiness\n    // of the element and non-emptiness of the previous element is checked below.\n    let length = unsafe { find_index_hint(array, |elem: T| is_empty(elem)) };\n    if length != 0 {\n        assert(!is_empty(array[length - 1]));\n    }\n    if length != N {\n        assert(is_empty(array[length]));\n    }\n    length\n}\n\n// Returns the number of consecutive elements at the start of the array for which the predicate returns false.\n// This function ensures that any element after the first matching element (predicate returns true) also matches the predicate.\npub fn array_length_until<T, let N: u32, Env>(array: [T; N], predicate: fn[Env](T) -> bool) -> u32 {\n    let mut length = 0;\n    let mut stop = false;\n    for i in 0..N {\n        if predicate(array[i]) {\n            stop = true;\n        } else {\n            assert(\n                stop == false,\n                \"matching element found after already encountering a non-matching element\",\n            );\n            length += 1;\n        }\n    }\n    length\n}\n\npub fn array_concat<T, let N: u32, let M: u32>(array1: [T; N], array2: [T; M]) -> [T; N + M] {\n    let mut result = [array1[0]; N + M];\n    for i in 1..N {\n        result[i] = array1[i];\n    }\n    for i in 0..M {\n        result[i + N] = array2[i];\n    }\n    result\n}\n\n/// This function assumes that `array1` and `array2` contain no more than N non-empty elements between them,\n/// if this is not the case then elements from the end of `array2` will be dropped.\npub fn array_merge<T, let N: u32>(array1: [T; N], array2: [T; N]) -> [T; N]\nwhere\n    T: Empty + Eq,\n{\n    // Safety: we constrain this array below\n    let result = unsafe { array_merge_helper(array1, array2) };\n    // We assume arrays have been validated. The only use cases so far are with previously validated arrays.\n    let array1_len = array_length(array1);\n    let mut add_from_left = true;\n    for i in 0..N {\n        add_from_left &= i != array1_len;\n        if add_from_left {\n            assert_eq(result[i], array1[i]);\n        } else {\n            assert_eq(result[i], array2[i - array1_len]);\n        }\n    }\n    result\n}\n\nunconstrained fn array_merge_helper<T, let N: u32>(array1: [T; N], array2: [T; N]) -> [T; N]\nwhere\n    T: Empty + Eq,\n{\n    let mut result: [T; N] = [T::empty(); N];\n    let mut i = 0;\n    for elem in array1 {\n        if !is_empty(elem) {\n            result[i] = elem;\n            i += 1;\n        }\n    }\n    for elem in array2 {\n        if !is_empty(elem) {\n            result[i] = elem;\n            i += 1;\n        }\n    }\n    result\n}\n\n// Helper fn to create a subarray from a given array\npub fn array_splice<T, let N: u32, let M: u32>(array: [T; N], offset: u32) -> [T; M]\nwhere\n    T: Empty,\n{\n    assert(M + offset <= N, \"Subarray length larger than array length\");\n    let mut result: [T; M] = [T::empty(); M];\n    for i in 0..M {\n        result[i] = array[offset + i];\n    }\n    result\n}\n\npub fn check_permutation<T, let N: u32>(\n    original_array: [T; N],\n    permuted_array: [T; N],\n    original_indexes: [u32; N],\n)\nwhere\n    T: Eq + Empty,\n{\n    let mut seen_value = [false; N];\n    for i in 0..N {\n        let index = original_indexes[i];\n        let original_value = original_array[index];\n        assert(permuted_array[i].eq(original_value), \"Invalid index\");\n        assert(!seen_value[index], \"Duplicated index\");\n        seen_value[index] = true;\n    }\n}\n\n// Helper function to find the index of the last element in an array, allowing empty elements.\n// e.g. useful for removing trailing 0s from [1, 0, 2, 0, 0, 0] -> [1, 0, 2]\n// Nothing to do with validated arrays. Correctness constrained by padded_array_length.\npub unconstrained fn find_last_value_index<T, let N: u32>(array: [T; N]) -> u32\nwhere\n    T: Empty + Eq,\n{\n    let mut index = N;\n    for i in 0..N {\n        let j = N - i - 1;\n        // We check `index == N` to ensure that we only update the index if we haven't found a match yet.\n        if (index == N) & !is_empty(array[j]) {\n            index = j;\n        }\n    }\n    index\n}\n\n// Routine which returns the length of an array right padded by empty elements\n// of the form: [*,*,*...,0,0,0,0] where * is any value (zeroes allowed).\n// See smoke_validate_array_trailing for examples.\n// Nothing to do with validated arrays. Correctness constrained by padded_array_length.\npub unconstrained fn unsafe_padded_array_length<T, let N: u32>(array: [T; N]) -> u32\nwhere\n    T: Empty + Eq,\n{\n    let index = find_last_value_index(array);\n    if index == N {\n        0\n    } else {\n        index + 1\n    }\n}\n\n// Routine which validates that zero values of an array form a contiguous region at the end, i.e.,\n// of the form: [*,*,*...,0,0,0,0] where * is any value (zeroes allowed).\npub fn padded_array_length<T, let N: u32>(array: [T; N]) -> u32\nwhere\n    T: Empty + Eq,\n{\n    // Safety: this value is constrained in the below loop.\n    let length = unsafe { unsafe_padded_array_length(array) };\n    // Check the elt just before length is non-zero:\n    if length != 0 {\n        assert(!is_empty(array[length - 1]), \"invalid right padded array\");\n    }\n    // Check all beyond length are zero:\n    let mut check_zero = false;\n    for i in 0..N {\n        check_zero |= i == length;\n        if check_zero {\n            assert(is_empty(array[i]), \"invalid right padded array\");\n        }\n    }\n    length\n}\n\n// Helper function to check if an array is padded with a given value from a given index.\n// Different to padded_array_length in that it allows the elements before the given index to be the same as the padded value.\npub fn array_padded_with<T, let N: u32>(array: [T; N], from_index: u32, padded_with: T) -> bool\nwhere\n    T: Eq,\n{\n    let mut is_valid = true;\n    let mut should_check = false;\n    for i in 0..N {\n        should_check |= i == from_index;\n        is_valid &= !should_check | (array[i] == padded_with);\n    }\n    is_valid\n}\n\n#[test]\nfn smoke_validate_array() {\n    let valid_array: [Field; 0] = [];\n    assert(validate_array(valid_array) == 0);\n\n    let valid_array = [0];\n    assert(validate_array(valid_array) == 0);\n\n    let valid_array = [3];\n    assert(validate_array(valid_array) == 1);\n\n    let valid_array = [1, 2, 3];\n    assert(validate_array(valid_array) == 3);\n\n    let valid_array = [1, 2, 3, 0];\n    assert(validate_array(valid_array) == 3);\n\n    let valid_array = [1, 2, 3, 0, 0];\n    assert(validate_array(valid_array) == 3);\n}\n\n#[test]\nfn smoke_validate_array_trailing() {\n    let valid_array: [Field; 0] = [];\n    assert(padded_array_length(valid_array) == 0);\n\n    let valid_array = [0];\n    assert(padded_array_length(valid_array) == 0);\n\n    let valid_array = [3];\n    assert(padded_array_length(valid_array) == 1);\n\n    let valid_array = [1, 0, 3];\n    assert(padded_array_length(valid_array) == 3);\n\n    let valid_array = [1, 0, 3, 0];\n    assert(padded_array_length(valid_array) == 3);\n\n    let valid_array = [1, 2, 3, 0, 0];\n    assert(padded_array_length(valid_array) == 3);\n\n    let valid_array = [0, 0, 3, 0, 0];\n    assert(padded_array_length(valid_array) == 3);\n}\n\n#[test(should_fail_with = \"invalid array\")]\nfn smoke_validate_array_invalid_case0() {\n    let invalid_array = [0, 1];\n    let _ = validate_array(invalid_array);\n}\n\n#[test(should_fail_with = \"invalid array\")]\nfn smoke_validate_array_invalid_case1() {\n    let invalid_array = [1, 0, 0, 1, 0];\n    let _ = validate_array(invalid_array);\n}\n\n#[test(should_fail_with = \"invalid array\")]\nfn smoke_validate_array_invalid_case2() {\n    let invalid_array = [0, 0, 0, 0, 1];\n    let _ = validate_array(invalid_array);\n}\n\n#[test]\nfn test_empty_array_length() {\n    assert_eq(array_length([0]), 0);\n    assert_eq(array_length([0, 0, 0]), 0);\n}\n\n#[test]\nfn test_array_length() {\n    assert_eq(array_length([123]), 1);\n    assert_eq(array_length([123, 0, 0]), 1);\n    assert_eq(array_length([123, 456]), 2);\n    assert_eq(array_length([123, 456, 0]), 2);\n}\n\n#[test]\nfn test_array_length_invalid_arrays() {\n    // Result can be misleading (but correct) for invalid arrays.\n    assert_eq(array_length([0, 0, 123]), 0);\n    assert_eq(array_length([0, 123, 0]), 0);\n    assert_eq(array_length([0, 123, 456]), 0);\n    assert_eq(array_length([123, 0, 456]), 1);\n}\n\n#[test]\nfn test_array_length_until() {\n    let array = [11, 22, 33, 44, 55];\n    assert_eq(array_length_until(array, |x| x == 55), 4);\n    assert_eq(array_length_until(array, |x| x == 56), 5);\n    assert_eq(array_length_until(array, |x| x > 40), 3);\n    assert_eq(array_length_until(array, |x| x > 10), 0);\n}\n\n#[test(should_fail_with = \"matching element found after already encountering a non-matching element\")]\nfn test_array_length_until_non_consecutive_fails() {\n    let array = [1, 1, 0, 1, 0];\n    let _ = array_length_until(array, |x| x == 0);\n}\n\n#[test(should_fail_with = \"matching element found after already encountering a non-matching element\")]\nfn test_array_length_until_first_non_matching_fails() {\n    let array = [1, 0, 0, 0, 0];\n    let _ = array_length_until(array, |x| x == 1);\n}\n\n#[test]\nunconstrained fn find_index_greater_than_min() {\n    let values = [10, 20, 30, 40];\n    let min = 22;\n    let index = find_index_hint(values, |v: Field| min.lt(v));\n    assert_eq(index, 2);\n}\n\n#[test]\nunconstrained fn find_index_not_found() {\n    let values = [10, 20, 30, 40];\n    let min = 100;\n    let index = find_index_hint(values, |v: Field| min.lt(v));\n    assert_eq(index, 4);\n}\n\n#[test]\nfn test_array_concat() {\n    let array0 = [1, 2, 3];\n    let array1 = [4, 5];\n    let concatenated = array_concat(array0, array1);\n    assert_eq(concatenated, [1, 2, 3, 4, 5]);\n}\n\n#[test]\nfn check_permutation_basic_test() {\n    let original_array = [1, 2, 3];\n    let permuted_array = [3, 1, 2];\n    let indexes = [2, 0, 1];\n    check_permutation(original_array, permuted_array, indexes);\n}\n\n#[test(should_fail_with = \"Duplicated index\")]\nfn check_permutation_duplicated_index() {\n    let original_array = [0, 1, 0];\n    let permuted_array = [1, 0, 0];\n    let indexes = [1, 0, 0];\n    check_permutation(original_array, permuted_array, indexes);\n}\n\n#[test(should_fail_with = \"Invalid index\")]\nfn check_permutation_invalid_index() {\n    let original_array = [0, 1, 2];\n    let permuted_array = [1, 0, 0];\n    let indexes = [1, 0, 2];\n    check_permutation(original_array, permuted_array, indexes);\n}\n\n#[test]\nfn test_array_padded_with() {\n    let array = [11, 22, 33, 44, 44];\n    assert_eq(array_padded_with(array, 0, 44), false);\n    assert_eq(array_padded_with(array, 1, 44), false);\n    assert_eq(array_padded_with(array, 2, 44), false);\n    assert_eq(array_padded_with(array, 3, 44), true);\n    assert_eq(array_padded_with(array, 4, 44), true);\n    assert_eq(array_padded_with(array, 4, 33), false);\n    assert_eq(array_padded_with(array, 5, 44), true); // Index out of bounds.\n    assert_eq(array_padded_with(array, 0, 11), false);\n}\n"
    },
    "366": {
      "path": "/Users/satyam/nargo/github.com/noir-lang/sha256/v0.1.2/src/sha256.nr",
      "source": "use std::hash::sha256_compression;\nuse std::runtime::is_unconstrained;\n\nuse constants::{\n    BLOCK_BYTE_PTR, BLOCK_SIZE, HASH, INITIAL_STATE, INT_BLOCK, INT_BLOCK_SIZE, INT_SIZE,\n    INT_SIZE_PTR, MSG_BLOCK, MSG_SIZE_PTR, STATE, TWO_POW_16, TWO_POW_24, TWO_POW_32, TWO_POW_8,\n};\n\nmod constants;\nmod tests;\n\n// Implementation of SHA-256 mapping a byte array of variable length to\n// 32 bytes.\n\n// Deprecated in favour of `sha256_var`\n// docs:start:sha256\npub fn sha256<let N: u32>(input: [u8; N]) -> HASH\n// docs:end:sha256\n{\n    digest(input)\n}\n\n// SHA-256 hash function\n#[no_predicates]\npub fn digest<let N: u32>(msg: [u8; N]) -> HASH {\n    sha256_var(msg, N as u64)\n}\n\n// Variable size SHA-256 hash\npub fn sha256_var<let N: u32>(msg: [u8; N], message_size: u64) -> HASH {\n    let message_size = message_size as u32;\n    assert(message_size <= N);\n\n    if std::runtime::is_unconstrained() {\n        // Safety: SHA256 is running as an unconstrained function.\n        unsafe {\n            __sha256_var(msg, message_size)\n        }\n    } else {\n        let mut msg_block: MSG_BLOCK = [0; INT_BLOCK_SIZE];\n        // Intermediate hash, starting with the canonical initial value\n        let mut h: STATE = INITIAL_STATE;\n        // Pointer into msg_block on a 64 byte scale\n        let mut msg_byte_ptr = 0;\n        let num_blocks = N / BLOCK_SIZE;\n        for i in 0..num_blocks {\n            let msg_start = BLOCK_SIZE * i;\n            let (new_msg_block, new_msg_byte_ptr) =\n                unsafe { build_msg_block(msg, message_size, msg_start) };\n\n            if msg_start < message_size {\n                msg_block = new_msg_block;\n            }\n\n            // Verify the block we are compressing was appropriately constructed\n            let new_msg_byte_ptr = verify_msg_block(msg, message_size, msg_block, msg_start);\n            if msg_start < message_size {\n                msg_byte_ptr = new_msg_byte_ptr;\n            }\n\n            // If the block is filled, compress it.\n            // An un-filled block is handled after this loop.\n            if (msg_start < message_size) & (msg_byte_ptr == BLOCK_SIZE) {\n                h = sha256_compression(msg_block, h);\n            }\n        }\n\n        let modulo = N % BLOCK_SIZE;\n        // Handle setup of the final msg block.\n        // This case is only hit if the msg is less than the block size,\n        // or our message cannot be evenly split into blocks.\n        if modulo != 0 {\n            let msg_start = BLOCK_SIZE * num_blocks;\n            let (new_msg_block, new_msg_byte_ptr) =\n                unsafe { build_msg_block(msg, message_size, msg_start) };\n\n            if msg_start < message_size {\n                msg_block = new_msg_block;\n            }\n\n            let new_msg_byte_ptr = verify_msg_block(msg, message_size, msg_block, msg_start);\n            if msg_start < message_size {\n                msg_byte_ptr = new_msg_byte_ptr;\n                verify_msg_block_padding(msg_block, msg_byte_ptr);\n            }\n        }\n\n        // If we had modulo == 0 then it means the last block was full,\n        // and we can reset the pointer to zero to overwrite it.\n        if msg_byte_ptr == BLOCK_SIZE {\n            msg_byte_ptr = 0;\n        }\n\n        // Pad the rest such that we have a [u32; 2] block at the end representing the length\n        // of the message, and a block of 1 0 ... 0 following the message (i.e. [1 << 7, 0, ..., 0]).\n        // Here we rely on the fact that everything beyond the available input is set to 0.\n        let index = msg_byte_ptr / INT_SIZE;\n        msg_block[index] = set_item_byte_then_zeros(msg_block[index], msg_byte_ptr, 1 << 7);\n\n        msg_byte_ptr = msg_byte_ptr + 1;\n        let last_block = msg_block;\n\n        // If we don't have room to write the size, compress the block and reset it.\n        if msg_byte_ptr > MSG_SIZE_PTR {\n            h = sha256_compression(msg_block, h);\n            // `attach_len_to_msg_block` will zero out everything after the `msg_byte_ptr`.\n            msg_byte_ptr = 0;\n        }\n\n        msg_block = unsafe { attach_len_to_msg_block(msg_block, msg_byte_ptr, message_size) };\n\n        verify_msg_len(msg_block, last_block, msg_byte_ptr, message_size);\n\n        hash_final_block(msg_block, h)\n    }\n}\n\n// Variable size SHA-256 hash\nunconstrained fn __sha256_var<let N: u32>(msg: [u8; N], message_size: u32) -> HASH {\n    let num_full_blocks = message_size / BLOCK_SIZE;\n    // Intermediate hash, starting with the canonical initial value\n    let mut h: STATE = INITIAL_STATE;\n    // Pointer into msg_block on a 64 byte scale\n    for i in 0..num_full_blocks {\n        let (msg_block, _) = build_msg_block(msg, message_size, BLOCK_SIZE * i);\n        h = sha256_compression(msg_block, h);\n    }\n\n    // Handle setup of the final msg block.\n    // This case is only hit if the msg is less than the block size,\n    // or our message cannot be evenly split into blocks.\n    let modulo = message_size % BLOCK_SIZE;\n    let (mut msg_block, mut msg_byte_ptr): (INT_BLOCK, u32) = if modulo != 0 {\n        let msg_start = BLOCK_SIZE * num_full_blocks;\n        let (new_msg_block, new_msg_byte_ptr) = build_msg_block(msg, message_size, msg_start);\n\n        (new_msg_block, new_msg_byte_ptr)\n    } else {\n        // If we had modulo == 0 then it means the last block was full,\n        // and we can reset the pointer to zero to overwrite it.\n        ([0; INT_BLOCK_SIZE], 0)\n    };\n\n    // Pad the rest such that we have a [u32; 2] block at the end representing the length\n    // of the message, and a block of 1 0 ... 0 following the message (i.e. [1 << 7, 0, ..., 0]).\n    // Here we rely on the fact that everything beyond the available input is set to 0.\n    let index = msg_byte_ptr / INT_SIZE;\n    msg_block[index] = set_item_byte_then_zeros(msg_block[index], msg_byte_ptr, 1 << 7);\n\n    // If we don't have room to write the size, compress the block and reset it.\n    let (h, mut msg_byte_ptr): (STATE, u32) = if msg_byte_ptr >= MSG_SIZE_PTR {\n        // `attach_len_to_msg_block` will zero out everything after the `msg_byte_ptr`.\n        (sha256_compression(msg_block, h), 0)\n    } else {\n        (h, msg_byte_ptr + 1)\n    };\n    msg_block = attach_len_to_msg_block(msg_block, msg_byte_ptr, message_size);\n\n    hash_final_block(msg_block, h)\n}\n\n// Take `BLOCK_SIZE` number of bytes from `msg` starting at `msg_start`.\n// Returns the block and the length that has been copied rather than padded with zeros.\nunconstrained fn build_msg_block<let N: u32>(\n    msg: [u8; N],\n    message_size: u32,\n    msg_start: u32,\n) -> (MSG_BLOCK, BLOCK_BYTE_PTR) {\n    let mut msg_block: MSG_BLOCK = [0; INT_BLOCK_SIZE];\n\n    // We insert `BLOCK_SIZE` bytes (or up to the end of the message)\n    let block_input = if message_size < msg_start {\n        // This function is sometimes called with `msg_start` past the end of the message.\n        // In this case we return an empty block and zero pointer to signal that the result should be ignored.\n        0\n    } else if message_size < msg_start + BLOCK_SIZE {\n        message_size - msg_start\n    } else {\n        BLOCK_SIZE\n    };\n\n    // Figure out the number of items in the int array that we have to pack.\n    // e.g. if the input is [0,1,2,3,4,5] then we need to pack it as 2 items: [0123, 4500]\n    let mut int_input = block_input / INT_SIZE;\n    if block_input % INT_SIZE != 0 {\n        int_input = int_input + 1;\n    };\n\n    for i in 0..int_input {\n        let mut msg_item: u32 = 0;\n        // Always construct the integer as 4 bytes, even if it means going beyond the input.\n        for j in 0..INT_SIZE {\n            let k = i * INT_SIZE + j;\n            let msg_byte = if k < block_input {\n                msg[msg_start + k]\n            } else {\n                0\n            };\n            msg_item = lshift8(msg_item, 1) + msg_byte as u32;\n        }\n        msg_block[i] = msg_item;\n    }\n\n    // Returning the index as if it was a 64 byte array.\n    // We have to project it down to 16 items and bit shifting to get a byte back if we need it.\n    (msg_block, block_input)\n}\n\n// Verify the block we are compressing was appropriately constructed by `build_msg_block`\n// and matches the input data. Returns the index of the first unset item.\n// If `message_size` is less than `msg_start` then this is called with the old non-empty block;\n// in that case we can skip verification, ie. no need to check that everything is zero.\nfn verify_msg_block<let N: u32>(\n    msg: [u8; N],\n    message_size: u32,\n    msg_block: MSG_BLOCK,\n    msg_start: u32,\n) -> BLOCK_BYTE_PTR {\n    let mut msg_byte_ptr = 0;\n    let mut msg_end = msg_start + BLOCK_SIZE;\n    if msg_end > N {\n        msg_end = N;\n    }\n    // We might have to go beyond the input to pad the fields.\n    if msg_end % INT_SIZE != 0 {\n        msg_end = msg_end + INT_SIZE - msg_end % INT_SIZE;\n    }\n\n    // Reconstructed packed item.\n    let mut msg_item: u32 = 0;\n\n    // Inclusive at the end so that we can compare the last item.\n    let mut i: u32 = 0;\n    for k in msg_start..=msg_end {\n        if k % INT_SIZE == 0 {\n            // If we consumed some input we can compare against the block.\n            if (msg_start < message_size) & (k > msg_start) {\n                assert_eq(msg_block[i], msg_item as u32);\n                i = i + 1;\n                msg_item = 0;\n            }\n        }\n        // Shift the accumulator\n        msg_item = lshift8(msg_item, 1);\n        // If we have input to consume, add it at the rightmost position.\n        if k < message_size & k < msg_end {\n            msg_item = msg_item + msg[k] as u32;\n            msg_byte_ptr = msg_byte_ptr + 1;\n        }\n    }\n\n    msg_byte_ptr\n}\n\n// Verify the block we are compressing was appropriately padded with zeros by `build_msg_block`.\n// This is only relevant for the last, potentially partially filled block.\nfn verify_msg_block_padding(msg_block: MSG_BLOCK, msg_byte_ptr: BLOCK_BYTE_PTR) {\n    // Check all the way to the end of the block.\n    verify_msg_block_zeros(msg_block, msg_byte_ptr, INT_BLOCK_SIZE);\n}\n\n// Verify that a region of ints in the message block are (partially) zeroed,\n// up to an (exclusive) maximum which can either be the end of the block\n// or just where the size is to be written.\nfn verify_msg_block_zeros(\n    msg_block: MSG_BLOCK,\n    mut msg_byte_ptr: BLOCK_BYTE_PTR,\n    max_int_byte_ptr: u32,\n) {\n    // This variable is used to get around the compiler under-constrained check giving a warning.\n    // We want to check against a constant zero, but if it does not come from the circuit inputs\n    // or return values the compiler check will issue a warning.\n    let zero = msg_block[0] - msg_block[0];\n\n    // First integer which is supposed to be (partially) zero.\n    let mut int_byte_ptr = msg_byte_ptr / INT_SIZE;\n\n    // Check partial zeros.\n    let modulo = msg_byte_ptr % INT_SIZE;\n    if modulo != 0 {\n        let zeros = INT_SIZE - modulo;\n        let mask = if zeros == 3 {\n            TWO_POW_24\n        } else if zeros == 2 {\n            TWO_POW_16\n        } else {\n            TWO_POW_8\n        };\n        assert_eq(msg_block[int_byte_ptr] % mask, zero);\n        int_byte_ptr = int_byte_ptr + 1;\n    }\n\n    // Check the rest of the items.\n    for i in 0..max_int_byte_ptr {\n        if i >= int_byte_ptr {\n            assert_eq(msg_block[i], zero);\n        }\n    }\n}\n\n// Verify that up to the byte pointer the two blocks are equal.\n// At the byte pointer the new block can be partially zeroed.\nfn verify_msg_block_equals_last(\n    msg_block: MSG_BLOCK,\n    last_block: MSG_BLOCK,\n    mut msg_byte_ptr: BLOCK_BYTE_PTR,\n) {\n    // msg_byte_ptr is the position at which they are no longer have to be the same.\n    // First integer which is supposed to be (partially) zero contains that pointer.\n    let mut int_byte_ptr = msg_byte_ptr / INT_SIZE;\n\n    // Check partial zeros.\n    let modulo = msg_byte_ptr % INT_SIZE;\n    if modulo != 0 {\n        // Reconstruct the partially zero item from the last block.\n        let last_field = last_block[int_byte_ptr];\n        let mut msg_item: u32 = 0;\n        // Reset to where they are still equal.\n        msg_byte_ptr = msg_byte_ptr - modulo;\n        for i in 0..INT_SIZE {\n            msg_item = lshift8(msg_item, 1);\n            if i < modulo {\n                msg_item = msg_item + get_item_byte(last_field, msg_byte_ptr) as u32;\n                msg_byte_ptr = msg_byte_ptr + 1;\n            }\n        }\n        assert_eq(msg_block[int_byte_ptr], msg_item);\n    }\n\n    for i in 0..INT_SIZE_PTR {\n        if i < int_byte_ptr {\n            assert_eq(msg_block[i], last_block[i]);\n        }\n    }\n}\n\n// Set the rightmost `zeros` number of bytes to 0.\n#[inline_always]\nfn set_item_zeros(item: u32, zeros: u8) -> u32 {\n    lshift8(rshift8(item, zeros), zeros)\n}\n\n// Replace one byte in the item with a value, and set everything after it to zero.\nfn set_item_byte_then_zeros(msg_item: u32, msg_byte_ptr: BLOCK_BYTE_PTR, msg_byte: u8) -> u32 {\n    let zeros = INT_SIZE - msg_byte_ptr % INT_SIZE;\n    let zeroed_item = set_item_zeros(msg_item, zeros as u8);\n    let new_item = byte_into_item(msg_byte, msg_byte_ptr);\n    zeroed_item + new_item\n}\n\n// Get a byte of a message item according to its overall position in the `BLOCK_SIZE` space.\nfn get_item_byte(mut msg_item: u32, msg_byte_ptr: BLOCK_BYTE_PTR) -> u8 {\n    // How many times do we have to shift to the right to get to the position we want?\n    let max_shifts = INT_SIZE - 1;\n    let shifts = max_shifts - msg_byte_ptr % INT_SIZE;\n    msg_item = rshift8(msg_item, shifts as u8);\n    // At this point the byte we want is in the rightmost position.\n    msg_item as u8\n}\n\n// Project a byte into a position in a field based on the overall block pointer.\n// For example putting 1 into pointer 5 would be 100, because overall we would\n// have [____, 0100] with indexes [0123,4567].\n#[inline_always]\nfn byte_into_item(msg_byte: u8, msg_byte_ptr: BLOCK_BYTE_PTR) -> u32 {\n    let mut msg_item = msg_byte as u32;\n    // How many times do we have to shift to the left to get to the position we want?\n    let max_shifts = INT_SIZE - 1;\n    let shifts = max_shifts - msg_byte_ptr % INT_SIZE;\n    lshift8(msg_item, shifts as u8)\n}\n\n// Construct a field out of 4 bytes.\n#[inline_always]\nfn make_item(b0: u8, b1: u8, b2: u8, b3: u8) -> u32 {\n    let mut item = b0 as u32;\n    item = lshift8(item, 1) + b1 as u32;\n    item = lshift8(item, 1) + b2 as u32;\n    item = lshift8(item, 1) + b3 as u32;\n    item\n}\n\n// Shift by 8 bits to the left between 0 and 4 times.\n// Checks `is_unconstrained()` to just use a bitshift if we're running in an unconstrained context,\n// otherwise multiplies by 256.\n#[inline_always]\nfn lshift8(item: u32, shifts: u8) -> u32 {\n    if is_unconstrained() {\n        // Brillig wouldn't shift 0<<4 without overflow.\n        if shifts >= 4 {\n            0\n        } else {\n            item << (8 * shifts)\n        }\n    } else {\n        // We can do a for loop up to INT_SIZE or an if-else.\n        if shifts == 0 {\n            item\n        } else if shifts == 1 {\n            item * TWO_POW_8\n        } else if shifts == 2 {\n            item * TWO_POW_16\n        } else if shifts == 3 {\n            item * TWO_POW_24\n        } else {\n            // Doesn't make sense, but it's most likely called on 0 anyway.\n            0\n        }\n    }\n}\n\n// Shift by 8 bits to the right between 0 and 4 times.\n// Checks `is_unconstrained()` to just use a bitshift if we're running in an unconstrained context,\n// otherwise divides by 256.\nfn rshift8(item: u32, shifts: u8) -> u32 {\n    if is_unconstrained() {\n        item >> (8 * shifts)\n    } else {\n        // Division wouldn't work on `Field`.\n        if shifts == 0 {\n            item\n        } else if shifts == 1 {\n            item / TWO_POW_8\n        } else if shifts == 2 {\n            item / TWO_POW_16\n        } else if shifts == 3 {\n            item / TWO_POW_24\n        } else {\n            0\n        }\n    }\n}\n\n// Zero out all bytes between the end of the message and where the length is appended,\n// then write the length into the last 8 bytes of the block.\nunconstrained fn attach_len_to_msg_block(\n    mut msg_block: MSG_BLOCK,\n    mut msg_byte_ptr: BLOCK_BYTE_PTR,\n    message_size: u32,\n) -> MSG_BLOCK {\n    // We assume that `msg_byte_ptr` is less than 57 because if not then it is reset to zero before calling this function.\n    // In any case, fill blocks up with zeros until the last 64 bits (i.e. until msg_byte_ptr = 56).\n    // There can be one item which has to be partially zeroed.\n    let modulo = msg_byte_ptr % INT_SIZE;\n    if modulo != 0 {\n        // Index of the block in which we find the item we need to partially zero.\n        let i = msg_byte_ptr / INT_SIZE;\n        let zeros = INT_SIZE - modulo;\n        msg_block[i] = set_item_zeros(msg_block[i], zeros as u8);\n        msg_byte_ptr = msg_byte_ptr + zeros;\n    }\n\n    // The rest can be zeroed without bit shifting anything.\n    for i in (msg_byte_ptr / INT_SIZE)..INT_SIZE_PTR {\n        msg_block[i] = 0;\n    }\n\n    // Set the last two 4 byte ints as the first/second half of the 8 bytes of the length.\n    let len = 8 * message_size;\n    let len_bytes: [u8; 8] = (len as Field).to_be_bytes();\n    for i in 0..=1 {\n        let shift = i * 4;\n        msg_block[INT_SIZE_PTR + i] = make_item(\n            len_bytes[shift],\n            len_bytes[shift + 1],\n            len_bytes[shift + 2],\n            len_bytes[shift + 3],\n        );\n    }\n    msg_block\n}\n\n// Verify that the message length was correctly written by `attach_len_to_msg_block`,\n// and that everything between the byte pointer and the size pointer was zeroed,\n// and that everything before the byte pointer was untouched.\nfn verify_msg_len(\n    msg_block: MSG_BLOCK,\n    last_block: MSG_BLOCK,\n    msg_byte_ptr: BLOCK_BYTE_PTR,\n    message_size: u32,\n) {\n    // Check zeros up to the size pointer.\n    verify_msg_block_zeros(msg_block, msg_byte_ptr, INT_SIZE_PTR);\n\n    // Check that up to the pointer we match the last block.\n    verify_msg_block_equals_last(msg_block, last_block, msg_byte_ptr);\n\n    // We verify the message length was inserted correctly by reversing the byte decomposition.\n    let mut reconstructed_len: u64 = 0;\n    for i in INT_SIZE_PTR..INT_BLOCK_SIZE {\n        reconstructed_len = reconstructed_len * TWO_POW_32;\n        reconstructed_len = reconstructed_len + msg_block[i] as u64;\n    }\n    let len = 8 * message_size as u64;\n    assert_eq(reconstructed_len, len);\n}\n\n// Perform the final compression, then transform the `STATE` into `HASH`.\nfn hash_final_block(msg_block: MSG_BLOCK, mut state: STATE) -> HASH {\n    let mut out_h: HASH = [0; 32]; // Digest as sequence of bytes\n    // Hash final padded block\n    state = sha256_compression(msg_block, state);\n\n    // Return final hash as byte array\n    for j in 0..8 {\n        let h_bytes: [u8; 4] = (state[j] as Field).to_be_bytes();\n        for k in 0..4 {\n            out_h[4 * j + k] = h_bytes[k];\n        }\n    }\n\n    out_h\n}\n\nmod equivalence_test {\n\n    #[test]\n    fn test_implementations_agree(msg: [u8; 100], message_size: u64) {\n        let message_size = message_size % 100;\n        let unconstrained_sha = unsafe { super::__sha256_var(msg, message_size as u32) };\n        let sha = super::sha256_var(msg, message_size);\n        assert_eq(sha, unconstrained_sha);\n    }\n}\n"
    },
    "403": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/uint-note/src/uint_note.nr",
      "source": "use dep::aztec::{\n    context::{PrivateContext, PublicContext},\n    keys::getters::{get_nsk_app, get_public_keys},\n    macros::notes::custom_note,\n    messages::logs::note,\n    note::note_interface::{NoteHash, NoteType},\n    oracle::random::random,\n    protocol_types::{\n        address::AztecAddress,\n        constants::{GENERATOR_INDEX__NOTE_HASH, GENERATOR_INDEX__NOTE_NULLIFIER},\n        hash::poseidon2_hash_with_separator,\n        traits::{Deserialize, Hash, Packable, Serialize, ToField},\n        utils::arrays::array_concat,\n    },\n};\n\n// UintNote supports partial notes, i.e. the ability to create an incomplete note in private, hiding certain values (the\n// owner, storage slot and randomness), and then completing the note in public with the ones missing (the amount).\n// Partial notes are being actively developed and are not currently fully supported via macros, and so we rely on the\n// #[custom_note] macro to implement it manually, resulting in some boilerplate. This is expected to be unnecessary once\n// macro support is expanded.\n\n/// A private note representing a numeric value associated to an account (e.g. a token balance).\n#[custom_note]\n#[derive(Eq, Serialize)]\npub struct UintNote {\n    // The ordering of these fields is important given that it must:\n    //   a) match that of UintPartialNotePrivateContent, and\n    //   b) have the public field at the end\n    // Correct ordering is checked by the tests in this module.\n\n    /// The owner of the note, i.e. the account whose nullifier secret key is required to compute the nullifier.\n    owner: AztecAddress,\n    /// Random value, protects against note hash preimage attacks.\n    randomness: Field,\n    /// The number stored in the note.\n    value: u128,\n}\n\nimpl NoteHash for UintNote {\n    fn compute_note_hash(self, storage_slot: Field) -> Field {\n        // Partial notes can be implemented by having the note hash be either the result of multiscalar multiplication\n        // (MSM), or two rounds of poseidon. MSM results in more constraints and is only required when multiple variants\n        // of partial notes are supported. Because UintNote has just one variant (where the value is public), we use\n        // poseidon instead.\n\n        // We must compute the same note hash as would be produced by a partial note created and completed with the same\n        // values, so that notes all behave the same way regardless of how they were created. To achieve this, we\n        // perform both steps of the partial note computation.\n\n        // First we create the partial note from a commitment to the private content (including storage slot).\n        let private_content =\n            UintPartialNotePrivateContent { owner: self.owner, randomness: self.randomness };\n        let partial_note = PartialUintNote {\n            commitment: private_content.compute_partial_commitment(storage_slot),\n        };\n\n        // Then compute the completion note hash. In a real partial note this step would be performed in public.\n        partial_note.compute_complete_note_hash(self.value)\n    }\n\n    // The nullifiers are nothing special - this is just the canonical implementation that would be injected by the\n    // #[note] macro.\n\n    fn compute_nullifier(\n        self,\n        context: &mut PrivateContext,\n        note_hash_for_nullify: Field,\n    ) -> Field {\n        let owner_npk_m = get_public_keys(self.owner).npk_m;\n        let owner_npk_m_hash = owner_npk_m.hash();\n        let secret = context.request_nsk_app(owner_npk_m_hash);\n        poseidon2_hash_with_separator(\n            [note_hash_for_nullify, secret],\n            GENERATOR_INDEX__NOTE_NULLIFIER,\n        )\n    }\n\n    unconstrained fn compute_nullifier_unconstrained(self, note_hash_for_nullify: Field) -> Field {\n        let owner_npk_m = get_public_keys(self.owner).npk_m;\n        let owner_npk_m_hash = owner_npk_m.hash();\n        let secret = get_nsk_app(owner_npk_m_hash);\n        poseidon2_hash_with_separator(\n            [note_hash_for_nullify, secret],\n            GENERATOR_INDEX__NOTE_NULLIFIER,\n        )\n    }\n}\n\nimpl UintNote {\n    pub fn new(value: u128, owner: AztecAddress) -> Self {\n        // Safety: We use the randomness to preserve the privacy of the note recipient by preventing brute-forcing,\n        // so a malicious sender could use non-random values to make the note less private. But they already know\n        // the full note pre-image anyway, and so the recipient already trusts them to not disclose this\n        // information. We can therefore assume that the sender will cooperate in the random value generation.\n        let randomness = unsafe { random() };\n        Self { value, owner, randomness }\n    }\n\n    pub fn get_value(self) -> u128 {\n        self.value\n    }\n\n    /// Creates a partial note that will hide the owner and storage slot but not the value, since the note will be later\n    /// completed in public. This is a powerful technique for scenarios in which the value cannot be known in private\n    /// (e.g. because it depends on some public state, such as a DEX).\n    ///\n    /// The returned `PartialUintNote` value must be sent to public execution via a secure channel, since it is not\n    /// possible to verify the integrity of its contents due to it hiding information. The recommended ways to do this\n    /// are to retrieve it from public storage, or to receive it in an internal public function call.\n    ///\n    /// Each partial note should only be used once, since otherwise multiple notes would be linked together and known to\n    /// belong to the same owner.\n    ///\n    /// As part of the partial note creation process, a log will be sent to `recipient` from `sender` so that they can\n    /// discover the note. `recipient` will typically be the same as `owner`.\n    pub fn partial(\n        owner: AztecAddress,\n        storage_slot: Field,\n        context: &mut PrivateContext,\n        recipient: AztecAddress,\n        sender: AztecAddress,\n    ) -> PartialUintNote {\n        // Safety: We use the randomness to preserve the privacy of the note recipient by preventing brute-forcing,\n        // so a malicious sender could use non-random values to make the note less private. But they already know\n        // the full note pre-image anyway, and so the recipient already trusts them to not disclose this\n        // information. We can therefore assume that the sender will cooperate in the random value generation.\n        let randomness = unsafe { random() };\n\n        // We create a commitment to the private data, which we then use to construct the log we send to the recipient.\n        let commitment = UintPartialNotePrivateContent { owner, randomness }\n            .compute_partial_commitment(storage_slot);\n\n        // Our partial note log encoding scheme includes a field with the tag of the public completion log, and we use\n        // the commitment as the tag. This is good for multiple reasons:\n        //  - the commitment is uniquely tied to this partial note\n        //  - the commitment is already public information, so we're not revealing anything else\n        //  - we don't need to create any additional information, private or public, for the tag\n        //  - other contracts cannot impersonate us and emit logs with the same tag due to public log siloing\n        let private_log_content = PrivateUintPartialNotePrivateLogContent {\n            owner,\n            randomness,\n            public_log_tag: commitment,\n        };\n\n        let encrypted_log =\n            note::compute_partial_note_log(private_log_content, storage_slot, recipient, sender);\n        // Regardless of the original content size, the log is padded with random bytes up to\n        // `PRIVATE_LOG_SIZE_IN_FIELDS` to prevent leaking information about the actual size.\n        let length = encrypted_log.len();\n        context.emit_private_log(encrypted_log, length);\n\n        PartialUintNote { commitment }\n    }\n}\n\n/// The private content of a partial UintNote, i.e. the fields that will remain private. All other note fields will be\n/// made public.\n#[derive(Packable)]\nstruct UintPartialNotePrivateContent {\n    // The ordering of these fields is important given that it must match that of UintNote.\n    // Correct ordering is checked by the tests in this module.\n    owner: AztecAddress,\n    randomness: Field,\n}\n\nimpl UintPartialNotePrivateContent {\n    fn compute_partial_commitment(self, storage_slot: Field) -> Field {\n        // Here we commit to all private values, including the storage slot.\n        poseidon2_hash_with_separator(\n            array_concat(self.pack(), [storage_slot]),\n            GENERATOR_INDEX__NOTE_HASH,\n        )\n    }\n}\n\n#[derive(Packable)]\nstruct PrivateUintPartialNotePrivateLogContent {\n    // The ordering of these fields is important given that it must:\n    //   a) match that of UintNote, and\n    //   b) have the public log tag at the beginning\n    // Correct ordering is checked by the tests in this module.\n    public_log_tag: Field,\n    owner: AztecAddress,\n    randomness: Field,\n}\n\nimpl NoteType for PrivateUintPartialNotePrivateLogContent {\n    fn get_id() -> Field {\n        UintNote::get_id()\n    }\n}\n\n/// A partial instance of a UintNote. This value represents a private commitment to the owner, randomness and storage\n/// slot, but the value field has not yet been set. A partial note can be completed in public with the `complete`\n/// function (revealing the value to the public), resulting in a UintNote that can be used like any other one (except\n/// of course that its value is known).\n#[derive(Packable, Serialize, Deserialize)]\npub struct PartialUintNote {\n    commitment: Field,\n}\n\nimpl PartialUintNote {\n    pub fn commitment(self) -> Field {\n        self.commitment\n    }\n}\n\nimpl PartialUintNote {\n    /// Completes the partial note, creating a new note that can be used like any other UintNote.\n    pub fn complete(self, value: u128, context: &mut PublicContext) {\n        // A note with a value of zero is valid, but we cannot currently complete a partial note with such a value\n        // because this will result in the completion log having its last field set to 0. Public logs currently do not\n        // track their length, and so trailing zeros are simply trimmed. This results in the completion log missing its\n        // last field (the value), and note discovery failing.\n        // TODO(#11636): remove this\n        assert(value != 0, \"Cannot complete a PartialUintNote with a value of 0\");\n\n        // We need to do two things:\n        //  - emit a public log containing the public fields (the value). The contract will later find it by searching\n        //  for the expected tag (which is simply the partial note commitment).\n        //  - insert the completion note hash (i.e. the hash of the note) into the note hash tree. This is typically\n        //  only done in private to hide the preimage of the hash that is inserted, but completed partial notes are\n        //  inserted in public as the public values are provided and the note hash computed.\n        context.emit_public_log(self.compute_note_completion_log(value));\n        context.push_note_hash(self.compute_complete_note_hash(value));\n    }\n\n    fn compute_note_completion_log(self, value: u128) -> [Field; 2] {\n        // The first field of this log must be the tag that the recipient of the partial note private field logs\n        // expects, which is equal to the partial note commitment.\n        [self.commitment, value.to_field()]\n    }\n\n    fn compute_complete_note_hash(self, value: u128) -> Field {\n        // Here we finalize the note hash by including the (public) value into the partial note commitment. Note that we\n        // use the same generator index as we used for the first round of poseidon - this is not an issue.\n        poseidon2_hash_with_separator(\n            [self.commitment, value.to_field()],\n            GENERATOR_INDEX__NOTE_HASH,\n        )\n    }\n}\n\nmod test {\n    use super::{\n        PartialUintNote, PrivateUintPartialNotePrivateLogContent, UintNote,\n        UintPartialNotePrivateContent,\n    };\n    use dep::aztec::{\n        note::note_interface::NoteHash,\n        protocol_types::{\n            address::AztecAddress,\n            traits::{FromField, Packable},\n            utils::arrays::array_concat,\n        },\n        utils::array::subarray,\n    };\n\n    global value: u128 = 17;\n    global randomness: Field = 42;\n    global owner: AztecAddress = AztecAddress::from_field(50);\n    global storage_slot: Field = 13;\n\n    #[test]\n    fn note_hash_matches_completed_partial_note_hash() {\n        // Tests that a UintNote has the same note hash as a PartialUintNote created and then completed with the same\n        // private values. This requires for the same hash function to be used in both flows, with the fields in the\n        // same order.\n\n        let note = UintNote { value, randomness, owner };\n        let note_hash = note.compute_note_hash(storage_slot);\n\n        let partial_note_private_content = UintPartialNotePrivateContent { owner, randomness };\n\n        let partial_note = PartialUintNote {\n            commitment: partial_note_private_content.compute_partial_commitment(storage_slot),\n        };\n        let completed_partial_note_hash = partial_note.compute_complete_note_hash(value);\n\n        assert_eq(note_hash, completed_partial_note_hash);\n    }\n\n    #[test]\n    fn unpack_from_partial_note_encoding() {\n        // Tests that the packed representation of a regular UintNote can be reconstructed given the partial note\n        // private fields log and the public completion log, ensuring the recipient will be able to compute the\n        // completed note as if it were a regular UintNote.\n\n        let note = UintNote { value, randomness, owner };\n\n        let partial_note_private_content = UintPartialNotePrivateContent { owner, randomness };\n        let commitment = partial_note_private_content.compute_partial_commitment(storage_slot);\n\n        let private_log_content = PrivateUintPartialNotePrivateLogContent {\n            owner,\n            randomness,\n            public_log_tag: commitment,\n        };\n        let partial_note = PartialUintNote { commitment };\n\n        // The first field of the partial note private content is the public completion log tag, so it should match the\n        // first field of the public log.\n        assert_eq(\n            private_log_content.pack()[0],\n            partial_note.compute_note_completion_log(value)[0],\n        );\n\n        // Then we extract all fields except the first of both logs (i.e. the public log tag), and combine them to\n        // produce the note's packed representation. This requires that the members of the intermediate structs are in\n        // the same order as in UintNote.\n        let private_log_without_public_tag: [_; 2] = subarray(private_log_content.pack(), 1);\n        let public_log_without_tag: [_; 1] =\n            subarray(partial_note.compute_note_completion_log(value), 1);\n\n        assert_eq(\n            array_concat(private_log_without_public_tag, public_log_without_tag),\n            note.pack(),\n        );\n    }\n}\n"
    },
    "42": {
      "path": "std/option.nr",
      "source": "use crate::cmp::{Eq, Ord, Ordering};\nuse crate::default::Default;\nuse crate::hash::{Hash, Hasher};\n\npub struct Option<T> {\n    _is_some: bool,\n    _value: T,\n}\n\nimpl<T> Option<T> {\n    /// Constructs a None value\n    pub fn none() -> Self {\n        Self { _is_some: false, _value: crate::mem::zeroed() }\n    }\n\n    /// Constructs a Some wrapper around the given value\n    pub fn some(_value: T) -> Self {\n        Self { _is_some: true, _value }\n    }\n\n    /// True if this Option is None\n    pub fn is_none(self) -> bool {\n        !self._is_some\n    }\n\n    /// True if this Option is Some\n    pub fn is_some(self) -> bool {\n        self._is_some\n    }\n\n    /// Asserts `self.is_some()` and returns the wrapped value.\n    pub fn unwrap(self) -> T {\n        assert(self._is_some);\n        self._value\n    }\n\n    /// Returns the inner value without asserting `self.is_some()`\n    /// Note that if `self` is `None`, there is no guarantee what value will be returned,\n    /// only that it will be of type `T`.\n    pub fn unwrap_unchecked(self) -> T {\n        self._value\n    }\n\n    /// Returns the wrapped value if `self.is_some()`. Otherwise, returns the given default value.\n    pub fn unwrap_or(self, default: T) -> T {\n        if self._is_some {\n            self._value\n        } else {\n            default\n        }\n    }\n\n    /// Returns the wrapped value if `self.is_some()`. Otherwise, calls the given function to return\n    /// a default value.\n    pub fn unwrap_or_else<Env>(self, default: fn[Env]() -> T) -> T {\n        if self._is_some {\n            self._value\n        } else {\n            default()\n        }\n    }\n\n    /// Asserts `self.is_some()` with a provided custom message and returns the contained `Some` value\n    pub fn expect<let N: u32, MessageTypes>(self, message: fmtstr<N, MessageTypes>) -> T {\n        assert(self.is_some(), message);\n        self._value\n    }\n\n    /// If self is `Some(x)`, this returns `Some(f(x))`. Otherwise, this returns `None`.\n    pub fn map<U, Env>(self, f: fn[Env](T) -> U) -> Option<U> {\n        if self._is_some {\n            Option::some(f(self._value))\n        } else {\n            Option::none()\n        }\n    }\n\n    /// If self is `Some(x)`, this returns `f(x)`. Otherwise, this returns the given default value.\n    pub fn map_or<U, Env>(self, default: U, f: fn[Env](T) -> U) -> U {\n        if self._is_some {\n            f(self._value)\n        } else {\n            default\n        }\n    }\n\n    /// If self is `Some(x)`, this returns `f(x)`. Otherwise, this returns `default()`.\n    pub fn map_or_else<U, Env1, Env2>(self, default: fn[Env1]() -> U, f: fn[Env2](T) -> U) -> U {\n        if self._is_some {\n            f(self._value)\n        } else {\n            default()\n        }\n    }\n\n    /// Returns None if self is None. Otherwise, this returns `other`.\n    pub fn and(self, other: Self) -> Self {\n        if self.is_none() {\n            Option::none()\n        } else {\n            other\n        }\n    }\n\n    /// If self is None, this returns None. Otherwise, this calls the given function\n    /// with the Some value contained within self, and returns the result of that call.\n    ///\n    /// In some languages this function is called `flat_map` or `bind`.\n    pub fn and_then<U, Env>(self, f: fn[Env](T) -> Option<U>) -> Option<U> {\n        if self._is_some {\n            f(self._value)\n        } else {\n            Option::none()\n        }\n    }\n\n    /// If self is Some, return self. Otherwise, return `other`.\n    pub fn or(self, other: Self) -> Self {\n        if self._is_some {\n            self\n        } else {\n            other\n        }\n    }\n\n    /// If self is Some, return self. Otherwise, return `default()`.\n    pub fn or_else<Env>(self, default: fn[Env]() -> Self) -> Self {\n        if self._is_some {\n            self\n        } else {\n            default()\n        }\n    }\n\n    // If only one of the two Options is Some, return that option.\n    // Otherwise, if both options are Some or both are None, None is returned.\n    pub fn xor(self, other: Self) -> Self {\n        if self._is_some {\n            if other._is_some {\n                Option::none()\n            } else {\n                self\n            }\n        } else if other._is_some {\n            other\n        } else {\n            Option::none()\n        }\n    }\n\n    /// Returns `Some(x)` if self is `Some(x)` and `predicate(x)` is true.\n    /// Otherwise, this returns `None`\n    pub fn filter<Env>(self, predicate: fn[Env](T) -> bool) -> Self {\n        if self._is_some {\n            if predicate(self._value) {\n                self\n            } else {\n                Option::none()\n            }\n        } else {\n            Option::none()\n        }\n    }\n\n    /// Flattens an Option<Option<T>> into a Option<T>.\n    /// This returns None if the outer Option is None. Otherwise, this returns the inner Option.\n    pub fn flatten(option: Option<Option<T>>) -> Option<T> {\n        if option._is_some {\n            option._value\n        } else {\n            Option::none()\n        }\n    }\n}\n\nimpl<T> Default for Option<T> {\n    fn default() -> Self {\n        Option::none()\n    }\n}\n\nimpl<T> Eq for Option<T>\nwhere\n    T: Eq,\n{\n    fn eq(self, other: Self) -> bool {\n        if self._is_some == other._is_some {\n            if self._is_some {\n                self._value == other._value\n            } else {\n                true\n            }\n        } else {\n            false\n        }\n    }\n}\n\nimpl<T> Hash for Option<T>\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self._is_some.hash(state);\n        if self._is_some {\n            self._value.hash(state);\n        }\n    }\n}\n\n// For this impl we're declaring Option::none < Option::some\nimpl<T> Ord for Option<T>\nwhere\n    T: Ord,\n{\n    fn cmp(self, other: Self) -> Ordering {\n        if self._is_some {\n            if other._is_some {\n                self._value.cmp(other._value)\n            } else {\n                Ordering::greater()\n            }\n        } else if other._is_some {\n            Ordering::less()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n"
    },
    "43": {
      "path": "std/panic.nr",
      "source": "pub fn panic<T, U, let N: u32>(message: fmtstr<N, T>) -> U {\n    assert(false, message);\n    crate::mem::zeroed()\n}\n"
    },
    "51": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/capsules/mod.nr",
      "source": "use crate::oracle::capsules;\nuse protocol_types::{address::AztecAddress, traits::{Deserialize, Serialize}};\n\n/// A dynamically sized array backed by PXE's non-volatile database (called capsules). Values are persisted until\n/// deleted, so they can be e.g. stored during simulation of a transaction and later retrieved during witness\n/// generation. All values are scoped per contract address, so external contracts cannot access them.\npub struct CapsuleArray<T> {\n    contract_address: AztecAddress,\n    /// The base slot is where the array length is stored in capsules. Array elements are stored in consecutive slots\n    /// after the base slot. For example, with base slot 5: the length is at slot 5, the first element (index 0) is at\n    /// slot 6, the second element (index 1) is at slot 7, and so on.\n    base_slot: Field,\n}\n\nimpl<T> CapsuleArray<T> {\n    /// Returns a CapsuleArray connected to a contract's capsules at a base slot. Array elements are stored in\n    /// contiguous slots following the base slot, so there should be sufficient space between array base slots to\n    /// accommodate elements. A reasonable strategy is to make the base slot a hash of a unique value.\n    pub unconstrained fn at(contract_address: AztecAddress, base_slot: Field) -> Self {\n        Self { contract_address, base_slot }\n    }\n\n    /// Returns the number of elements stored in the array.\n    pub unconstrained fn len(self) -> u32 {\n        // An uninitialized array defaults to a length of 0.\n        capsules::load(self.contract_address, self.base_slot).unwrap_or(0) as u32\n    }\n\n    /// Stores a value at the end of the array.\n    pub unconstrained fn push<let N: u32>(self, value: T)\n    where\n        T: Serialize<N>,\n    {\n        let current_length = self.len();\n\n        // The slot corresponding to the index `current_length` is the first slot immediately after the end of the\n        // array, which is where we want to place the new value.\n        capsules::store(self.contract_address, self.slot_at(current_length), value);\n\n        // Then we simply update the length.\n        let new_length = current_length + 1;\n        capsules::store(self.contract_address, self.base_slot, new_length);\n    }\n\n    /// Retrieves the value stored in the array at `index`. Throws if the index is out of bounds.\n    pub unconstrained fn get<let N: u32>(self, index: u32) -> T\n    where\n        T: Deserialize<N>,\n    {\n        assert(index < self.len(), \"Attempted to read past the length of a CapsuleArray\");\n\n        capsules::load(self.contract_address, self.slot_at(index)).unwrap()\n    }\n\n    /// Deletes the value stored in the array at `index`. Throws if the index is out of bounds.\n    pub unconstrained fn remove(self, index: u32) {\n        let current_length = self.len();\n        assert(index < current_length, \"Attempted to delete past the length of a CapsuleArray\");\n\n        // In order to be able to remove elements at arbitrary indices, we need to shift the entire contents of the\n        // array past the removed element one slot backward so that we don't end up with a gap and preserve the\n        // contiguous slots. We can skip this when deleting the last element however.\n        if index != current_length - 1 {\n            // The source and destination regions overlap, but `copy` supports this.\n            capsules::copy(\n                self.contract_address,\n                self.slot_at(index + 1),\n                self.slot_at(index),\n                current_length - index - 1,\n            );\n        }\n\n        // We can now delete the last element (which has either been copied to the slot immediately before it, or was\n        // the element we meant to delete in the first place) and update the length.\n        capsules::delete(self.contract_address, self.slot_at(current_length - 1));\n        capsules::store(self.contract_address, self.base_slot, current_length - 1);\n    }\n\n    /// Iterates over the entire array, calling the callback with all values and their array index. The order in which\n    /// values are processed is arbitrary.\n    ///\n    /// It is safe to delete the current element (and only the current element) from inside the callback via `remove`:\n    /// ```noir\n    /// array.for_each(|index, value| {\n    ///   if some_condition(value) {\n    ///     array.remove(index); // safe only for this index\n    ///   }\n    /// }\n    /// ```\n    ///\n    /// If all elements in the array need to iterated over and then removed, then using `for_each` results in optimal\n    /// efficiency.\n    ///\n    /// It is **not** safe to push new elements into the array from inside the callback.\n    pub unconstrained fn for_each<Env, let N: u32>(self, f: unconstrained fn[Env](u32, T) -> ())\n    where\n        T: Deserialize<N>,\n    {\n        // Iterating over all elements is simple, but we want to do it in such a way that a) deleting the current\n        // element is safe to do, and b) deleting *all* elements is optimally efficient. This is because CapsuleArrays\n        // are typically used to hold pending tasks, so iterating them while clearing completed tasks (sometimes\n        // unconditionally, resulting in a full clear) is a very common access pattern.\n        //\n        // The way we achieve this is by iterating backwards: each element can always be deleted since it won't change\n        // any preceding (lower) indices, and if every element is deleted then every element will (in turn) be the last\n        // element. This results in an optimal full clear since `remove` will be able to skip the `capsules::copy` call\n        // to shift any elements past the deleted one (because there will be none).\n        let mut i = self.len();\n        while i > 0 {\n            i -= 1;\n            f(i, self.get(i));\n        }\n    }\n\n    unconstrained fn slot_at(self, index: u32) -> Field {\n        // Elements are stored immediately after the base slot, so we add 1 to it to compute the slot for the first\n        // element.\n        self.base_slot + 1 + index as Field\n    }\n}\n\nmod test {\n    use crate::test::helpers::test_environment::TestEnvironment;\n    use super::CapsuleArray;\n    use protocol_types::address::AztecAddress;\n\n    global SLOT: Field = 1230;\n\n    unconstrained fn setup() -> AztecAddress {\n        TestEnvironment::new().utility().this_address()\n    }\n\n    #[test]\n    unconstrained fn empty_array() {\n        let contract_address = setup();\n\n        let array: CapsuleArray<Field> = CapsuleArray::at(contract_address, SLOT);\n        assert_eq(array.len(), 0);\n    }\n\n    #[test(should_fail_with = \"Attempted to read past the length of a CapsuleArray\")]\n    unconstrained fn empty_array_read() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n        let _: Field = array.get(0);\n    }\n\n    #[test]\n    unconstrained fn array_push() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n        array.push(5);\n\n        assert_eq(array.len(), 1);\n        assert_eq(array.get(0), 5);\n    }\n\n    #[test(should_fail_with = \"Attempted to read past the length of a CapsuleArray\")]\n    unconstrained fn read_past_len() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n        array.push(5);\n\n        let _ = array.get(1);\n    }\n\n    #[test]\n    unconstrained fn array_remove_last() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(5);\n        array.remove(0);\n\n        assert_eq(array.len(), 0);\n    }\n\n    #[test]\n    unconstrained fn array_remove_some() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(7);\n        array.push(8);\n        array.push(9);\n\n        assert_eq(array.len(), 3);\n        assert_eq(array.get(0), 7);\n        assert_eq(array.get(1), 8);\n        assert_eq(array.get(2), 9);\n\n        array.remove(1);\n\n        assert_eq(array.len(), 2);\n        assert_eq(array.get(0), 7);\n        assert_eq(array.get(1), 9);\n    }\n\n    #[test]\n    unconstrained fn array_remove_all() {\n        let contract_address = setup();\n\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(7);\n        array.push(8);\n        array.push(9);\n\n        array.remove(1);\n        array.remove(1);\n        array.remove(0);\n\n        assert_eq(array.len(), 0);\n    }\n\n    #[test]\n    unconstrained fn for_each_called_with_all_elements() {\n        let contract_address = setup();\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(4);\n        array.push(5);\n        array.push(6);\n\n        // We store all values that we were called with and check that all (value, index) tuples are present. Note that\n        // we do not care about the order in which each tuple was passed to the closure.\n        let called_with = &mut BoundedVec::<(u32, Field), 3>::new();\n        array.for_each(|index, value| { called_with.push((index, value)); });\n\n        assert_eq(called_with.len(), 3);\n        assert(called_with.any(|(index, value)| (index == 0) & (value == 4)));\n        assert(called_with.any(|(index, value)| (index == 1) & (value == 5)));\n        assert(called_with.any(|(index, value)| (index == 2) & (value == 6)));\n    }\n\n    #[test]\n    unconstrained fn for_each_remove_some() {\n        let contract_address = setup();\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(4);\n        array.push(5);\n        array.push(6);\n\n        array.for_each(|index, _| {\n            if index == 1 {\n                array.remove(index);\n            }\n        });\n\n        assert_eq(array.len(), 2);\n        assert_eq(array.get(0), 4);\n        assert_eq(array.get(1), 6);\n    }\n\n    #[test]\n    unconstrained fn for_each_remove_all() {\n        let contract_address = setup();\n        let array = CapsuleArray::at(contract_address, SLOT);\n\n        array.push(4);\n        array.push(5);\n        array.push(6);\n\n        array.for_each(|index, _| { array.remove(index); });\n\n        assert_eq(array.len(), 0);\n    }\n\n    // TODO: uncomment this test once OracleMock::count is implemented in the stdlib.\n    // #[test]\n    // unconstrained fn for_each_remove_all_no_copy() {\n    //     let contract_address = setup();\n    //     let array = CapsuleArray::at(contract_address, SLOT);\n\n    //     array.push(4);\n    //     array.push(5);\n    //     array.push(6);\n\n    //     // We test that the copyCapsule was never called, which is the expensive operation we want to avoid.\n    //     let mock = OracleMock::mock(\"copyCapsule\");\n\n    //     array.for_each(|index, _| {\n    //         array.remove(index);\n    //     });\n\n    //     assert_eq(mock.count(), 0);\n    // }\n}\n"
    },
    "6": {
      "path": "std/collections/bounded_vec.nr",
      "source": "use crate::{cmp::Eq, convert::From, runtime::is_unconstrained, static_assert};\n\n/// A `BoundedVec<T, MaxLen>` is a growable storage similar to a `Vec<T>` except that it\n/// is bounded with a maximum possible length. Unlike `Vec`, `BoundedVec` is not implemented\n/// via slices and thus is not subject to the same restrictions slices are (notably, nested\n/// slices - and thus nested vectors as well - are disallowed).\n///\n/// Since a BoundedVec is backed by a normal array under the hood, growing the BoundedVec by\n/// pushing an additional element is also more efficient - the length only needs to be increased\n/// by one.\n///\n/// For these reasons `BoundedVec<T, N>` should generally be preferred over `Vec<T>` when there\n/// is a reasonable maximum bound that can be placed on the vector.\n///\n/// Example:\n///\n/// ```noir\n/// let mut vector: BoundedVec<Field, 10> = BoundedVec::new();\n/// for i in 0..5 {\n///     vector.push(i);\n/// }\n/// assert(vector.len() == 5);\n/// assert(vector.max_len() == 10);\n/// ```\npub struct BoundedVec<T, let MaxLen: u32> {\n    storage: [T; MaxLen],\n    len: u32,\n}\n\nimpl<T, let MaxLen: u32> BoundedVec<T, MaxLen> {\n    /// Creates a new, empty vector of length zero.\n    ///\n    /// Since this container is backed by an array internally, it still needs an initial value\n    /// to give each element. To resolve this, each element is zeroed internally. This value\n    /// is guaranteed to be inaccessible unless `get_unchecked` is used.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let empty_vector: BoundedVec<Field, 10> = BoundedVec::new();\n    /// assert(empty_vector.len() == 0);\n    /// ```\n    ///\n    /// Note that whenever calling `new` the maximum length of the vector should always be specified\n    /// via a type signature:\n    ///\n    /// ```noir\n    /// fn good() -> BoundedVec<Field, 10> {\n    ///     // Ok! MaxLen is specified with a type annotation\n    ///     let v1: BoundedVec<Field, 3> = BoundedVec::new();\n    ///     let v2 = BoundedVec::new();\n    ///\n    ///     // Ok! MaxLen is known from the type of `good`'s return value\n    ///     v2\n    /// }\n    ///\n    /// fn bad() {\n    ///     // Error: Type annotation needed\n    ///     // The compiler can't infer `MaxLen` from the following code:\n    ///     let mut v3 = BoundedVec::new();\n    ///     v3.push(5);\n    /// }\n    /// ```\n    ///\n    /// This defaulting of `MaxLen` (and numeric generics in general) to zero may change in future noir versions\n    /// but for now make sure to use type annotations when using bounded vectors. Otherwise, you will receive a\n    /// constraint failure at runtime when the vec is pushed to.\n    pub fn new() -> Self {\n        let zeroed = crate::mem::zeroed();\n        BoundedVec { storage: [zeroed; MaxLen], len: 0 }\n    }\n\n    /// Retrieves an element from the vector at the given index, starting from zero.\n    ///\n    /// If the given index is equal to or greater than the length of the vector, this\n    /// will issue a constraint failure.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn foo<let N: u32>(v: BoundedVec<u32, N>) {\n    ///     let first = v.get(0);\n    ///     let last = v.get(v.len() - 1);\n    ///     assert(first != last);\n    /// }\n    /// ```\n    pub fn get(self, index: u32) -> T {\n        assert(index < self.len, \"Attempted to read past end of BoundedVec\");\n        self.get_unchecked(index)\n    }\n\n    /// Retrieves an element from the vector at the given index, starting from zero, without\n    /// performing a bounds check.\n    ///\n    /// Since this function does not perform a bounds check on length before accessing the element,\n    /// it is unsafe! Use at your own risk!\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn sum_of_first_three<let N: u32>(v: BoundedVec<u32, N>) -> u32 {\n    ///     // Always ensure the length is larger than the largest\n    ///     // index passed to get_unchecked\n    ///     assert(v.len() > 2);\n    ///     let first = v.get_unchecked(0);\n    ///     let second = v.get_unchecked(1);\n    ///     let third = v.get_unchecked(2);\n    ///     first + second + third\n    /// }\n    /// ```\n    pub fn get_unchecked(self, index: u32) -> T {\n        self.storage[index]\n    }\n\n    /// Writes an element to the vector at the given index, starting from zero.\n    ///\n    /// If the given index is equal to or greater than the length of the vector, this will issue a constraint failure.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn foo<let N: u32>(v: BoundedVec<u32, N>) {\n    ///     let first = v.get(0);\n    ///     assert(first != 42);\n    ///     v.set(0, 42);\n    ///     let new_first = v.get(0);\n    ///     assert(new_first == 42);\n    /// }\n    /// ```\n    pub fn set(&mut self, index: u32, value: T) {\n        assert(index < self.len, \"Attempted to write past end of BoundedVec\");\n        self.set_unchecked(index, value)\n    }\n\n    /// Writes an element to the vector at the given index, starting from zero, without performing a bounds check.\n    ///\n    /// Since this function does not perform a bounds check on length before accessing the element, it is unsafe! Use at your own risk!\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// fn set_unchecked_example() {\n    ///     let mut vec: BoundedVec<u32, 5> = BoundedVec::new();\n    ///     vec.extend_from_array([1, 2]);\n    ///\n    ///     // Here we're safely writing within the valid range of `vec`\n    ///     // `vec` now has the value [42, 2]\n    ///     vec.set_unchecked(0, 42);\n    ///\n    ///     // We can then safely read this value back out of `vec`.\n    ///     // Notice that we use the checked version of `get` which would prevent reading unsafe values.\n    ///     assert_eq(vec.get(0), 42);\n    ///\n    ///     // We've now written past the end of `vec`.\n    ///     // As this index is still within the maximum potential length of `v`,\n    ///     // it won't cause a constraint failure.\n    ///     vec.set_unchecked(2, 42);\n    ///     println(vec);\n    ///\n    ///     // This will write past the end of the maximum potential length of `vec`,\n    ///     // it will then trigger a constraint failure.\n    ///     vec.set_unchecked(5, 42);\n    ///     println(vec);\n    /// }\n    /// ```\n    pub fn set_unchecked(&mut self, index: u32, value: T) {\n        self.storage[index] = value;\n    }\n\n    /// Pushes an element to the end of the vector. This increases the length\n    /// of the vector by one.\n    ///\n    /// Panics if the new length of the vector will be greater than the max length.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<Field, 2> = BoundedVec::new();\n    ///\n    /// v.push(1);\n    /// v.push(2);\n    ///\n    /// // Panics with failed assertion \"push out of bounds\"\n    /// v.push(3);\n    /// ```\n    pub fn push(&mut self, elem: T) {\n        assert(self.len < MaxLen, \"push out of bounds\");\n\n        self.storage[self.len] = elem;\n        self.len += 1;\n    }\n\n    /// Returns the current length of this vector\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<Field, 4> = BoundedVec::new();\n    /// assert(v.len() == 0);\n    ///\n    /// v.push(100);\n    /// assert(v.len() == 1);\n    ///\n    /// v.push(200);\n    /// v.push(300);\n    /// v.push(400);\n    /// assert(v.len() == 4);\n    ///\n    /// let _ = v.pop();\n    /// let _ = v.pop();\n    /// assert(v.len() == 2);\n    /// ```\n    pub fn len(self) -> u32 {\n        self.len\n    }\n\n    /// Returns the maximum length of this vector. This is always\n    /// equal to the `MaxLen` parameter this vector was initialized with.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<Field, 5> = BoundedVec::new();\n    ///\n    /// assert(v.max_len() == 5);\n    /// v.push(10);\n    /// assert(v.max_len() == 5);\n    /// ```\n    pub fn max_len(_self: BoundedVec<T, MaxLen>) -> u32 {\n        MaxLen\n    }\n\n    /// Returns the internal array within this vector.\n    ///\n    /// Since arrays in Noir are immutable, mutating the returned storage array will not mutate\n    /// the storage held internally by this vector.\n    ///\n    /// Note that uninitialized elements may be zeroed out!\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<Field, 5> = BoundedVec::new();\n    ///\n    /// assert(v.storage() == [0, 0, 0, 0, 0]);\n    ///\n    /// v.push(57);\n    /// assert(v.storage() == [57, 0, 0, 0, 0]);\n    /// ```\n    pub fn storage(self) -> [T; MaxLen] {\n        self.storage\n    }\n\n    /// Pushes each element from the given array to this vector.\n    ///\n    /// Panics if pushing each element would cause the length of this vector\n    /// to exceed the maximum length.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut vec: BoundedVec<Field, 3> = BoundedVec::new();\n    /// vec.extend_from_array([2, 4]);\n    ///\n    /// assert(vec.len == 2);\n    /// assert(vec.get(0) == 2);\n    /// assert(vec.get(1) == 4);\n    /// ```\n    pub fn extend_from_array<let Len: u32>(&mut self, array: [T; Len]) {\n        let new_len = self.len + array.len();\n        assert(new_len <= MaxLen, \"extend_from_array out of bounds\");\n        for i in 0..array.len() {\n            self.storage[self.len + i] = array[i];\n        }\n        self.len = new_len;\n    }\n\n    /// Pushes each element from the given slice to this vector.\n    ///\n    /// Panics if pushing each element would cause the length of this vector\n    /// to exceed the maximum length.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut vec: BoundedVec<Field, 3> = BoundedVec::new();\n    /// vec.extend_from_slice(&[2, 4]);\n    ///\n    /// assert(vec.len == 2);\n    /// assert(vec.get(0) == 2);\n    /// assert(vec.get(1) == 4);\n    /// ```\n    pub fn extend_from_slice(&mut self, slice: [T]) {\n        let new_len = self.len + slice.len();\n        assert(new_len <= MaxLen, \"extend_from_slice out of bounds\");\n        for i in 0..slice.len() {\n            self.storage[self.len + i] = slice[i];\n        }\n        self.len = new_len;\n    }\n\n    /// Pushes each element from the other vector to this vector. The length of\n    /// the other vector is left unchanged.\n    ///\n    /// Panics if pushing each element would cause the length of this vector\n    /// to exceed the maximum length.\n    ///\n    /// ```noir\n    /// let mut v1: BoundedVec<Field, 5> = BoundedVec::new();\n    /// let mut v2: BoundedVec<Field, 7> = BoundedVec::new();\n    ///\n    /// v2.extend_from_array([1, 2, 3]);\n    /// v1.extend_from_bounded_vec(v2);\n    ///\n    /// assert(v1.storage() == [1, 2, 3, 0, 0]);\n    /// assert(v2.storage() == [1, 2, 3, 0, 0, 0, 0]);\n    /// ```\n    pub fn extend_from_bounded_vec<let Len: u32>(&mut self, vec: BoundedVec<T, Len>) {\n        let append_len = vec.len();\n        let new_len = self.len + append_len;\n        assert(new_len <= MaxLen, \"extend_from_bounded_vec out of bounds\");\n\n        if is_unconstrained() {\n            for i in 0..append_len {\n                self.storage[self.len + i] = vec.get_unchecked(i);\n            }\n        } else {\n            let mut exceeded_len = false;\n            for i in 0..Len {\n                exceeded_len |= i == append_len;\n                if !exceeded_len {\n                    self.storage[self.len + i] = vec.get_unchecked(i);\n                }\n            }\n        }\n        self.len = new_len;\n    }\n\n    /// Creates a new vector, populating it with values derived from an array input.\n    /// The maximum length of the vector is determined based on the type signature.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let bounded_vec: BoundedVec<Field, 10> = BoundedVec::from_array([1, 2, 3])\n    /// ```\n    pub fn from_array<let Len: u32>(array: [T; Len]) -> Self {\n        static_assert(Len <= MaxLen, \"from array out of bounds\");\n        let mut vec: BoundedVec<T, MaxLen> = BoundedVec::new();\n        vec.extend_from_array(array);\n        vec\n    }\n\n    /// Pops the element at the end of the vector. This will decrease the length\n    /// of the vector by one.\n    ///\n    /// Panics if the vector is empty.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<Field, 2> = BoundedVec::new();\n    /// v.push(1);\n    /// v.push(2);\n    ///\n    /// let two = v.pop();\n    /// let one = v.pop();\n    ///\n    /// assert(two == 2);\n    /// assert(one == 1);\n    ///\n    /// // error: cannot pop from an empty vector\n    /// let _ = v.pop();\n    /// ```\n    pub fn pop(&mut self) -> T {\n        assert(self.len > 0);\n        self.len -= 1;\n\n        let elem = self.storage[self.len];\n        self.storage[self.len] = crate::mem::zeroed();\n        elem\n    }\n\n    /// Returns true if the given predicate returns true for any element\n    /// in this vector.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let mut v: BoundedVec<u32, 3> = BoundedVec::new();\n    /// v.extend_from_array([2, 4, 6]);\n    ///\n    /// let all_even = !v.any(|elem: u32| elem % 2 != 0);\n    /// assert(all_even);\n    /// ```\n    pub fn any<Env>(self, predicate: fn[Env](T) -> bool) -> bool {\n        let mut ret = false;\n        if is_unconstrained() {\n            for i in 0..self.len {\n                ret |= predicate(self.storage[i]);\n            }\n        } else {\n            let mut ret = false;\n            let mut exceeded_len = false;\n            for i in 0..MaxLen {\n                exceeded_len |= i == self.len;\n                if !exceeded_len {\n                    ret |= predicate(self.storage[i]);\n                }\n            }\n        }\n        ret\n    }\n\n    /// Creates a new vector of equal size by calling a closure on each element in this vector.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n    /// let result = vec.map(|value| value * 2);\n    ///\n    /// let expected = BoundedVec::from_array([2, 4, 6, 8]);\n    /// assert_eq(result, expected);\n    /// ```\n    pub fn map<U, Env>(self, f: fn[Env](T) -> U) -> BoundedVec<U, MaxLen> {\n        let mut ret = BoundedVec::new();\n        ret.len = self.len();\n\n        if is_unconstrained() {\n            for i in 0..self.len() {\n                ret.storage[i] = f(self.get_unchecked(i));\n            }\n        } else {\n            for i in 0..MaxLen {\n                if i < self.len() {\n                    ret.storage[i] = f(self.get_unchecked(i));\n                }\n            }\n        }\n\n        ret\n    }\n\n    /// Creates a new vector of equal size by calling a closure on each element\n    /// in this vector, along with its index.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n    /// let result = vec.mapi(|i, value| i + value * 2);\n    ///\n    /// let expected = BoundedVec::from_array([2, 5, 8, 11]);\n    /// assert_eq(result, expected);\n    /// ```\n    pub fn mapi<U, Env>(self, f: fn[Env](u32, T) -> U) -> BoundedVec<U, MaxLen> {\n        let mut ret = BoundedVec::new();\n        ret.len = self.len();\n\n        if is_unconstrained() {\n            for i in 0..self.len() {\n                ret.storage[i] = f(i, self.get_unchecked(i));\n            }\n        } else {\n            for i in 0..MaxLen {\n                if i < self.len() {\n                    ret.storage[i] = f(i, self.get_unchecked(i));\n                }\n            }\n        }\n\n        ret\n    }\n\n    /// Calls a closure on each element in this vector.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n    /// let mut result = BoundedVec::<u32, 4>::new();\n    /// vec.for_each(|value| result.push(value * 2));\n    ///\n    /// let expected = BoundedVec::from_array([2, 4, 6, 8]);\n    /// assert_eq(result, expected);\n    /// ```\n    pub fn for_each<Env>(self, f: fn[Env](T) -> ()) {\n        if is_unconstrained() {\n            for i in 0..self.len() {\n                f(self.get_unchecked(i));\n            }\n        } else {\n            for i in 0..MaxLen {\n                if i < self.len() {\n                    f(self.get_unchecked(i));\n                }\n            }\n        }\n    }\n\n    /// Calls a closure on each element in this vector, along with its index.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n    /// let mut result = BoundedVec::<u32, 4>::new();\n    /// vec.for_eachi(|i, value| result.push(i + value * 2));\n    ///\n    /// let expected = BoundedVec::from_array([2, 5, 8, 11]);\n    /// assert_eq(result, expected);\n    /// ```\n    pub fn for_eachi<Env>(self, f: fn[Env](u32, T) -> ()) {\n        if is_unconstrained() {\n            for i in 0..self.len() {\n                f(i, self.get_unchecked(i));\n            }\n        } else {\n            for i in 0..MaxLen {\n                if i < self.len() {\n                    f(i, self.get_unchecked(i));\n                }\n            }\n        }\n    }\n\n    /// Creates a new BoundedVec from the given array and length.\n    /// The given length must be less than or equal to the length of the array.\n    ///\n    /// This function will zero out any elements at or past index `len` of `array`.\n    /// This incurs an extra runtime cost of O(MaxLen). If you are sure your array is\n    /// zeroed after that index, you can use `from_parts_unchecked` to remove the extra loop.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_parts([1, 2, 3, 0], 3);\n    /// assert_eq(vec.len(), 3);\n    /// ```\n    pub fn from_parts(mut array: [T; MaxLen], len: u32) -> Self {\n        assert(len <= MaxLen);\n        let zeroed = crate::mem::zeroed();\n\n        if is_unconstrained() {\n            for i in len..MaxLen {\n                array[i] = zeroed;\n            }\n        } else {\n            for i in 0..MaxLen {\n                if i >= len {\n                    array[i] = zeroed;\n                }\n            }\n        }\n\n        BoundedVec { storage: array, len }\n    }\n\n    /// Creates a new BoundedVec from the given array and length.\n    /// The given length must be less than or equal to the length of the array.\n    ///\n    /// This function is unsafe because it expects all elements past the `len` index\n    /// of `array` to be zeroed, but does not check for this internally. Use `from_parts`\n    /// for a safe version of this function which does zero out any indices past the\n    /// given length. Invalidating this assumption can notably cause `BoundedVec::eq`\n    /// to give incorrect results since it will check even elements past `len`.\n    ///\n    /// Example:\n    ///\n    /// ```noir\n    /// let vec: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 0], 3);\n    /// assert_eq(vec.len(), 3);\n    ///\n    /// // invalid use!\n    /// let vec1: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 1], 3);\n    /// let vec2: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 2], 3);\n    ///\n    /// // both vecs have length 3 so we'd expect them to be equal, but this\n    /// // fails because elements past the length are still checked in eq\n    /// assert_eq(vec1, vec2); // fails\n    /// ```\n    pub fn from_parts_unchecked(array: [T; MaxLen], len: u32) -> Self {\n        assert(len <= MaxLen);\n        BoundedVec { storage: array, len }\n    }\n}\n\nimpl<T, let MaxLen: u32> Eq for BoundedVec<T, MaxLen>\nwhere\n    T: Eq,\n{\n    fn eq(self, other: BoundedVec<T, MaxLen>) -> bool {\n        // TODO: https://github.com/noir-lang/noir/issues/4837\n        //\n        // We make the assumption that the user has used the proper interface for working with `BoundedVec`s\n        // rather than directly manipulating the internal fields as this can result in an inconsistent internal state.\n        if self.len == other.len {\n            self.storage == other.storage\n        } else {\n            false\n        }\n    }\n}\n\nimpl<T, let MaxLen: u32, let Len: u32> From<[T; Len]> for BoundedVec<T, MaxLen> {\n    fn from(array: [T; Len]) -> BoundedVec<T, MaxLen> {\n        BoundedVec::from_array(array)\n    }\n}\n\nmod bounded_vec_tests {\n\n    mod get {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test(should_fail_with = \"Attempted to read past end of BoundedVec\")]\n        fn panics_when_reading_elements_past_end_of_vec() {\n            let vec: BoundedVec<Field, 5> = BoundedVec::new();\n\n            crate::println(vec.get(0));\n        }\n    }\n\n    mod set {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn set_updates_values_properly() {\n            let mut vec = BoundedVec::from_array([0, 0, 0, 0, 0]);\n\n            vec.set(0, 42);\n            assert_eq(vec.storage, [42, 0, 0, 0, 0]);\n\n            vec.set(1, 43);\n            assert_eq(vec.storage, [42, 43, 0, 0, 0]);\n\n            vec.set(2, 44);\n            assert_eq(vec.storage, [42, 43, 44, 0, 0]);\n\n            vec.set(1, 10);\n            assert_eq(vec.storage, [42, 10, 44, 0, 0]);\n\n            vec.set(0, 0);\n            assert_eq(vec.storage, [0, 10, 44, 0, 0]);\n        }\n\n        #[test(should_fail_with = \"Attempted to write past end of BoundedVec\")]\n        fn panics_when_writing_elements_past_end_of_vec() {\n            let mut vec: BoundedVec<Field, 5> = BoundedVec::new();\n            vec.set(0, 42);\n\n            // Need to use println to avoid DIE removing the write operation.\n            crate::println(vec.get(0));\n        }\n    }\n\n    mod map {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn applies_function_correctly() {\n            // docs:start:bounded-vec-map-example\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = vec.map(|value| value * 2);\n            // docs:end:bounded-vec-map-example\n            let expected = BoundedVec::from_array([2, 4, 6, 8]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn applies_function_that_changes_return_type() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = vec.map(|value| (value * 2) as Field);\n            let expected: BoundedVec<Field, 4> = BoundedVec::from_array([2, 4, 6, 8]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn does_not_apply_function_past_len() {\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([0, 1]);\n            let result = vec.map(|value| if value == 0 { 5 } else { value });\n            let expected = BoundedVec::from_array([5, 1]);\n\n            assert_eq(result, expected);\n            assert_eq(result.get_unchecked(2), 0);\n        }\n    }\n\n    mod mapi {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn applies_function_correctly() {\n            // docs:start:bounded-vec-mapi-example\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = vec.mapi(|i, value| i + value * 2);\n            // docs:end:bounded-vec-mapi-example\n            let expected = BoundedVec::from_array([2, 5, 8, 11]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn applies_function_that_changes_return_type() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = vec.mapi(|i, value| (i + value * 2) as Field);\n            let expected: BoundedVec<Field, 4> = BoundedVec::from_array([2, 5, 8, 11]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn does_not_apply_function_past_len() {\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([0, 1]);\n            let result = vec.mapi(|_, value| if value == 0 { 5 } else { value });\n            let expected = BoundedVec::from_array([5, 1]);\n\n            assert_eq(result, expected);\n            assert_eq(result.get_unchecked(2), 0);\n        }\n    }\n\n    mod for_each {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        // map in terms of for_each\n        fn for_each_map<T, U, Env, let MaxLen: u32>(\n            input: BoundedVec<T, MaxLen>,\n            f: fn[Env](T) -> U,\n        ) -> BoundedVec<U, MaxLen> {\n            let mut output = BoundedVec::<U, MaxLen>::new();\n            let output_ref = &mut output;\n            input.for_each(|x| output_ref.push(f(x)));\n            output\n        }\n\n        #[test]\n        fn smoke_test() {\n            let mut acc = 0;\n            let acc_ref = &mut acc;\n            // docs:start:bounded-vec-for-each-example\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([1, 2, 3]);\n            vec.for_each(|value| { *acc_ref += value; });\n            // docs:end:bounded-vec-for-each-example\n            assert_eq(acc, 6);\n        }\n\n        #[test]\n        fn applies_function_correctly() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = for_each_map(vec, |value| value * 2);\n            let expected = BoundedVec::from_array([2, 4, 6, 8]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn applies_function_that_changes_return_type() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = for_each_map(vec, |value| (value * 2) as Field);\n            let expected: BoundedVec<Field, 4> = BoundedVec::from_array([2, 4, 6, 8]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn does_not_apply_function_past_len() {\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([0, 1]);\n            let result = for_each_map(vec, |value| if value == 0 { 5 } else { value });\n            let expected = BoundedVec::from_array([5, 1]);\n\n            assert_eq(result, expected);\n            assert_eq(result.get_unchecked(2), 0);\n        }\n    }\n\n    mod for_eachi {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        // mapi in terms of for_eachi\n        fn for_eachi_mapi<T, U, Env, let MaxLen: u32>(\n            input: BoundedVec<T, MaxLen>,\n            f: fn[Env](u32, T) -> U,\n        ) -> BoundedVec<U, MaxLen> {\n            let mut output = BoundedVec::<U, MaxLen>::new();\n            let output_ref = &mut output;\n            input.for_eachi(|i, x| output_ref.push(f(i, x)));\n            output\n        }\n\n        #[test]\n        fn smoke_test() {\n            let mut acc = 0;\n            let acc_ref = &mut acc;\n            // docs:start:bounded-vec-for-eachi-example\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([1, 2, 3]);\n            vec.for_eachi(|i, value| { *acc_ref += i * value; });\n            // docs:end:bounded-vec-for-eachi-example\n\n            // 0 * 1 + 1 * 2 + 2 * 3\n            assert_eq(acc, 8);\n        }\n\n        #[test]\n        fn applies_function_correctly() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = for_eachi_mapi(vec, |i, value| i + value * 2);\n            let expected = BoundedVec::from_array([2, 5, 8, 11]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn applies_function_that_changes_return_type() {\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_array([1, 2, 3, 4]);\n            let result = for_eachi_mapi(vec, |i, value| (i + value * 2) as Field);\n            let expected: BoundedVec<Field, 4> = BoundedVec::from_array([2, 5, 8, 11]);\n\n            assert_eq(result, expected);\n        }\n\n        #[test]\n        fn does_not_apply_function_past_len() {\n            let vec: BoundedVec<u32, 3> = BoundedVec::from_array([0, 1]);\n            let result = for_eachi_mapi(vec, |_, value| if value == 0 { 5 } else { value });\n            let expected = BoundedVec::from_array([5, 1]);\n\n            assert_eq(result, expected);\n            assert_eq(result.get_unchecked(2), 0);\n        }\n    }\n\n    mod from_array {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn empty() {\n            let empty_array: [Field; 0] = [];\n            let bounded_vec = BoundedVec::from_array([]);\n\n            assert_eq(bounded_vec.max_len(), 0);\n            assert_eq(bounded_vec.len(), 0);\n            assert_eq(bounded_vec.storage(), empty_array);\n        }\n\n        #[test]\n        fn equal_len() {\n            let array = [1, 2, 3];\n            let bounded_vec = BoundedVec::from_array(array);\n\n            assert_eq(bounded_vec.max_len(), 3);\n            assert_eq(bounded_vec.len(), 3);\n            assert_eq(bounded_vec.storage(), array);\n        }\n\n        #[test]\n        fn max_len_greater_then_array_len() {\n            let array = [1, 2, 3];\n            let bounded_vec: BoundedVec<Field, 10> = BoundedVec::from_array(array);\n\n            assert_eq(bounded_vec.max_len(), 10);\n            assert_eq(bounded_vec.len(), 3);\n            assert_eq(bounded_vec.get(0), 1);\n            assert_eq(bounded_vec.get(1), 2);\n            assert_eq(bounded_vec.get(2), 3);\n        }\n\n        #[test(should_fail_with = \"from array out of bounds\")]\n        fn max_len_lower_then_array_len() {\n            let _: BoundedVec<Field, 2> = BoundedVec::from_array([0; 3]);\n        }\n    }\n\n    mod trait_from {\n        use crate::collections::bounded_vec::BoundedVec;\n        use crate::convert::From;\n\n        #[test]\n        fn simple() {\n            let array = [1, 2];\n            let bounded_vec: BoundedVec<Field, 10> = BoundedVec::from(array);\n\n            assert_eq(bounded_vec.max_len(), 10);\n            assert_eq(bounded_vec.len(), 2);\n            assert_eq(bounded_vec.get(0), 1);\n            assert_eq(bounded_vec.get(1), 2);\n        }\n    }\n\n    mod trait_eq {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn empty_equality() {\n            let mut bounded_vec1: BoundedVec<Field, 3> = BoundedVec::new();\n            let mut bounded_vec2: BoundedVec<Field, 3> = BoundedVec::new();\n\n            assert_eq(bounded_vec1, bounded_vec2);\n        }\n\n        #[test]\n        fn inequality() {\n            let mut bounded_vec1: BoundedVec<Field, 3> = BoundedVec::new();\n            let mut bounded_vec2: BoundedVec<Field, 3> = BoundedVec::new();\n            bounded_vec1.push(1);\n            bounded_vec2.push(2);\n\n            assert(bounded_vec1 != bounded_vec2);\n        }\n    }\n\n    mod from_parts {\n        use crate::collections::bounded_vec::BoundedVec;\n\n        #[test]\n        fn from_parts() {\n            // docs:start:from-parts\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_parts([1, 2, 3, 0], 3);\n            assert_eq(vec.len(), 3);\n\n            // Any elements past the given length are zeroed out, so these\n            // two BoundedVecs will be completely equal\n            let vec1: BoundedVec<u32, 4> = BoundedVec::from_parts([1, 2, 3, 1], 3);\n            let vec2: BoundedVec<u32, 4> = BoundedVec::from_parts([1, 2, 3, 2], 3);\n            assert_eq(vec1, vec2);\n            // docs:end:from-parts\n        }\n\n        #[test]\n        fn from_parts_unchecked() {\n            // docs:start:from-parts-unchecked\n            let vec: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 0], 3);\n            assert_eq(vec.len(), 3);\n\n            // invalid use!\n            let vec1: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 1], 3);\n            let vec2: BoundedVec<u32, 4> = BoundedVec::from_parts_unchecked([1, 2, 3, 2], 3);\n\n            // both vecs have length 3 so we'd expect them to be equal, but this\n            // fails because elements past the length are still checked in eq\n            assert(vec1 != vec2);\n            // docs:end:from-parts-unchecked\n        }\n    }\n}\n"
    },
    "62": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/context/utility_context.nr",
      "source": "use crate::oracle::{\n    execution::{get_block_number, get_chain_id, get_contract_address, get_version},\n    storage::storage_read,\n};\nuse dep::protocol_types::{address::AztecAddress, traits::Packable};\n\npub struct UtilityContext {\n    block_number: u32,\n    contract_address: AztecAddress,\n    version: Field,\n    chain_id: Field,\n}\n\nimpl UtilityContext {\n    pub unconstrained fn new() -> Self {\n        // We could call these oracles on the getters instead of at creation, which makes sense given that they might\n        // not even be accessed. However any performance gains are minimal, and we'd rather fail early if a user\n        // incorrectly attempts to create a UtilityContext in an environment in which these oracles are not\n        // available.\n        let block_number = get_block_number();\n        let contract_address = get_contract_address();\n        let chain_id = get_chain_id();\n        let version = get_version();\n        Self { block_number, contract_address, version, chain_id }\n    }\n\n    pub unconstrained fn at(contract_address: AztecAddress) -> Self {\n        let block_number = get_block_number();\n        let chain_id = get_chain_id();\n        let version = get_version();\n        Self { block_number, contract_address, version, chain_id }\n    }\n\n    pub unconstrained fn at_historical(contract_address: AztecAddress, block_number: u32) -> Self {\n        let chain_id = get_chain_id();\n        let version = get_version();\n        Self { block_number, contract_address, version, chain_id }\n    }\n\n    pub fn block_number(self) -> u32 {\n        self.block_number\n    }\n\n    pub fn this_address(self) -> AztecAddress {\n        self.contract_address\n    }\n\n    pub fn version(self) -> Field {\n        self.version\n    }\n\n    pub fn chain_id(self) -> Field {\n        self.chain_id\n    }\n\n    pub unconstrained fn raw_storage_read<let N: u32>(\n        self: Self,\n        storage_slot: Field,\n    ) -> [Field; N] {\n        storage_read(self.this_address(), storage_slot, self.block_number())\n    }\n\n    pub unconstrained fn storage_read<T, let N: u32>(self, storage_slot: Field) -> T\n    where\n        T: Packable<N>,\n    {\n        T::unpack(self.raw_storage_read(storage_slot))\n    }\n}\n"
    },
    "83": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/keys/getters/mod.nr",
      "source": "use crate::{\n    keys::constants::{NULLIFIER_INDEX, OUTGOING_INDEX},\n    oracle::{\n        key_validation_request::get_key_validation_request,\n        keys::get_public_keys_and_partial_address,\n    },\n};\nuse dep::protocol_types::{address::AztecAddress, public_keys::PublicKeys};\n\nmod test;\n\npub unconstrained fn get_nsk_app(npk_m_hash: Field) -> Field {\n    get_key_validation_request(npk_m_hash, NULLIFIER_INDEX).sk_app\n}\n\n// A helper function that gets app-siloed outgoing viewing key for a given `ovpk_m_hash`. This function is used\n// in unconstrained contexts only - when computing unconstrained note logs. The safe alternative is `request_ovsk_app`\n// function defined on `PrivateContext`.\npub unconstrained fn get_ovsk_app(ovpk_m_hash: Field) -> Field {\n    get_key_validation_request(ovpk_m_hash, OUTGOING_INDEX).sk_app\n}\n\n// Returns all public keys for a given account, applying proper constraints to the context. We read all\n// keys at once since the constraints for reading them all are actually fewer than if we read them one at a time - any\n// read keys that are not required by the caller can simply be discarded.\npub fn get_public_keys(account: AztecAddress) -> PublicKeys {\n    // Safety: Public keys are constrained by showing their inclusion in the address's preimage.\n    let (public_keys, partial_address) = unsafe { get_public_keys_and_partial_address(account) };\n    assert_eq(\n        account,\n        AztecAddress::compute(public_keys, partial_address),\n        \"Invalid public keys hint for address\",\n    );\n\n    public_keys\n}\n"
    },
    "87": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/macros/aztec.nr",
      "source": "use crate::{\n    macros::{\n        dispatch::generate_public_dispatch,\n        functions::{stub_registry, utils::check_each_fn_macroified},\n        notes::{generate_note_export, NOTES},\n        storage::STORAGE_LAYOUT_NAME,\n        utils::{get_trait_impl_method, module_has_storage},\n    },\n    messages::discovery::private_notes::MAX_NOTE_PACKED_LEN,\n};\n\n/// Marks a contract as an Aztec contract, generating the interfaces for its functions and notes, as well as injecting\n/// the `sync_private_state` utility function PXE requires in order to discover notes.\n/// Note: This is a module annotation, so the returned quote gets injected inside the module (contract) itself.\npub comptime fn aztec(m: Module) -> Quoted {\n    let interface = generate_contract_interface(m);\n\n    // Functions that don't have #[private], #[public], #[utility], #[contract_library_method], or #[test] are not\n    // allowed in contracts.\n    check_each_fn_macroified(m);\n\n    let contract_library_method_compute_note_hash_and_nullifier =\n        generate_contract_library_method_compute_note_hash_and_nullifier();\n    let note_exports = generate_note_exports();\n    let public_dispatch = generate_public_dispatch(m);\n    let sync_private_state = generate_sync_private_state();\n\n    quote {\n        $note_exports\n        $interface\n        $contract_library_method_compute_note_hash_and_nullifier\n        $public_dispatch\n        $sync_private_state\n    }\n}\n\ncomptime fn generate_contract_interface(m: Module) -> Quoted {\n    let module_name = m.name();\n    let contract_stubs = stub_registry::get(m);\n    let fn_stubs_quote = if contract_stubs.is_some() {\n        contract_stubs.unwrap().join(quote {})\n    } else {\n        quote {}\n    };\n\n    let has_storage_layout = module_has_storage(m) & STORAGE_LAYOUT_NAME.get(m).is_some();\n    let storage_layout_getter = if has_storage_layout {\n        let storage_layout_name = STORAGE_LAYOUT_NAME.get(m).unwrap();\n        quote {\n            pub fn storage_layout() -> StorageLayoutFields {\n                $storage_layout_name.fields\n            }\n        }\n    } else {\n        quote {}\n    };\n\n    let library_storage_layout_getter = if has_storage_layout {\n        quote {\n            #[contract_library_method]\n            $storage_layout_getter\n        }\n    } else {\n        quote {}\n    };\n\n    quote {\n        pub struct $module_name {\n            pub target_contract: dep::aztec::protocol_types::address::AztecAddress\n        }\n\n        impl $module_name {\n            $fn_stubs_quote\n\n            pub fn at(\n                addr: aztec::protocol_types::address::AztecAddress\n            ) -> Self {\n                Self { target_contract: addr }\n            }\n\n            pub fn interface() -> Self {\n                Self { target_contract: aztec::protocol_types::address::AztecAddress::zero() }\n            }\n\n            $storage_layout_getter\n        }\n\n        #[contract_library_method]\n        pub fn at(\n            addr: aztec::protocol_types::address::AztecAddress\n        ) -> $module_name {\n            $module_name { target_contract: addr }\n        }\n\n        #[contract_library_method]\n        pub fn interface() -> $module_name {\n            $module_name { target_contract: aztec::protocol_types::address::AztecAddress::zero() }\n        }\n\n        $library_storage_layout_getter\n\n    }\n}\n\n/// Generates a contract library method called `_compute_note_hash_and_nullifier` which is used for note\n/// discovery (to create the `aztec::messages::discovery::ComputeNoteHashAndNullifier` function) and to implement the\n/// `compute_note_hash_and_nullifier` unconstrained contract function.\ncomptime fn generate_contract_library_method_compute_note_hash_and_nullifier() -> Quoted {\n    let notes = NOTES.entries();\n\n    if notes.len() > 0 {\n        let max_note_packed_len = notes.fold(\n            0,\n            |acc, (_, (_, len, _, _)): (Type, (TypeDefinition, u32, Field, [(Quoted, u32, bool)]))| {\n                if len > acc {\n                    len\n                } else {\n                    acc\n                }\n            },\n        );\n\n        if max_note_packed_len > MAX_NOTE_PACKED_LEN {\n            panic(\n                f\"One of the notes has packed len {max_note_packed_len} but the maximum is {MAX_NOTE_PACKED_LEN}\",\n            );\n        }\n\n        // Contracts that do define notes produce an if-else chain where `note_type_id` is matched against the\n        // `get_note_type_id()` function of each note type that we know of, in order to identify the note type. Once we\n        // know it we call we correct `unpack` method from the `Packable` trait to obtain the underlying note type, and\n        // compute the note hash (non-siloed) and inner nullifier (also non-siloed).\n\n        let mut if_note_type_id_match_statements_list = &[];\n        for i in 0..notes.len() {\n            let (typ, (_, packed_note_length, _, _)) = notes[i];\n\n            let get_note_type_id = get_trait_impl_method(\n                typ,\n                quote { crate::note::note_interface::NoteType },\n                quote { get_id },\n            );\n            let unpack = get_trait_impl_method(\n                typ,\n                quote { crate::protocol_types::traits::Packable<_> },\n                quote { unpack },\n            );\n\n            let compute_note_hash = get_trait_impl_method(\n                typ,\n                quote { crate::note::note_interface::NoteHash },\n                quote { compute_note_hash },\n            );\n\n            let compute_nullifier_unconstrained = get_trait_impl_method(\n                typ,\n                quote { crate::note::note_interface::NoteHash },\n                quote { compute_nullifier_unconstrained },\n            );\n\n            let if_or_else_if = if i == 0 {\n                quote { if }\n            } else {\n                quote { else if }\n            };\n\n            if_note_type_id_match_statements_list = if_note_type_id_match_statements_list.push_back(\n                quote {\n                    $if_or_else_if note_type_id == $get_note_type_id() {\n                        // As an extra safety check we make sure that the packed_note BoundedVec has the expected\n                        // length, since we're about to interpret it's raw storage as a fixed-size array by calling the\n                        // unpack function on it.\n                        let expected_len = $packed_note_length;\n                        let actual_len = packed_note.len();\n                        assert(\n                            actual_len == expected_len,\n                            f\"Expected packed note of length {expected_len} but got {actual_len} for note type id {note_type_id}\"\n                        );\n\n                        let note = $unpack(aztec::utils::array::subarray(packed_note.storage(), 0));\n\n                        let note_hash = $compute_note_hash(note, storage_slot);\n    \n                        // The message discovery process finds settled notes, that is, notes that were created in prior\n                        // transactions and are therefore already part of the note hash tree. We therefore compute the\n                        // nullification note hash by treating the note as a settled note with the provided nonce.\n                        let note_hash_for_nullify = aztec::note::utils::compute_note_hash_for_nullify(\n                            aztec::note::retrieved_note::RetrievedNote{ \n                                note, \n                                contract_address, \n                                metadata: aztec::note::note_metadata::SettledNoteMetadata::new(nonce).into() \n                            }, \n                            storage_slot,\n                        );\n\n                        let inner_nullifier = $compute_nullifier_unconstrained(note, note_hash_for_nullify);\n\n                        Option::some(\n                            aztec::messages::discovery::NoteHashAndNullifier {\n                                note_hash, inner_nullifier\n                            }\n                        )\n                    }\n                },\n            );\n        }\n\n        let if_note_type_id_match_statements = if_note_type_id_match_statements_list.join(quote {});\n\n        quote {\n            /// Unpacks an array into a note corresponding to `note_type_id` and then computes its note hash\n            /// (non-siloed) and inner nullifier (non-siloed) assuming the note has been inserted into the note hash\n            /// tree with `nonce`.\n            ///\n            /// The signature of this function notably matches the `aztec::messages::discovery::ComputeNoteHashAndNullifier` type,\n            /// and so it can be used to call functions from that module such as `discover_new_messages`, \n            /// `do_process_log` and `attempt_note_discovery`.\n            ///\n            /// This function is automatically injected by the `#[aztec]` macro.\n            #[contract_library_method]\n            unconstrained fn _compute_note_hash_and_nullifier(\n                packed_note: BoundedVec<Field, aztec::messages::discovery::private_notes::MAX_NOTE_PACKED_LEN>,\n                storage_slot: Field,\n                note_type_id: Field,\n                contract_address: aztec::protocol_types::address::AztecAddress,\n                nonce: Field,\n            ) -> Option<aztec::messages::discovery::NoteHashAndNullifier> {\n                $if_note_type_id_match_statements\n                else {\n                    Option::none()\n                }\n            }\n        }\n    } else {\n        // Contracts with no notes still implement this function to avoid having special-casing, the implementation\n        // simply throws immediately.\n        quote {\n            /// This contract does not use private notes, so this function should never be called as it will\n            /// unconditionally fail.\n            ///\n            /// This function is automatically injected by the `#[aztec]` macro.\n            #[contract_library_method]\n            unconstrained fn _compute_note_hash_and_nullifier(\n                _packed_note: BoundedVec<Field, aztec::messages::discovery::private_notes::MAX_NOTE_PACKED_LEN>,\n                _storage_slot: Field,\n                _note_type_id: Field,\n                _contract_address: aztec::protocol_types::address::AztecAddress,\n                _nonce: Field,\n            ) -> Option<aztec::messages::discovery::NoteHashAndNullifier> {\n                panic(f\"This contract does not use private notes\")\n            }\n        }\n    }\n}\n\ncomptime fn generate_note_exports() -> Quoted {\n    let notes = NOTES.values();\n    // Second value in each tuple is `note_packed_len` and that is ignored here because it's only used when\n    // generating partial note helper functions.\n    notes\n        .map(|(s, _, note_type_id, fields): (TypeDefinition, u32, Field, [(Quoted, u32, bool)])| {\n            generate_note_export(s, note_type_id, fields)\n        })\n        .join(quote {})\n}\n\ncomptime fn generate_sync_private_state() -> Quoted {\n    // We obtain the `utility` function on the next line instead of directly doing\n    // `#[aztec::macros::functions::utility]` in the returned quote because the latter would result in the function\n    // attribute having the full path in the ABI. This is undesirable because we use the information in the ABI only\n    // to determine whether a function is `private`, `public`, or `utility`.\n    let utility = crate::macros::functions::utility;\n\n    // All we need to do here is trigger message discovery, but this is already done by the #[utility] macro - we don't\n    // need to do anything extra.\n    quote {\n        #[$utility]\n        unconstrained fn sync_private_state() {\n        }\n    }\n}\n"
    },
    "95": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/macros/functions/utils.nr",
      "source": "use crate::macros::{\n    functions::{abi_export::create_fn_abi_export, call_interface_stubs::stub_fn, stub_registry},\n    notes::NOTES,\n    utils::{\n        add_to_hasher, fn_has_noinitcheck, get_fn_visibility, is_fn_contract_library_method,\n        is_fn_initializer, is_fn_internal, is_fn_private, is_fn_public, is_fn_test, is_fn_utility,\n        is_fn_view, modify_fn_body, module_has_initializer, module_has_storage,\n    },\n};\nuse protocol_types::meta::generate_serialize_to_fields;\nuse std::meta::type_of;\n\npub(crate) comptime fn transform_private(f: FunctionDefinition) -> Quoted {\n    let fn_abi = create_fn_abi_export(f);\n    let fn_stub = stub_fn(f);\n    stub_registry::register(f.module(), fn_stub);\n\n    // If a function is further modified as unconstrained, we throw an error\n    if f.is_unconstrained() {\n        let name = f.name();\n        panic(\n            f\"Function {name} is annotated with #[private] but marked as unconstrained, remove unconstrained keyword\",\n        );\n    }\n\n    let module_has_initializer = module_has_initializer(f.module());\n    let module_has_storage = module_has_storage(f.module());\n\n    // Private functions undergo a lot of transformations from their Aztec.nr form into a circuit that can be fed to the\n    // Private Kernel Circuit.\n    // First we change the function signature so that it also receives `PrivateContextInputs`, which contain information\n    // about the execution context (e.g. the caller).\n    let original_params = f.parameters();\n    f.set_parameters(&[(\n        quote { inputs },\n        quote { crate::context::inputs::private_context_inputs::PrivateContextInputs }.as_type(),\n    )]\n        .append(original_params));\n\n    let mut body = f.body().as_block().unwrap();\n\n    // The original params are hashed and passed to the `context` object, so that the kernel can verify we've received\n    // the correct values.\n    // TODO: Optimize args_hasher for small number of arguments\n    let args_hasher_name = quote { args_hasher };\n    let args_hasher = original_params.fold(\n        quote {\n            let mut $args_hasher_name = dep::aztec::hash::ArgsHasher::new();\n        },\n        |args_hasher, param: (Quoted, Type)| {\n            let (name, typ) = param;\n            let appended_arg = add_to_hasher(args_hasher_name, name, typ);\n            quote {\n                $args_hasher\n                $appended_arg\n            }\n        },\n    );\n\n    let context_creation = quote {\n        let mut context = dep::aztec::context::private_context::PrivateContext::new(inputs, dep::aztec::protocol_types::traits::Hash::hash($args_hasher_name));\n    };\n\n    // Modifications introduced by the different marker attributes.\n    let internal_check = if is_fn_internal(f) {\n        create_internal_check(f)\n    } else {\n        quote {}\n    };\n\n    let view_check = if is_fn_view(f) {\n        create_view_check(f)\n    } else {\n        quote {}\n    };\n\n    let (assert_initializer, mark_as_initialized) = if is_fn_initializer(f) {\n        (create_assert_correct_initializer_args(f), create_mark_as_initialized(f))\n    } else {\n        (quote {}, quote {})\n    };\n\n    let storage_init = if module_has_storage {\n        quote {\n            // Some functions don't access storage, but it'd be quite difficult to only inject this variable if it is\n            // referenced. We instead ignore 'unused variable' warnings for it.\n            #[allow(unused_variables)]\n            let storage = Storage::init(&mut context);\n        }\n    } else {\n        quote {}\n    };\n\n    // Initialization checks are not included in contracts that don't have initializers.\n    let init_check = if module_has_initializer & !is_fn_initializer(f) & !fn_has_noinitcheck(f) {\n        create_init_check(f)\n    } else {\n        quote {}\n    };\n\n    // All private functions perform message discovery, since they may need to access notes. This is slightly\n    // inefficient and could be improved by only doing it once we actually attempt to read any.\n    let message_discovery_call = if NOTES.len() > 0 {\n        create_message_discovery_call()\n    } else {\n        quote {}\n    };\n\n    // Finally, we need to change the return type to be `PrivateCircuitPublicInputs`, which is what the Private Kernel\n    // circuit expects.\n    let return_value_var_name = quote { macro__returned__values };\n\n    let return_value_type = f.return_type();\n    let return_value = if body.len() == 0 {\n        quote {}\n    } else if return_value_type != type_of(()) {\n        // The original return value is passed to a second args hasher which the context receives.\n        let (body_without_return, last_body_expr) = body.pop_back();\n        let return_value = last_body_expr.quoted();\n        let return_value_assignment =\n            quote { let $return_value_var_name: $return_value_type = $return_value; };\n        let return_hasher_name = quote { return_hasher };\n        let return_value_into_hasher =\n            add_to_hasher(return_hasher_name, return_value_var_name, return_value_type);\n\n        body = body_without_return;\n\n        quote {\n            let mut $return_hasher_name = dep::aztec::hash::ArgsHasher::new();\n            $return_value_assignment\n            $return_value_into_hasher\n            context.set_return_hash($return_hasher_name);\n        }\n    } else {\n        let (body_without_return, last_body_expr) = body.pop_back();\n        if !last_body_expr.has_semicolon()\n            & last_body_expr.as_for().is_none()\n            & last_body_expr.as_assert().is_none()\n            & last_body_expr.as_for_range().is_none()\n            & last_body_expr.as_assert_eq().is_none()\n            & last_body_expr.as_let().is_none() {\n            let unused_return_value_name = f\"_{return_value_var_name}\".quoted_contents();\n            body = body_without_return.push_back(\n                quote { let $unused_return_value_name = $last_body_expr; }.as_expr().unwrap(),\n            );\n        }\n        quote {}\n    };\n\n    let context_finish = quote { context.finish() };\n\n    let to_prepend = quote {\n        $args_hasher\n        $context_creation\n        $assert_initializer\n        $init_check\n        $internal_check\n        $view_check\n        $storage_init\n        $message_discovery_call\n    };\n\n    let to_append = quote {\n        $return_value\n        $mark_as_initialized\n        $context_finish\n    };\n    let modified_body = modify_fn_body(body, to_prepend, to_append);\n    f.set_body(modified_body);\n    f.set_return_type(\n        quote { dep::protocol_types::abis::private_circuit_public_inputs::PrivateCircuitPublicInputs }\n            .as_type(),\n    );\n    f.set_return_data();\n\n    fn_abi\n}\n\npub(crate) comptime fn transform_public(f: FunctionDefinition) -> Quoted {\n    let fn_abi = create_fn_abi_export(f);\n    let fn_stub = stub_fn(f);\n    stub_registry::register(f.module(), fn_stub);\n\n    // If a function is further modified as unconstrained, we throw an error\n    if f.is_unconstrained() {\n        let name = f.name();\n        panic(\n            f\"Function {name} is annotated with #[public] but marked as unconstrained, remove unconstrained keyword\",\n        );\n    }\n\n    let module_has_initializer = module_has_initializer(f.module());\n    let module_has_storage = module_has_storage(f.module());\n\n    // Public functions undergo a lot of transformations from their Aztec.nr form.\n    let original_params = f.parameters();\n    let args_len = original_params\n        .map(|(name, typ): (Quoted, Type)| {\n            generate_serialize_to_fields(name, typ, false).0.len()\n        })\n        .fold(0, |acc: u32, val: u32| acc + val);\n\n    // Unlike in the private case, in public the `context` does not need to receive the hash of the original params.\n    let context_creation = quote {\n        let mut context = dep::aztec::context::public_context::PublicContext::new(|| {\n        // We start from 1 because we skip the selector for the dispatch function.\n        let serialized_args : [Field; $args_len] = dep::aztec::context::public_context::calldata_copy(1, $args_len);\n        dep::aztec::hash::hash_args_array(serialized_args)\n        });\n    };\n\n    // Modifications introduced by the different marker attributes.\n    let internal_check = if is_fn_internal(f) {\n        create_internal_check(f)\n    } else {\n        quote {}\n    };\n\n    let view_check = if is_fn_view(f) {\n        create_view_check(f)\n    } else {\n        quote {}\n    };\n\n    let (assert_initializer, mark_as_initialized) = if is_fn_initializer(f) {\n        (create_assert_correct_initializer_args(f), create_mark_as_initialized(f))\n    } else {\n        (quote {}, quote {})\n    };\n\n    let storage_init = if module_has_storage {\n        // Some functions don't access storage, but it'd be quite difficult to only inject this variable if it is\n        // referenced. We instead ignore 'unused variable' warnings for it.\n        quote {\n            #[allow(unused_variables)]\n            let storage = Storage::init(&mut context);\n        }\n    } else {\n        quote {}\n    };\n\n    // Initialization checks are not included in contracts that don't have initializers.\n    let init_check = if module_has_initializer & !fn_has_noinitcheck(f) & !is_fn_initializer(f) {\n        create_init_check(f)\n    } else {\n        quote {}\n    };\n\n    let to_prepend = quote {\n        $context_creation\n        $assert_initializer\n        $init_check\n        $internal_check\n        $view_check\n        $storage_init\n    };\n\n    let to_append = quote {\n        $mark_as_initialized\n    };\n\n    let body = f.body().as_block().unwrap();\n    let modified_body = modify_fn_body(body, to_prepend, to_append);\n    f.set_body(modified_body);\n\n    // All public functions are automatically made unconstrained, even if they were not marked as such. This is because\n    // instead of compiling into a circuit, they will compile to bytecode that will be later transpiled into AVM\n    // bytecode.\n    f.set_unconstrained(true);\n    f.set_return_public(true);\n\n    fn_abi\n}\n\npub(crate) comptime fn transform_utility(f: FunctionDefinition) -> Quoted {\n    let fn_abi = create_fn_abi_export(f);\n    let fn_stub = stub_fn(f);\n    stub_registry::register(f.module(), fn_stub);\n\n    // Check if function is marked as unconstrained\n    if !f.is_unconstrained() {\n        let name = f.name();\n        panic(\n            f\"Function {name} is annotated with #[utility] but not marked as unconstrained, add unconstrained keyword\",\n        );\n    }\n\n    // Create utility context\n    let context_creation =\n        quote { let mut context = dep::aztec::context::utility_context::UtilityContext::new(); };\n    let module_has_storage = module_has_storage(f.module());\n\n    // Initialize Storage if module has storage\n    let storage_init = if module_has_storage {\n        quote {\n            // Some functions don't access storage, but it'd be quite difficult to only inject this variable if it is\n            // referenced. We instead ignore 'unused variable' warnings for it.\n            #[allow(unused_variables)]\n            let storage = Storage::init(context);\n        }\n    } else {\n        quote {}\n    };\n\n    // All utility functions perform message discovery, since they may need to access private notes that would be\n    // found during this process. This is slightly inefficient and could be improved by only doing it once we actually\n    // attempt to read any.\n    let message_discovery_call = if NOTES.len() > 0 {\n        create_message_discovery_call()\n    } else {\n        quote {}\n    };\n\n    // Inject context creation, storage initialization, and message discovery call at the beginning of the function\n    // body.\n    let to_prepend = quote {\n        $context_creation\n        $storage_init\n        $message_discovery_call\n    };\n    let body = f.body().as_block().unwrap();\n    let modified_body = modify_fn_body(body, to_prepend, quote {});\n    f.set_body(modified_body);\n\n    f.set_return_public(true);\n\n    fn_abi\n}\n\ncomptime fn create_internal_check(f: FunctionDefinition) -> Quoted {\n    let name = f.name();\n    let assertion_message = f\"Function {name} can only be called internally\";\n    quote { assert(context.msg_sender() == context.this_address(), $assertion_message); }\n}\n\ncomptime fn create_view_check(f: FunctionDefinition) -> Quoted {\n    let name = f.name();\n    let assertion_message = f\"Function {name} can only be called statically\";\n    if is_fn_private(f) {\n        // Here `context` is of type context::PrivateContext\n        quote { assert(context.inputs.call_context.is_static_call == true, $assertion_message); }\n    } else {\n        // Here `context` is of type context::PublicContext\n        quote { assert(context.is_static_call(), $assertion_message); }\n    }\n}\n\ncomptime fn create_assert_correct_initializer_args(f: FunctionDefinition) -> Quoted {\n    let fn_visibility = get_fn_visibility(f);\n    f\"dep::aztec::macros::functions::initialization_utils::assert_initialization_matches_address_preimage_{fn_visibility}(context);\"\n        .quoted_contents()\n}\n\ncomptime fn create_mark_as_initialized(f: FunctionDefinition) -> Quoted {\n    let fn_visibility = get_fn_visibility(f);\n    f\"dep::aztec::macros::functions::initialization_utils::mark_as_initialized_{fn_visibility}(&mut context);\"\n        .quoted_contents()\n}\n\ncomptime fn create_init_check(f: FunctionDefinition) -> Quoted {\n    let fn_visibility = get_fn_visibility(f);\n    f\"dep::aztec::macros::functions::initialization_utils::assert_is_initialized_{fn_visibility}(&mut context);\"\n        .quoted_contents()\n}\n\n/// Injects a call to `aztec::messages::discovery::discover_new_messages`, causing for new notes to be added to PXE and made\n/// available for the current execution.\npub(crate) comptime fn create_message_discovery_call() -> Quoted {\n    quote {\n        /// Safety: message discovery returns nothing and is performed solely for its side-effects. It is therefore\n        /// always safe to call.\n        unsafe {\n            dep::aztec::messages::discovery::discover_new_messages(\n                context.this_address(),\n                _compute_note_hash_and_nullifier,\n            );\n        };\n    }\n}\n\n/// Checks if each function in the module is marked with either #[private], #[public], #[utility],\n/// #[contract_library_method], or #[test]. Non-macroified functions are not allowed in contracts.\npub(crate) comptime fn check_each_fn_macroified(m: Module) {\n    for f in m.functions() {\n        let name = f.name();\n        if !is_fn_private(f)\n            & !is_fn_public(f)\n            & !is_fn_utility(f)\n            & !is_fn_contract_library_method(f)\n            & !is_fn_test(f) {\n            panic(\n                f\"Function {name} must be marked as either #[private], #[public], #[utility], #[contract_library_method], or #[test]\",\n            );\n        }\n    }\n}\n"
    },
    "97": {
      "path": "/Users/satyam/nargo/github.com/AztecProtocol/aztec-packages/v0.87.2/noir-projects/aztec-nr/aztec/src/macros/notes.nr",
      "source": "use crate::{macros::utils::AsStrQuote, note::note_getter_options::PropertySelector};\nuse poseidon::poseidon2::Poseidon2Hasher;\nuse protocol_types::meta::{derive_packable_and_get_packed_len, generate_serialize_to_fields};\nuse std::{\n    collections::umap::UHashMap,\n    hash::{BuildHasherDefault, Hash, Hasher},\n    meta::{type_of, unquote},\n};\n\n/// A map from note type to (note_struct_definition, note_packed_len, note_type_id, fields).\n/// `fields` is an array of tuples where each tuple contains the name of the field/struct member (e.g. `amount`\n/// in `TokenNote`), the index of where the packed member starts in the packed note and a flag indicating\n/// whether the field is nullable or not.\npub comptime mut global NOTES: UHashMap<Type, (TypeDefinition, u32, Field, [(Quoted, u32, bool)]), BuildHasherDefault<Poseidon2Hasher>> =\n    UHashMap::default();\n\npub comptime mut global NOTE_TYPE_ID_COUNTER: u32 = 0;\n\n/// The note type id is set by enumerating the note types.\ncomptime fn get_next_note_type_id() -> Field {\n    // We assert that the note type id fits within 7 bits\n    assert(\n        NOTE_TYPE_ID_COUNTER < 128 as u32,\n        \"A contract can contain at most 128 different note types\",\n    );\n\n    let note_type_id = NOTE_TYPE_ID_COUNTER as Field;\n    NOTE_TYPE_ID_COUNTER += 1;\n    note_type_id\n}\n\n/// Generates a quote that implements `Packable` for a given struct `s`.\n/// If the note struct already implements `Packable`, we return an empty quote.\ncomptime fn derive_packable_if_not_implemented_and_get_len(s: TypeDefinition) -> (Quoted, u32) {\n    // We try to get the packed length of the note struct. If it does not implement `Packable`, we get Option::none()\n    let packed_len_typ = std::meta::typ::fresh_type_variable();\n    // We don't care about the result of the implements check. We just want the get the packed length.\n    let _ = s.as_type().implements(\n        quote { crate::protocol_types::traits::Packable<$packed_len_typ> }.as_trait_constraint(),\n    );\n    let maybe_packed_length = packed_len_typ.as_constant();\n\n    if maybe_packed_length.is_some() {\n        // We got some packed length meaning that the note struct implements `Packable`. For this reason we return\n        // an empty quote for the implementation and the packed length.\n        (quote {}, maybe_packed_length.unwrap())\n    } else {\n        // We didn't manage to get the packed length which means the note struct doesn't implement `Packable`\n        // so we derive it and return it along with the packed length.\n        derive_packable_and_get_packed_len(s)\n    }\n}\n\n/// Generates default `NoteType` implementation for a given note struct `s` and returns it as a quote.\n///\n/// impl NoteType for NoteStruct {\n///     fn get_id() -> Field {\n///         ...\n///     }\n/// }\ncomptime fn generate_note_interface(s: TypeDefinition, note_type_id: Field) -> Quoted {\n    let name = s.name();\n\n    quote {\n        impl aztec::note::note_interface::NoteType for $name {\n            fn get_id() -> Field {\n                $note_type_id\n            }\n        }\n    }\n}\n\n/// Generates default `NoteHash` trait implementation for a given note struct `s` and returns it as a quote.\n///\n/// # Generated Implementation\n/// ```\n/// impl NoteHash for NoteStruct {\n///     fn compute_note_hash(self, storage_slot: Field) -> Field { ... }\n///\n///     fn compute_nullifier(self, context: &mut PrivateContext, note_hash_for_nullify: Field) -> Field { ... }\n///\n///     unconstrained fn compute_nullifier_unconstrained(note_hash_for_nullify: Field) -> Field { ... }\n/// }\n/// ```\ncomptime fn generate_note_hash_trait_impl(s: TypeDefinition) -> Quoted {\n    let name = s.name();\n\n    quote {\n        impl aztec::note::note_interface::NoteHash for $name {\n            fn compute_note_hash(self, storage_slot: Field) -> Field {\n                let inputs = aztec::protocol_types::utils::arrays::array_concat(aztec::protocol_types::traits::Packable::pack(self), [storage_slot]);\n                aztec::protocol_types::hash::poseidon2_hash_with_separator(inputs, aztec::protocol_types::constants::GENERATOR_INDEX__NOTE_HASH)\n            }\n\n            fn compute_nullifier(\n                self,\n                context: &mut aztec::prelude::PrivateContext,\n                note_hash_for_nullify: Field,\n            ) -> Field {\n                let owner_npk_m = aztec::keys::getters::get_public_keys(self.owner).npk_m;\n                // We invoke hash as a static trait function rather than calling owner_npk_m.hash() directly\n                // in the quote to avoid \"trait not in scope\" compiler warnings.\n                let owner_npk_m_hash = aztec::protocol_types::traits::Hash::hash(owner_npk_m);\n                let secret = context.request_nsk_app(owner_npk_m_hash);\n                aztec::protocol_types::hash::poseidon2_hash_with_separator(\n                    [note_hash_for_nullify, secret],\n                    aztec::protocol_types::constants::GENERATOR_INDEX__NOTE_NULLIFIER as Field,\n                )\n            }\n\n            unconstrained fn compute_nullifier_unconstrained(\n                self,\n                note_hash_for_nullify: Field,\n            ) -> Field {\n                let owner_npk_m = aztec::keys::getters::get_public_keys(self.owner).npk_m;\n                // We invoke hash as a static trait function rather than calling owner_npk_m.hash() directly\n                // in the quote to avoid \"trait not in scope\" compiler warnings.\n                let owner_npk_m_hash = aztec::protocol_types::traits::Hash::hash(owner_npk_m);\n                let secret = aztec::keys::getters::get_nsk_app(owner_npk_m_hash);\n                aztec::protocol_types::hash::poseidon2_hash_with_separator(\n                    [note_hash_for_nullify, secret],\n                    aztec::protocol_types::constants::GENERATOR_INDEX__NOTE_NULLIFIER as Field,\n                )\n            }\n        }\n    }\n}\n\n/// Generates note properties struct for a given note struct `s`.\n///\n/// Example:\n/// ```\n/// struct TokenNoteProperties {\n///     amount: aztec::note::note_getter_options::PropertySelector,\n///     npk_m_hash: aztec::note::note_getter_options::PropertySelector\n///     randomness: aztec::note::note_getter_options::PropertySelector\n/// }\n///\n/// impl aztec::note::note_interface::NoteProperties<TokenNoteProperties> for TokenNote {\n///     fn properties() -> TokenNoteProperties {\n///         Self {\n///             amount: aztec::note::note_getter_options::PropertySelector { index: 0, offset: 0, length: 32 },\n///             npk_m_hash: aztec::note::note_getter_options::PropertySelector { index: 1, offset: 0, length: 32 },\n///             randomness: aztec::note::note_getter_options::PropertySelector { index: 2, offset: 0, length: 32 }\n///         }\n///     }\n/// }\n/// ```\ncomptime fn generate_note_properties(s: TypeDefinition) -> Quoted {\n    let name = s.name();\n\n    let struct_name = f\"{name}Properties\".quoted_contents();\n\n    let property_selector_type = type_of(PropertySelector { index: 0, offset: 0, length: 0 });\n\n    let note_fields = s.fields_as_written();\n\n    let properties_types = note_fields\n        .map(|(name, _): (Quoted, Type)| quote { pub $name: $property_selector_type })\n        .join(quote {,});\n\n    // TODO #8694: Properly handle non-field types https://github.com/AztecProtocol/aztec-packages/issues/8694\n    let mut properties_list = &[];\n    for i in 0..note_fields.len() {\n        let (name, _) = note_fields[i];\n        properties_list = properties_list.push_back(\n            quote { $name: aztec::note::note_getter_options::PropertySelector { index: $i, offset: 0, length: 32 } },\n        );\n    }\n\n    let properties = properties_list.join(quote {,});\n\n    quote {\n        pub struct $struct_name {\n            $properties_types\n        }\n\n        impl aztec::note::note_interface::NoteProperties<$struct_name> for $name {\n            fn properties() -> $struct_name {\n                $struct_name {\n                    $properties\n                }\n            }\n        }\n    }\n}\n\n/// Generates note export for a given note struct `s`. The export is a global variable that contains note type id,\n/// note name and information about note fields (field name, index and whether the field is nullable or not).\n///\n/// Example:\n/// ```\n/// struct TokenNoteFields_5695262104 {\n///     amount: aztec::note::note_field::NoteField,\n///     owner: aztec::note::note_field::NoteField\n/// }\n///\n/// #[abi(notes)]\n/// global TokenNote_EXPORTS_5695262104: (Field, str<8>, TokenNoteFields_5695262104) = (\n///     0,\n///     \"TokenNote\",\n///     TokenNoteFields_5695262104 {\n///         amount: aztec::note::note_field::NoteField { index: 0, nullable: false },\n///         owner: aztec::note::note_field::NoteField { index: 1, nullable: false }\n///     }\n/// );\n///\n/// Randomly looking value at the end of the export name is generated by hashing the note struct type and is included\n/// to prevent naming collisions in case there are multiple notes with the same name imported in a contract.\npub(crate) comptime fn generate_note_export(\n    s: TypeDefinition,\n    note_type_id: Field,\n    fields: [(Quoted, u32, bool)],\n) -> Quoted {\n    let name = s.name();\n    let mut hasher = Poseidon2Hasher::default();\n    s.as_type().hash(&mut hasher);\n    let hash = hasher.finish() as u32;\n    let global_export_name = f\"{name}_EXPORTS_{hash}\".quoted_contents();\n    let note_fields_name = f\"{name}Fields_{hash}\".quoted_contents();\n    let (note_name_as_str, _) = name.as_str_quote();\n    let note_name_str_len = unquote!(quote { $note_name_as_str.as_bytes().len() });\n\n    let mut note_fields = &[];\n    let mut note_field_constructors = &[];\n    for field in fields {\n        let (name, index, nullable) = field;\n        note_fields = note_fields.push_back(quote { $name: aztec::note::note_field::NoteField });\n        note_field_constructors = note_field_constructors.push_back(\n            quote { $name: aztec::note::note_field::NoteField { index: $index, nullable: $nullable }},\n        );\n    }\n\n    let note_fields = note_fields.join(quote {,});\n    let note_field_constructors = note_field_constructors.join(quote {,});\n\n    quote {\n        pub struct $note_fields_name {\n            pub $note_fields\n        }\n\n        #[abi(notes)]\n        global $global_export_name: (Field, str<$note_name_str_len>, $note_fields_name) = ($note_type_id, $note_name_as_str, $note_fields_name { $note_field_constructors });\n    }\n}\n\n/// Registers a note struct `note` with the given `note_packed_len`, `note_type_id`, `fixed_fields` and\n/// `nullable_fields` in the global `NOTES` map.\ncomptime fn register_note(\n    note: TypeDefinition,\n    note_packed_len: u32,\n    note_type_id: Field,\n    fixed_fields: [(Quoted, Type, u32)],\n    nullable_fields: [(Quoted, Type, u32)],\n) {\n    let mut fields = &[];\n    for field in fixed_fields {\n        let (name, _, index) = field;\n        fields = fields.push_back((name, index, false));\n    }\n    for field in nullable_fields {\n        let (name, _, index) = field;\n        fields = fields.push_back((name, index, true));\n    }\n\n    NOTES.insert(note.as_type(), (note, note_packed_len, note_type_id, fields));\n}\n\n/// Separates note struct members into fixed and nullable ones. It also stores the index of where each struct member\n/// starts in the serialized note. Note that each struct member can occupy multiple fields (as in Field type).\ncomptime fn index_note_fields(\n    s: TypeDefinition,\n    nullable_fields: [Quoted],\n) -> ([(Quoted, Type, u32)], [(Quoted, Type, u32)]) {\n    let mut indexed_fixed_fields: [(Quoted, Type, u32)] = &[];\n    let mut indexed_nullable_fields = &[];\n    let mut counter: u32 = 0;\n    for field in s.fields_as_written() {\n        let (name, typ) = field;\n        if nullable_fields.all(|field| field != name) {\n            indexed_fixed_fields = indexed_fixed_fields.push_back((name, typ, counter));\n        } else {\n            indexed_nullable_fields = indexed_nullable_fields.push_back((name, typ, counter));\n        }\n        let (serialization_fields, _) = generate_serialize_to_fields(name, typ, true);\n        // Each struct member can occupy multiple fields so we need to increment the counter accordingly\n        counter += serialization_fields.len();\n    }\n    (indexed_fixed_fields, indexed_nullable_fields)\n}\n\n/// Generates the following:\n/// - NoteTypeProperties\n/// - NoteType trait implementation\n/// - NoteHash trait implementation\n/// - Packable implementation\n///\n/// Registers the note in the global `NOTES` map.\n///\n/// For more details on the generated code, see the individual functions.\npub comptime fn note(s: TypeDefinition) -> Quoted {\n    assert_has_owner(s);\n\n    let (indexed_fixed_fields, indexed_nullable_fields) = index_note_fields(s, &[]);\n\n    let note_properties = generate_note_properties(s);\n    let note_type_id = get_next_note_type_id();\n    let note_interface_impl = generate_note_interface(s, note_type_id);\n    let note_hash_impl = generate_note_hash_trait_impl(s);\n    let (packable_impl, note_packed_len) = derive_packable_if_not_implemented_and_get_len(s);\n\n    register_note(\n        s,\n        note_packed_len,\n        note_type_id,\n        indexed_fixed_fields,\n        indexed_nullable_fields,\n    );\n\n    quote {\n        $note_properties\n        $note_interface_impl\n        $note_hash_impl\n        $packable_impl\n    }\n}\n\n/// Generates code for a custom note implementation that requires specialized note hash or nullifier computation.\n///\n/// # Generated Code\n/// - NoteTypeProperties: Defines the structure and properties of note fields\n/// - NoteType trait implementation: Provides the note type ID\n/// - Packable implementation: Enables serialization/deserialization of the note\n///\n/// # Registration\n/// Registers the note in the global `NOTES` map with:\n/// - Note type ID\n/// - Packed length\n/// - Field indices and nullability\n///\n/// # Use Cases\n/// Use this macro when implementing a note that needs custom:\n/// - Note hash computation logic\n/// - Nullifier computation logic\n///\n/// The macro omits generating default NoteHash trait implementation, allowing you to provide your own.\n///\n/// # Example\n/// ```\n/// #[custom_note]\n/// struct CustomNote {\n///     value: Field,\n///     metadata: Field\n/// }\n///\n/// impl NoteHash for CustomNote {\n///     // Custom note hash computation...\n///     fn compute_note_hash(...) -> Field { ... }\n///\n///     // Custom nullifier computation...\n///     fn compute_nullifier(...) -> Field { ... }\n///     fn compute_nullifier_unconstrained(...) -> Field { ... }\n/// }\n/// ```\npub comptime fn custom_note(s: TypeDefinition) -> Quoted {\n    let (packable_impl, note_packed_len) = derive_packable_if_not_implemented_and_get_len(s);\n    let note_type_id = get_next_note_type_id();\n\n    let (indexed_fixed_fields, indexed_nullable_fields) = index_note_fields(s, &[]);\n    register_note(\n        s,\n        note_packed_len,\n        note_type_id,\n        indexed_fixed_fields,\n        indexed_nullable_fields,\n    );\n\n    let note_properties = generate_note_properties(s);\n    let note_interface_impl = generate_note_interface(s, note_type_id);\n\n    quote {\n        $note_properties\n        $note_interface_impl\n        $packable_impl\n    }\n}\n\n/// Asserts that the note has an 'owner' field.\n///\n/// We require notes implemented with #[note] macro macro to have an 'owner' field because our\n/// auto-generated nullifier functions expect it. This requirement is most likely only temporary.\ncomptime fn assert_has_owner(note: TypeDefinition) {\n    let fields = note.fields_as_written();\n    let mut has_owner = false;\n    for i in 0..fields.len() {\n        let (field_name, _) = fields[i];\n        if field_name == quote { owner } {\n            has_owner = true;\n            break;\n        }\n    }\n    assert(\n        has_owner,\n        \"Note must have an 'owner' field. If your notes have no owner, use #[custom_note] insteadof #[note] and implement the NoteHashing trait manually.\",\n    );\n}\n"
    }
  }
}
